{"type": "text", "bbox": [152, 285, 751, 707], "res": [{"text": "The question involves extracting information", "confidence": 0.9968027472496033, "text_region": [[155.0, 293.0], [706.0, 294.0], [706.0, 317.0], [155.0, 316.0]]}, {"text": "in a specific format, such as a table or list,", "confidence": 0.9985038042068481, "text_region": [[155.0, 330.0], [673.0, 330.0], [673.0, 353.0], [155.0, 353.0]]}, {"text": "and the model disregards the instruction. This", "confidence": 0.9939463138580322, "text_region": [[155.0, 364.0], [723.0, 364.0], [723.0, 387.0], [155.0, 387.0]]}, {"text": "is a common problem you might face when", "confidence": 0.9919825792312622, "text_region": [[155.0, 400.0], [701.0, 400.0], [701.0, 423.0], [155.0, 423.0]]}, {"text": "interacting with LLMs. This can be due to the", "confidence": 0.9865254163742065, "text_region": [[155.0, 435.0], [698.0, 435.0], [698.0, 458.0], [155.0, 458.0]]}, {"text": "model's inability to interpret specific formatting", "confidence": 0.9995495676994324, "text_region": [[154.0, 468.0], [741.0, 471.0], [741.0, 495.0], [154.0, 492.0]]}, {"text": "instructions, either due to inadequate training", "confidence": 0.9996017217636108, "text_region": [[155.0, 502.0], [722.0, 506.0], [722.0, 531.0], [155.0, 526.0]]}, {"text": "or if your instruction is vague. However, you", "confidence": 0.9899117946624756, "text_region": [[156.0, 539.0], [692.0, 540.0], [692.0, 564.0], [156.0, 563.0]]}, {"text": "can quickly address this issue with a follow-up", "confidence": 0.995611310005188, "text_region": [[156.0, 575.0], [731.0, 575.0], [731.0, 598.0], [156.0, 598.0]]}, {"text": "prompt where you instruct the LLM to give you", "confidence": 0.9907032251358032, "text_region": [[156.0, 611.0], [723.0, 611.0], [723.0, 634.0], [156.0, 634.0]]}, {"text": "the same response in the form of a table, list,", "confidence": 0.9863792061805725, "text_region": [[155.0, 645.0], [712.0, 645.0], [712.0, 668.0], [155.0, 668.0]]}, {"text": "Or format you'd like", "confidence": 0.9776976704597473, "text_region": [[157.0, 680.0], [395.0, 680.0], [395.0, 701.0], [157.0, 701.0]]}], "img_idx": 0}
{"type": "text", "bbox": [153, 1118, 735, 1642], "res": [{"text": "In this scenario, the model is either vague in", "confidence": 0.9978989958763123, "text_region": [[156.0, 1125.0], [699.0, 1125.0], [699.0, 1149.0], [156.0, 1149.0]]}, {"text": "its response or highly specific and, therefore,", "confidence": 0.9860849380493164, "text_region": [[156.0, 1160.0], [706.0, 1160.0], [706.0, 1184.0], [156.0, 1184.0]]}, {"text": "may not be a very apt response to your", "confidence": 0.9797576069831848, "text_region": [[156.0, 1195.0], [645.0, 1194.0], [645.0, 1218.0], [156.0, 1219.0]]}, {"text": "query. This usually happens if your query is.", "confidence": 0.9874787330627441, "text_region": [[157.0, 1230.0], [684.0, 1229.0], [684.0, 1253.0], [157.0, 1254.0]]}, {"text": "not very specific or lacks context. Say, \"what.", "confidence": 0.966454029083252, "text_region": [[155.0, 1264.0], [705.0, 1263.0], [705.0, 1288.0], [155.0, 1289.0]]}, {"text": "are the effects of stress?\". Here, the LLM has", "confidence": 0.989616870880127, "text_region": [[157.0, 1300.0], [691.0, 1300.0], [691.0, 1321.0], [157.0, 1321.0]]}, {"text": "no way of knowing if you want to know about", "confidence": 0.9943569898605347, "text_region": [[157.0, 1335.0], [714.0, 1335.0], [714.0, 1359.0], [157.0, 1359.0]]}, {"text": "osychological effects, short or long terms, etc.", "confidence": 0.995938241481781, "text_region": [[157.0, 1370.0], [722.0, 1369.0], [722.0, 1393.0], [157.0, 1394.0]]}, {"text": "So, it'll typically provide a generic answer that.", "confidence": 0.9780367016792297, "text_region": [[158.0, 1405.0], [723.0, 1405.0], [723.0, 1429.0], [158.0, 1429.0]]}, {"text": "may not answer your question or, in some", "confidence": 0.9933319091796875, "text_region": [[157.0, 1440.0], [675.0, 1440.0], [675.0, 1464.0], [157.0, 1464.0]]}, {"text": "cases, throw a lot of information at you! So", "confidence": 0.9858787655830383, "text_region": [[157.0, 1473.0], [681.0, 1473.0], [681.0, 1497.0], [157.0, 1497.0]]}, {"text": "what's happening is the LLM, having seen", "confidence": 0.9946190118789673, "text_region": [[156.0, 1510.0], [665.0, 1510.0], [665.0, 1534.0], [156.0, 1534.0]]}, {"text": "ooth in-depth answers and overviews in its", "confidence": 0.9820461273193359, "text_region": [[157.0, 1546.0], [688.0, 1546.0], [688.0, 1566.0], [157.0, 1566.0]]}, {"text": "training data, is unable to tune both detail", "confidence": 0.9997714757919312, "text_region": [[155.0, 1579.0], [679.0, 1578.0], [679.0, 1602.0], [155.0, 1603.0]]}, {"text": "and conciseness to your needs", "confidence": 0.9969489574432373, "text_region": [[157.0, 1615.0], [541.0, 1615.0], [541.0, 1636.0], [157.0, 1636.0]]}], "img_idx": 0}
{"type": "title", "bbox": [154, 1008, 694, 1064], "res": [{"text": "NCORRECT SPECIFICITY", "confidence": 0.935641884803772, "text_region": [[159.0, 1024.0], [688.0, 1024.0], [688.0, 1053.0], [159.0, 1053.0]]}], "img_idx": 0}
{"type": "title", "bbox": [153, 185, 531, 246], "res": [{"text": "WRONG FORMAT", "confidence": 0.9933347105979919, "text_region": [[159.0, 203.0], [526.0, 203.0], [526.0, 233.0], [159.0, 233.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [146, 296, 1473, 2105], "res": [{"text": "The question involves extracting information", "confidence": 0.9943849444389343, "text_region": [[154.0, 296.0], [708.0, 296.0], [708.0, 320.0], [154.0, 320.0]]}, {"text": "in a specific format, such as a table or list,", "confidence": 0.99892657995224, "text_region": [[152.0, 328.0], [676.0, 328.0], [676.0, 353.0], [152.0, 353.0]]}, {"text": "and the model disregards the instruction. This", "confidence": 0.9996761679649353, "text_region": [[152.0, 364.0], [723.0, 364.0], [723.0, 388.0], [152.0, 388.0]]}, {"text": "is a common problem you might face when", "confidence": 0.9931281805038452, "text_region": [[152.0, 398.0], [702.0, 398.0], [702.0, 424.0], [152.0, 424.0]]}, {"text": "Mitigation strategy", "confidence": 0.9987332224845886, "text_region": [[957.0, 416.0], [1257.0, 424.0], [1255.0, 464.0], [956.0, 456.0]]}, {"text": "interacting with LLMs. This can be due to the", "confidence": 0.9881861209869385, "text_region": [[152.0, 434.0], [698.0, 434.0], [698.0, 458.0], [152.0, 458.0]]}, {"text": "model's inability to interpret specific formatting", "confidence": 0.9997174739837646, "text_region": [[150.0, 467.0], [742.0, 469.0], [742.0, 496.0], [150.0, 494.0]]}, {"text": "instructions, either due to inadequate training.", "confidence": 0.9750798344612122, "text_region": [[148.0, 498.0], [725.0, 501.0], [725.0, 534.0], [148.0, 530.0]]}, {"text": "or if your instruction is vague. However, you", "confidence": 0.981092095375061, "text_region": [[152.0, 537.0], [691.0, 539.0], [691.0, 565.0], [152.0, 564.0]]}, {"text": "The onus is on the user to provide.", "confidence": 0.9865330457687378, "text_region": [[853.0, 537.0], [1269.0, 537.0], [1269.0, 562.0], [853.0, 562.0]]}, {"text": "can quickly address this issue with a follow-up.", "confidence": 0.9944343566894531, "text_region": [[154.0, 573.0], [732.0, 573.0], [732.0, 599.0], [154.0, 599.0]]}, {"text": "clear instructions of what specific.", "confidence": 0.9820816516876221, "text_region": [[851.0, 573.0], [1269.0, 573.0], [1269.0, 597.0], [851.0, 597.0]]}, {"text": "prompt where you instruct the LLM to give you", "confidence": 0.9979906678199768, "text_region": [[150.0, 607.0], [725.0, 609.0], [725.0, 635.0], [150.0, 633.0]]}, {"text": "format they'd like to receive the.", "confidence": 0.9956102967262268, "text_region": [[851.0, 607.0], [1245.0, 607.0], [1245.0, 631.0], [851.0, 631.0]]}, {"text": "the same response in the form of a table, list,", "confidence": 0.972449541091919, "text_region": [[150.0, 641.0], [712.0, 643.0], [711.0, 669.0], [150.0, 667.0]]}, {"text": "response in. It also helps to have", "confidence": 0.9801586270332336, "text_region": [[849.0, 643.0], [1256.0, 641.0], [1256.0, 667.0], [849.0, 669.0]]}, {"text": "or format you'd like.", "confidence": 0.9678134918212891, "text_region": [[152.0, 679.0], [397.0, 679.0], [397.0, 705.0], [152.0, 705.0]]}, {"text": "multiple format types in the training.", "confidence": 0.9937453866004944, "text_region": [[851.0, 679.0], [1300.0, 679.0], [1300.0, 705.0], [851.0, 705.0]]}, {"text": "dataset as part of the model fine-", "confidence": 0.9977946281433105, "text_region": [[851.0, 712.0], [1273.0, 712.0], [1273.0, 739.0], [851.0, 739.0]]}, {"text": "tuning process, so the LLM can be", "confidence": 0.9957399368286133, "text_region": [[851.0, 748.0], [1269.0, 748.0], [1269.0, 775.0], [851.0, 775.0]]}, {"text": "more accurate when responding", "confidence": 0.9998518824577332, "text_region": [[849.0, 780.0], [1264.0, 784.0], [1264.0, 811.0], [849.0, 807.0]]}, {"text": "INCORRECT SPECIFICITY", "confidence": 0.988967776298523, "text_region": [[152.0, 1018.0], [691.0, 1018.0], [691.0, 1055.0], [152.0, 1055.0]]}, {"text": "In this scenario, the model is either vague in", "confidence": 0.9928938150405884, "text_region": [[152.0, 1123.0], [698.0, 1123.0], [698.0, 1148.0], [152.0, 1148.0]]}, {"text": "its response or highly specific and, therefore,", "confidence": 0.9775229692459106, "text_region": [[152.0, 1159.0], [706.0, 1159.0], [706.0, 1185.0], [152.0, 1185.0]]}, {"text": "may not be a very apt response to your", "confidence": 0.9815381765365601, "text_region": [[152.0, 1195.0], [646.0, 1195.0], [646.0, 1219.0], [152.0, 1219.0]]}, {"text": "query. This usually happens if your query is", "confidence": 0.9866897463798523, "text_region": [[152.0, 1229.0], [687.0, 1229.0], [687.0, 1255.0], [152.0, 1255.0]]}, {"text": "not very specific or lacks context. Say, \"What", "confidence": 0.9941264986991882, "text_region": [[152.0, 1261.0], [704.0, 1261.0], [704.0, 1287.0], [152.0, 1287.0]]}, {"text": "Mitigation strategy", "confidence": 0.9996851682662964, "text_region": [[957.0, 1253.0], [1256.0, 1257.0], [1256.0, 1291.0], [956.0, 1287.0]]}, {"text": "are the effects of stress?\". Here, the LLM has", "confidence": 0.9847415685653687, "text_region": [[152.0, 1298.0], [693.0, 1298.0], [693.0, 1323.0], [152.0, 1323.0]]}, {"text": "no way of knowing if you want to know about.", "confidence": 0.9849860668182373, "text_region": [[152.0, 1332.0], [713.0, 1332.0], [713.0, 1357.0], [152.0, 1357.0]]}, {"text": "psychological effects, short or long terms, etc.", "confidence": 0.9828864932060242, "text_region": [[154.0, 1368.0], [721.0, 1368.0], [721.0, 1395.0], [154.0, 1395.0]]}, {"text": "An interactive query generation", "confidence": 0.9957684278488159, "text_region": [[851.0, 1361.0], [1249.0, 1361.0], [1249.0, 1387.0], [851.0, 1387.0]]}, {"text": "LLM that suggests alternate queries", "confidence": 0.9777121543884277, "text_region": [[847.0, 1391.0], [1296.0, 1393.0], [1296.0, 1425.0], [847.0, 1423.0]]}, {"text": "So, it'll typically provide a generic answer that", "confidence": 0.9929099082946777, "text_region": [[154.0, 1404.0], [723.0, 1404.0], [723.0, 1430.0], [154.0, 1430.0]]}, {"text": "with additional context can be a", "confidence": 0.9964013695716858, "text_region": [[849.0, 1428.0], [1256.0, 1430.0], [1256.0, 1457.0], [849.0, 1455.0]]}, {"text": "may not answer your question or, in some", "confidence": 0.994655966758728, "text_region": [[152.0, 1438.0], [676.0, 1438.0], [676.0, 1464.0], [152.0, 1464.0]]}, {"text": "cases, throw a lot of information at you! So", "confidence": 0.9967131018638611, "text_region": [[152.0, 1472.0], [683.0, 1474.0], [683.0, 1500.0], [152.0, 1498.0]]}, {"text": "great strategy here. The user can", "confidence": 0.9985716938972473, "text_region": [[851.0, 1466.0], [1266.0, 1466.0], [1266.0, 1493.0], [851.0, 1493.0]]}, {"text": "then refine the query by adding", "confidence": 0.9938759207725525, "text_region": [[849.0, 1498.0], [1245.0, 1502.0], [1245.0, 1528.0], [849.0, 1525.0]]}, {"text": "what's happening is the LLM, having seen", "confidence": 0.9930415153503418, "text_region": [[154.0, 1510.0], [666.0, 1510.0], [666.0, 1534.0], [154.0, 1534.0]]}, {"text": "both in-depth answers and overviews in its", "confidence": 0.9932599067687988, "text_region": [[152.0, 1543.0], [691.0, 1543.0], [691.0, 1568.0], [152.0, 1568.0]]}, {"text": "or removing information before", "confidence": 0.9838407635688782, "text_region": [[851.0, 1536.0], [1245.0, 1536.0], [1245.0, 1562.0], [851.0, 1562.0]]}, {"text": "training data, is unable to tune both detail", "confidence": 0.9997551441192627, "text_region": [[152.0, 1579.0], [679.0, 1579.0], [679.0, 1604.0], [152.0, 1604.0]]}, {"text": "sending it to the LLM.", "confidence": 0.9994027614593506, "text_region": [[851.0, 1572.0], [1107.0, 1572.0], [1107.0, 1596.0], [851.0, 1596.0]]}, {"text": "and conciseness to your needs", "confidence": 0.999695360660553, "text_region": [[152.0, 1615.0], [542.0, 1615.0], [542.0, 1640.0], [152.0, 1640.0]]}, {"text": "Galileo", "confidence": 0.9957697987556458, "text_region": [[243.0, 1992.0], [352.0, 1996.0], [350.0, 2032.0], [242.0, 2027.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9903985261917114, "text_region": [[1147.0, 2003.0], [1339.0, 2003.0], [1339.0, 2028.0], [1147.0, 2028.0]]}], "img_idx": 0}
