{"type": "figure", "bbox": [0, 0, 1488, 2104], "res": [{"text": "01", "confidence": 0.9110136032104492, "text_region": [[148.0, 206.0], [261.0, 206.0], [261.0, 298.0], [148.0, 298.0]]}, {"text": "INTRODUCTION TO LLMS AND RAGS", "confidence": 0.9561594128608704, "text_region": [[153.0, 333.0], [1174.0, 333.0], [1174.0, 377.0], [153.0, 377.0]]}, {"text": "The introduction of generative models,", "confidence": 0.9934642314910889, "text_region": [[155.0, 476.0], [633.0, 476.0], [633.0, 504.0], [155.0, 504.0]]}, {"text": "Then, OpenAl came up with Generative Pre", "confidence": 0.9820030331611633, "text_region": [[775.0, 476.0], [1311.0, 476.0], [1311.0, 504.0], [775.0, 504.0]]}, {"text": "that is, the use of the generator and the", "confidence": 0.9992899894714355, "text_region": [[148.0, 508.0], [649.0, 511.0], [649.0, 541.0], [148.0, 539.0]]}, {"text": "trained Transformers (GPTs) models that", "confidence": 0.993117094039917, "text_region": [[773.0, 511.0], [1289.0, 511.0], [1289.0, 539.0], [773.0, 539.0]]}, {"text": " discriminator model competing against one", "confidence": 0.9825835227966309, "text_region": [[148.0, 543.0], [709.0, 546.0], [708.0, 576.0], [148.0, 574.0]]}, {"text": "used unsupervised learning (pre-trained", "confidence": 0.9837315082550049, "text_region": [[775.0, 550.0], [1284.0, 550.0], [1284.0, 572.0], [775.0, 572.0]]}, {"text": "another, became the bedrock upon which", "confidence": 0.9854938983917236, "text_region": [[153.0, 583.0], [675.0, 583.0], [675.0, 605.0], [153.0, 605.0]]}, {"text": "on vast amounts of text) and then fine-", "confidence": 0.9756234288215637, "text_region": [[773.0, 581.0], [1267.0, 581.0], [1267.0, 609.0], [773.0, 609.0]]}, {"text": "foundation models were built. Then, the", "confidence": 0.9882157444953918, "text_region": [[151.0, 616.0], [647.0, 616.0], [647.0, 644.0], [151.0, 644.0]]}, {"text": "tuned for specific tasks based on need..", "confidence": 0.9668553471565247, "text_region": [[773.0, 618.0], [1262.0, 618.0], [1262.0, 640.0], [773.0, 640.0]]}, {"text": "introduction of the attention mechanism", "confidence": 0.9914380311965942, "text_region": [[148.0, 649.0], [662.0, 651.0], [662.0, 679.0], [148.0, 677.0]]}, {"text": "Its successor models grew capabilities.", "confidence": 0.985130786895752, "text_region": [[771.0, 651.0], [1264.0, 651.0], [1264.0, 679.0], [771.0, 679.0]]}, {"text": "(in the phenomenal paper \"Attention Is All", "confidence": 0.9914321899414062, "text_region": [[153.0, 686.0], [678.0, 686.0], [678.0, 714.0], [153.0, 714.0]]}, {"text": "With GPT-2, you could perform translation,", "confidence": 0.98786860704422, "text_region": [[773.0, 686.0], [1300.0, 686.0], [1300.0, 714.0], [773.0, 714.0]]}, {"text": "You Need\") and transformers thereafter", "confidence": 0.9769371151924133, "text_region": [[153.0, 721.0], [651.0, 721.0], [651.0, 750.0], [153.0, 750.0]]}, {"text": " summarization, and even rudimentary", "confidence": 0.9845821857452393, "text_region": [[771.0, 719.0], [1256.0, 721.0], [1255.0, 752.0], [771.0, 750.0]]}, {"text": "marked the departure from recurrent", "confidence": 0.9892269968986511, "text_region": [[153.0, 756.0], [622.0, 756.0], [622.0, 785.0], [153.0, 785.0]]}, {"text": "conversation. With GPT-3, having 175 billion", "confidence": 0.9991706609725952, "text_region": [[773.0, 756.0], [1313.0, 756.0], [1313.0, 785.0], [773.0, 785.0]]}, {"text": "neural networks (RNNs) or long short-term", "confidence": 0.9870058298110962, "text_region": [[151.0, 791.0], [682.0, 791.0], [682.0, 820.0], [151.0, 820.0]]}, {"text": "parameters and therefore capable of", "confidence": 0.9998091459274292, "text_region": [[771.0, 791.0], [1247.0, 789.0], [1247.0, 820.0], [771.0, 822.0]]}, {"text": "memory networks (LsTMs). while these", "confidence": 0.9796183109283447, "text_region": [[151.0, 826.0], [640.0, 826.0], [640.0, 855.0], [151.0, 855.0]]}, {"text": "capturing complex relationships between", "confidence": 0.9911178946495056, "text_region": [[773.0, 828.0], [1295.0, 828.0], [1295.0, 857.0], [773.0, 857.0]]}, {"text": "were processing data sequentially,the", "confidence": 0.9618962407112122, "text_region": [[151.0, 861.0], [638.0, 861.0], [638.0, 890.0], [151.0, 890.0]]}, {"text": "elements, it could generate creative content,", "confidence": 0.9918373823165894, "text_region": [[771.0, 861.0], [1333.0, 861.0], [1333.0, 890.0], [771.0, 890.0]]}, {"text": "newer methods could learn contextual", "confidence": 0.9812855124473572, "text_region": [[151.0, 896.0], [638.0, 896.0], [638.0, 925.0], [151.0, 925.0]]}, {"text": "solve complex problems, and provide", "confidence": 0.9782295227050781, "text_region": [[773.0, 896.0], [1247.0, 896.0], [1247.0, 925.0], [773.0, 925.0]]}, {"text": "relationships between different elements in", "confidence": 0.9829092025756836, "text_region": [[151.0, 931.0], [695.0, 931.0], [695.0, 960.0], [151.0, 960.0]]}, {"text": "explanations.The introduction of GPT-40", "confidence": 0.9700793623924255, "text_region": [[771.0, 931.0], [1284.0, 929.0], [1284.0, 958.0], [771.0, 960.0]]}, {"text": "the sequence.The progress in the field since", "confidence": 0.9449604153633118, "text_region": [[148.0, 967.0], [706.0, 967.0], [706.0, 995.0], [148.0, 995.0]]}, {"text": "much more refined with few-shot and", "confidence": 0.9682181477546692, "text_region": [[768.0, 967.0], [1251.0, 967.0], [1251.0, 995.0], [768.0, 995.0]]}, {"text": "then has been groundbreaking,building", "confidence": 0.9572523236274719, "text_region": [[146.0, 997.0], [658.0, 1002.0], [657.0, 1032.0], [146.0, 1028.0]]}, {"text": "zero-shot learning capabilities,has been", "confidence": 0.9627538919448853, "text_region": [[773.0, 1002.0], [1284.0, 1002.0], [1284.0, 1030.0], [773.0, 1030.0]]}, {"text": "atop transformers.", "confidence": 0.9686293005943298, "text_region": [[153.0, 1037.0], [385.0, 1037.0], [385.0, 1065.0], [153.0, 1065.0]]}, {"text": "a milepost in the space with additional", "confidence": 0.9643598794937134, "text_region": [[773.0, 1037.0], [1271.0, 1037.0], [1271.0, 1065.0], [773.0, 1065.0]]}, {"text": "capabilities i.e., the ability to process image", "confidence": 0.9284771680831909, "text_region": [[775.0, 1072.0], [1331.0, 1072.0], [1331.0, 1100.0], [775.0, 1100.0]]}, {"text": "sound,and text) and the ability to let users", "confidence": 0.9484434127807617, "text_region": [[773.0, 1107.0], [1311.0, 1107.0], [1311.0, 1135.0], [773.0, 1135.0]]}, {"text": "customize their style,tone,and tasks.", "confidence": 0.9593833684921265, "text_region": [[773.0, 1142.0], [1238.0, 1142.0], [1238.0, 1170.0], [773.0, 1170.0]]}, {"text": "Galileo", "confidence": 0.9965332746505737, "text_region": [[248.0, 1997.0], [352.0, 1997.0], [352.0, 2029.0], [248.0, 2029.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9906944036483765, "text_region": [[1145.0, 2001.0], [1340.0, 2001.0], [1340.0, 2029.0], [1145.0, 2029.0]]}], "img_idx": 0}
