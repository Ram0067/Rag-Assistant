{"type": "text", "bbox": [198, 1016, 1290, 1243], "res": [{"text": "s begin by looking at Fig 1.3 to understand the workings of a simple RAG system. In the fir", "confidence": 0.9846304655075073, "text_region": [[199.0, 1022.0], [1285.0, 1021.0], [1285.0, 1044.0], [199.0, 1046.0]]}, {"text": "o, there's an encoder that converts your raw text and documents into mathematical forr", "confidence": 0.9890022873878479, "text_region": [[199.0, 1055.0], [1288.0, 1054.0], [1288.0, 1077.0], [199.0, 1079.0]]}, {"text": "he computer can understand them. So, all the words, sentences, or entire documents th", "confidence": 0.986882746219635, "text_region": [[200.0, 1087.0], [1287.0, 1085.0], [1287.0, 1108.0], [200.0, 1111.0]]}, {"text": "ke up your external database are converted into \"vectors.\" All these vectors (in the form.", "confidence": 0.9869605898857117, "text_region": [[199.0, 1119.0], [1283.0, 1116.0], [1283.0, 1144.0], [199.0, 1146.0]]}, {"text": "tor embeddings) will now be stored in a vector database. Note that this is a great way o.", "confidence": 0.9828279614448547, "text_region": [[198.0, 1148.0], [1288.0, 1151.0], [1288.0, 1178.0], [198.0, 1176.0]]}, {"text": "turing the semantics of different words, their relationship to other words, and what topic.", "confidence": 0.9913866519927979, "text_region": [[198.0, 1182.0], [1287.0, 1183.0], [1287.0, 1210.0], [198.0, 1209.0]]}, {"text": "se words represent.", "confidence": 0.994583010673523, "text_region": [[200.0, 1216.0], [437.0, 1216.0], [437.0, 1239.0], [200.0, 1239.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [150, 0, 1337, 932], "res": [{"text": "10", "confidence": 0.9987791776657104, "text_region": [[1310.0, 118.0], [1335.0, 118.0], [1335.0, 138.0], [1310.0, 138.0]]}, {"text": "HOW DO RAGs WORK?", "confidence": 0.9940603971481323, "text_region": [[156.0, 206.0], [759.0, 204.0], [760.0, 241.0], [156.0, 244.0]]}, {"text": "How RAG Works", "confidence": 0.9277275800704956, "text_region": [[621.0, 343.0], [868.0, 343.0], [868.0, 369.0], [621.0, 369.0]]}, {"text": "Encoder", "confidence": 0.9981117248535156, "text_region": [[479.0, 436.0], [543.0, 436.0], [543.0, 453.0], [479.0, 453.0]]}, {"text": "Vector Database", "confidence": 0.9776535630226135, "text_region": [[646.0, 436.0], [772.0, 436.0], [772.0, 453.0], [646.0, 453.0]]}, {"text": "Search", "confidence": 0.9973707795143127, "text_region": [[292.0, 590.0], [358.0, 590.0], [358.0, 612.0], [292.0, 612.0]]}, {"text": "Query", "confidence": 0.9981769323348999, "text_region": [[482.0, 588.0], [543.0, 593.0], [541.0, 613.0], [481.0, 609.0]]}, {"text": "Question +Context", "confidence": 0.9701905846595764, "text_region": [[648.0, 591.0], [795.0, 591.0], [795.0, 608.0], [648.0, 608.0]]}, {"text": "LLM", "confidence": 0.9971649646759033, "text_region": [[913.0, 591.0], [952.0, 591.0], [952.0, 609.0], [913.0, 609.0]]}, {"text": "Answer", "confidence": 0.9985876083374023, "text_region": [[1095.0, 590.0], [1156.0, 590.0], [1156.0, 607.0], [1095.0, 607.0]]}, {"text": "\"The population of Paris", "confidence": 0.9442529678344727, "text_region": [[1024.0, 691.0], [1229.0, 691.0], [1229.0, 711.0], [1024.0, 711.0]]}, {"text": "France,according to the", "confidence": 0.9681298732757568, "text_region": [[1023.0, 711.0], [1232.0, 712.0], [1232.0, 733.0], [1023.0, 732.0]]}, {"text": "most recent census", "confidence": 0.9733763933181763, "text_region": [[1024.0, 737.0], [1192.0, 737.0], [1192.0, 754.0], [1024.0, 754.0]]}, {"text": "\"What is the population", "confidence": 0.9654225707054138, "text_region": [[412.0, 755.0], [609.0, 756.0], [609.0, 777.0], [412.0, 775.0]]}, {"text": "report,is approximately", "confidence": 0.9878607988357544, "text_region": [[1024.0, 758.0], [1223.0, 758.0], [1223.0, 775.0], [1024.0, 775.0]]}, {"text": "of Paris,France?\"", "confidence": 0.9149518609046936, "text_region": [[412.0, 778.0], [561.0, 778.0], [561.0, 799.0], [412.0, 799.0]]}, {"text": "2.2million people.\"", "confidence": 0.9616719484329224, "text_region": [[1023.0, 777.0], [1184.0, 778.0], [1184.0, 799.0], [1023.0, 797.0]]}, {"text": "Galileo", "confidence": 0.9941333532333374, "text_region": [[736.0, 877.0], [790.0, 877.0], [790.0, 896.0], [736.0, 896.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [145, 0, 1353, 2081], "res": [{"text": "10", "confidence": 0.9994739294052124, "text_region": [[1306.0, 113.0], [1337.0, 113.0], [1337.0, 141.0], [1306.0, 141.0]]}, {"text": "HOW DO RAGs WORK?", "confidence": 0.9966054558753967, "text_region": [[156.0, 202.0], [760.0, 202.0], [760.0, 245.0], [156.0, 245.0]]}, {"text": "How RAG Works", "confidence": 0.9245285391807556, "text_region": [[618.0, 340.0], [871.0, 340.0], [871.0, 371.0], [618.0, 371.0]]}, {"text": "Encoder", "confidence": 0.9982291460037231, "text_region": [[478.0, 431.0], [545.0, 431.0], [545.0, 455.0], [478.0, 455.0]]}, {"text": "Vector Database", "confidence": 0.9839468598365784, "text_region": [[642.0, 429.0], [776.0, 429.0], [776.0, 460.0], [642.0, 460.0]]}, {"text": "Search", "confidence": 0.9785647392272949, "text_region": [[287.0, 585.0], [363.0, 585.0], [363.0, 616.0], [287.0, 616.0]]}, {"text": "Query", "confidence": 0.9978501200675964, "text_region": [[483.0, 587.0], [545.0, 587.0], [545.0, 616.0], [483.0, 616.0]]}, {"text": "Question +Context", "confidence": 0.9670178890228271, "text_region": [[645.0, 587.0], [796.0, 587.0], [796.0, 609.0], [645.0, 609.0]]}, {"text": "LLM", "confidence": 0.9942811131477356, "text_region": [[911.0, 585.0], [956.0, 585.0], [956.0, 611.0], [911.0, 611.0]]}, {"text": "Answer", "confidence": 0.9978953003883362, "text_region": [[1089.0, 583.0], [1160.0, 583.0], [1160.0, 613.0], [1089.0, 613.0]]}, {"text": "\"The population of Paris", "confidence": 0.9497013092041016, "text_region": [[1024.0, 689.0], [1229.0, 689.0], [1229.0, 711.0], [1024.0, 711.0]]}, {"text": "France,according to the", "confidence": 0.9707382917404175, "text_region": [[1022.0, 711.0], [1233.0, 711.0], [1233.0, 733.0], [1022.0, 733.0]]}, {"text": "most recent census", "confidence": 0.9651232957839966, "text_region": [[1022.0, 733.0], [1188.0, 730.0], [1189.0, 754.0], [1022.0, 757.0]]}, {"text": "\"What is the population", "confidence": 0.9385480284690857, "text_region": [[411.0, 750.0], [611.0, 750.0], [611.0, 778.0], [411.0, 778.0]]}, {"text": "ortis approximately", "confidence": 0.9262799620628357, "text_region": [[1053.0, 748.0], [1227.0, 750.0], [1226.0, 781.0], [1053.0, 778.0]]}, {"text": "repo", "confidence": 0.9928942918777466, "text_region": [[1029.0, 759.0], [1062.0, 759.0], [1062.0, 774.0], [1029.0, 774.0]]}, {"text": "of ParisFrance", "confidence": 0.9544867873191833, "text_region": [[409.0, 776.0], [560.0, 774.0], [560.0, 798.0], [409.0, 800.0]]}, {"text": "2.2 million people.", "confidence": 0.930167019367218, "text_region": [[1024.0, 776.0], [1184.0, 776.0], [1184.0, 800.0], [1024.0, 800.0]]}, {"text": "Galileo", "confidence": 0.9713816046714783, "text_region": [[707.0, 871.0], [791.0, 871.0], [791.0, 895.0], [707.0, 895.0]]}, {"text": "Fig 1.3: How RAG works.", "confidence": 0.974275529384613, "text_region": [[611.0, 954.0], [869.0, 954.0], [869.0, 982.0], [611.0, 982.0]]}, {"text": "Let's begin by looking at Fig 1.3 to understand the workings of a simple RAG system. In the first", "confidence": 0.9816445708274841, "text_region": [[149.0, 1019.0], [1313.0, 1019.0], [1313.0, 1047.0], [149.0, 1047.0]]}, {"text": "step, there's an encoder that converts your raw text and documents into mathematical form,.", "confidence": 0.9901759624481201, "text_region": [[149.0, 1049.0], [1313.0, 1051.0], [1313.0, 1082.0], [149.0, 1080.0]]}, {"text": "so the computer can understand them. So, all the words, sentences, or entire documents that", "confidence": 0.993153989315033, "text_region": [[149.0, 1084.0], [1317.0, 1084.0], [1317.0, 1112.0], [149.0, 1112.0]]}, {"text": "make up your external database are converted into \"vectors.\" All these vectors (in the form of", "confidence": 0.9956842064857483, "text_region": [[149.0, 1116.0], [1317.0, 1116.0], [1317.0, 1145.0], [149.0, 1145.0]]}, {"text": "vector embeddings) will now be stored in a vector database. Note that this is a great way of", "confidence": 0.9993659257888794, "text_region": [[149.0, 1149.0], [1300.0, 1149.0], [1300.0, 1177.0], [149.0, 1177.0]]}, {"text": "capturing the semantics of different words, their relationship to other words, and what topics", "confidence": 0.9971374273300171, "text_region": [[152.0, 1181.0], [1309.0, 1181.0], [1309.0, 1210.0], [152.0, 1210.0]]}, {"text": "these words represent..", "confidence": 0.9852778315544128, "text_region": [[147.0, 1212.0], [436.0, 1214.0], [436.0, 1242.0], [147.0, 1240.0]]}, {"text": "Learn more", "confidence": 0.9875062108039856, "text_region": [[323.0, 1355.0], [511.0, 1355.0], [511.0, 1383.0], [323.0, 1383.0]]}, {"text": "It's not possible to convert the vector embeddings back to the text. Remember.", "confidence": 0.9935386776924133, "text_region": [[196.0, 1431.0], [1191.0, 1431.0], [1191.0, 1459.0], [196.0, 1459.0]]}, {"text": "that this isn't a 1:1 mapping of text to vector. This is because the text undergoes a.", "confidence": 0.9865899085998535, "text_region": [[196.0, 1463.0], [1220.0, 1463.0], [1220.0, 1494.0], [196.0, 1494.0]]}, {"text": "dimensionality reduction, and only the essential features are retained. Consequently,.", "confidence": 0.9942726492881775, "text_region": [[196.0, 1496.0], [1280.0, 1496.0], [1280.0, 1524.0], [196.0, 1524.0]]}, {"text": "many words, sentences, and texts will have similar vector embeddings, and this helps", "confidence": 0.9916934967041016, "text_region": [[194.0, 1528.0], [1289.0, 1528.0], [1289.0, 1556.0], [194.0, 1556.0]]}, {"text": "determine their similarity or cluster them together. You'll see how the idea will form.", "confidence": 0.9915381073951721, "text_region": [[196.0, 1561.0], [1253.0, 1561.0], [1253.0, 1589.0], [196.0, 1589.0]]}, {"text": "the crux of the RAG system further down. So, each time you store a vector embedding.", "confidence": 0.9951595067977905, "text_region": [[192.0, 1591.0], [1280.0, 1593.0], [1280.0, 1624.0], [192.0, 1621.0]]}, {"text": "to the vector database, you'll also store a reference to the actual document in the", "confidence": 0.9872401356697083, "text_region": [[194.0, 1624.0], [1231.0, 1624.0], [1231.0, 1652.0], [194.0, 1652.0]]}, {"text": "form of a URL or maybe a document ID..", "confidence": 0.9812623262405396, "text_region": [[196.0, 1658.0], [691.0, 1658.0], [691.0, 1686.0], [196.0, 1686.0]]}, {"text": "In the first step, you'll ask, \"What is the population of Paris, France?\" Ideally, a model with an", "confidence": 0.9908670783042908, "text_region": [[152.0, 1795.0], [1286.0, 1795.0], [1286.0, 1823.0], [152.0, 1823.0]]}, {"text": "older training cutoff date and no recent source to refer to will give an outdated answer. In this.", "confidence": 0.9938154220581055, "text_region": [[152.0, 1827.0], [1320.0, 1827.0], [1320.0, 1856.0], [152.0, 1856.0]]}, {"text": "case, your prompt is first encoded using the same model that was used to create the vector", "confidence": 0.9918725490570068, "text_region": [[152.0, 1862.0], [1302.0, 1862.0], [1302.0, 1884.0], [152.0, 1884.0]]}, {"text": "embeddings for the external source (and stored in the vector database). So, the output would", "confidence": 0.9923939108848572, "text_region": [[152.0, 1892.0], [1326.0, 1892.0], [1326.0, 1921.0], [152.0, 1921.0]]}, {"text": "be a vector that'll represent your query..", "confidence": 0.9854890704154968, "text_region": [[147.0, 1925.0], [645.0, 1925.0], [645.0, 1953.0], [147.0, 1953.0]]}, {"text": "Galileo", "confidence": 0.9935593008995056, "text_region": [[245.0, 1999.0], [349.0, 1999.0], [349.0, 2031.0], [245.0, 2031.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9901229739189148, "text_region": [[1146.0, 2003.0], [1344.0, 2003.0], [1344.0, 2031.0], [1146.0, 2031.0]]}], "img_idx": 0}
