{"type": "figure", "bbox": [0, 0, 1488, 2104], "res": [{"text": "7", "confidence": 0.11173919588327408, "text_region": [[1318.0, 121.0], [1329.0, 121.0], [1329.0, 134.0], [1318.0, 134.0]]}, {"text": "RAGVS.FINE-TUNING VS", "confidence": 0.9692713022232056, "text_region": [[157.0, 202.0], [839.0, 202.0], [839.0, 245.0], [157.0, 245.0]]}, {"text": "PROMPT ENGINEERING", "confidence": 0.980530321598053, "text_region": [[157.0, 254.0], [760.0, 254.0], [760.0, 298.0], [157.0, 298.0]]}, {"text": "We've already looked at RAG in some depth", "confidence": 0.9962643980979919, "text_region": [[151.0, 368.0], [700.0, 368.0], [700.0, 397.0], [151.0, 397.0]]}, {"text": "multiple epochs with the aim of reducing", "confidence": 0.986048698425293, "text_region": [[771.0, 366.0], [1289.0, 368.0], [1289.0, 399.0], [771.0, 397.0]]}, {"text": "in the previous sections. Now, let's quickly", "confidence": 0.9979895949363708, "text_region": [[148.0, 401.0], [669.0, 401.0], [669.0, 430.0], [148.0, 430.0]]}, {"text": "its loss, i.e., the model's predicted sentiment", "confidence": 0.9852070212364197, "text_region": [[771.0, 397.0], [1324.0, 399.0], [1324.0, 430.0], [771.0, 427.0]]}, {"text": "go through two more widely used terms", "confidence": 0.9792665243148804, "text_region": [[151.0, 434.0], [653.0, 434.0], [653.0, 462.0], [151.0, 462.0]]}, {"text": "label should be the same as the actual.", "confidence": 0.9634547829627991, "text_region": [[775.0, 434.0], [1271.0, 434.0], [1271.0, 462.0], [775.0, 462.0]]}, {"text": "concerning LLMs and when to use what.", "confidence": 0.9993728399276733, "text_region": [[151.0, 467.0], [647.0, 467.0], [647.0, 495.0], [151.0, 495.0]]}, {"text": "Prompt engineering is sometimes confused", "confidence": 0.9836732745170593, "text_region": [[773.0, 500.0], [1322.0, 500.0], [1322.0, 528.0], [773.0, 528.0]]}, {"text": "When you're fine-tuning an LLM, you're", "confidence": 0.9899783134460449, "text_region": [[151.0, 530.0], [636.0, 530.0], [636.0, 559.0], [151.0, 559.0]]}, {"text": "with fine-tuning. Prompt engineering", "confidence": 0.9874977469444275, "text_region": [[771.0, 528.0], [1238.0, 530.0], [1238.0, 561.0], [771.0, 559.0]]}, {"text": "training the model on smaller (and more", "confidence": 0.9836735129356384, "text_region": [[151.0, 563.0], [664.0, 563.0], [664.0, 592.0], [151.0, 592.0]]}, {"text": "involves no training at all. Rather, its a", "confidence": 0.9630076289176941, "text_region": [[773.0, 563.0], [1251.0, 563.0], [1251.0, 592.0], [773.0, 592.0]]}, {"text": "specific) datasets to help them perform", "confidence": 0.9891520738601685, "text_region": [[153.0, 596.0], [653.0, 596.0], [653.0, 625.0], [153.0, 625.0]]}, {"text": "technique where you provide additional", "confidence": 0.9764850735664368, "text_region": [[773.0, 596.0], [1275.0, 596.0], [1275.0, 625.0], [773.0, 625.0]]}, {"text": "better on specific tasks. For task-specific", "confidence": 0.976196825504303, "text_region": [[151.0, 629.0], [662.0, 629.0], [662.0, 658.0], [151.0, 658.0]]}, {"text": "context to the LLM in the form of examples", "confidence": 0.9904261827468872, "text_region": [[773.0, 629.0], [1304.0, 629.0], [1304.0, 658.0], [773.0, 658.0]]}, {"text": "fine-tuning, you'd typically do this by", "confidence": 0.9873603582382202, "text_region": [[148.0, 657.0], [616.0, 660.0], [615.0, 690.0], [148.0, 688.0]]}, {"text": "of how you expect it to reply to your prompt", "confidence": 0.980476975440979, "text_region": [[773.0, 662.0], [1322.0, 662.0], [1322.0, 690.0], [773.0, 690.0]]}, {"text": "preparing a labeled dataset and then fine-", "confidence": 0.9907907843589783, "text_region": [[148.0, 693.0], [686.0, 690.0], [686.0, 721.0], [148.0, 723.0]]}, {"text": "so that it's able to understand your intent", "confidence": 0.9945902228355408, "text_region": [[773.0, 695.0], [1293.0, 695.0], [1293.0, 723.0], [773.0, 723.0]]}, {"text": "tuning specific layers of the pre-trained", "confidence": 0.9963662028312683, "text_region": [[148.0, 725.0], [651.0, 725.0], [651.0, 754.0], [148.0, 754.0]]}, {"text": "better. So, instead of saying, \"Give me a", "confidence": 0.9939941763877869, "text_region": [[773.0, 725.0], [1269.0, 725.0], [1269.0, 756.0], [773.0, 756.0]]}, {"text": "model to perform a specific task accurately.", "confidence": 0.9859308004379272, "text_region": [[151.0, 758.0], [702.0, 758.0], [702.0, 787.0], [151.0, 787.0]]}, {"text": "code to implement RAG, you'll say,\"Give", "confidence": 0.9632626175880432, "text_region": [[773.0, 758.0], [1286.0, 758.0], [1286.0, 789.0], [773.0, 789.0]]}, {"text": "Let's say maybe you want to classify legal", "confidence": 0.9907101988792419, "text_region": [[148.0, 789.0], [675.0, 789.0], [675.0, 817.0], [148.0, 817.0]]}, {"text": "me an introductory code that shows the", "confidence": 0.9886053800582886, "text_region": [[773.0, 791.0], [1278.0, 791.0], [1278.0, 820.0], [773.0, 820.0]]}, {"text": "wordings into positive, neutral, and negative", "confidence": 0.9998021721839905, "text_region": [[151.0, 824.0], [704.0, 824.0], [704.0, 853.0], [151.0, 853.0]]}, {"text": "basic implementation of RAG, and make", "confidence": 0.9823864102363586, "text_region": [[775.0, 824.0], [1282.0, 824.0], [1282.0, 853.0], [775.0, 853.0]]}, {"text": "sentiments. So you'd have a large amount", "confidence": 0.9992052316665649, "text_region": [[151.0, 857.0], [684.0, 857.0], [684.0, 885.0], [151.0, 885.0]]}, {"text": "sure to use the dot product to determine the", "confidence": 0.9889069199562073, "text_region": [[773.0, 859.0], [1326.0, 859.0], [1326.0, 881.0], [773.0, 881.0]]}, {"text": "of labeled data with specific terminologies", "confidence": 0.9992548227310181, "text_region": [[148.0, 885.0], [686.0, 888.0], [686.0, 918.0], [148.0, 916.0]]}, {"text": "similarity between the query vector and the", "confidence": 0.9884403944015503, "text_region": [[775.0, 890.0], [1322.0, 890.0], [1322.0, 918.0], [775.0, 918.0]]}, {"text": "(Iabeled appropriately) and then fine-tune", "confidence": 0.9932679533958435, "text_region": [[153.0, 920.0], [691.0, 920.0], [691.0, 949.0], [153.0, 949.0]]}, {"text": "document vectors.\"", "confidence": 0.9997804164886475, "text_region": [[773.0, 920.0], [1023.0, 920.0], [1023.0, 949.0], [773.0, 949.0]]}, {"text": "the model by training it on this dataset for", "confidence": 0.996782124042511, "text_region": [[151.0, 953.0], [678.0, 953.0], [678.0, 982.0], [151.0, 982.0]]}, {"text": "Let's look at the differences in the three approaches in Table 1.1", "confidence": 0.9884588122367859, "text_region": [[151.0, 1056.0], [941.0, 1056.0], [941.0, 1085.0], [151.0, 1085.0]]}, {"text": "CHARACTERISTIC", "confidence": 0.9990288019180298, "text_region": [[173.0, 1172.0], [436.0, 1175.0], [436.0, 1206.0], [173.0, 1203.0]]}, {"text": "FINE-TUNING", "confidence": 0.9982870221138, "text_region": [[589.0, 1175.0], [788.0, 1175.0], [788.0, 1205.0], [589.0, 1205.0]]}, {"text": "RAG", "confidence": 0.9343883395195007, "text_region": [[857.0, 1173.0], [928.0, 1173.0], [928.0, 1205.0], [857.0, 1205.0]]}, {"text": "PROMPT ENGINEERING", "confidence": 0.9743779301643372, "text_region": [[985.0, 1175.0], [1318.0, 1175.0], [1318.0, 1203.0], [985.0, 1203.0]]}, {"text": "Can it make use of external", "confidence": 0.9831568598747253, "text_region": [[173.0, 1249.0], [518.0, 1249.0], [518.0, 1278.0], [173.0, 1278.0]]}, {"text": "knowledge sources?", "confidence": 0.9997589588165283, "text_region": [[168.0, 1278.0], [430.0, 1280.0], [429.0, 1311.0], [168.0, 1308.0]]}, {"text": "x", "confidence": 0.8620558977127075, "text_region": [[680.0, 1269.0], [702.0, 1269.0], [702.0, 1293.0], [680.0, 1293.0]]}, {"text": "x", "confidence": 0.7729629278182983, "text_region": [[1143.0, 1269.0], [1162.0, 1269.0], [1162.0, 1293.0], [1143.0, 1293.0]]}, {"text": "Does it minimize.", "confidence": 0.9589568972587585, "text_region": [[170.0, 1341.0], [374.0, 1341.0], [374.0, 1363.0], [170.0, 1363.0]]}, {"text": "hallucinations?", "confidence": 0.9995114803314209, "text_region": [[170.0, 1370.0], [365.0, 1370.0], [365.0, 1398.0], [170.0, 1398.0]]}, {"text": "Does it require domain-", "confidence": 0.9964432716369629, "text_region": [[173.0, 1429.0], [469.0, 1429.0], [469.0, 1457.0], [173.0, 1457.0]]}, {"text": "x", "confidence": 0.7652614712715149, "text_region": [[881.0, 1451.0], [903.0, 1451.0], [903.0, 1473.0], [881.0, 1473.0]]}, {"text": "x", "confidence": 0.8785978555679321, "text_region": [[1140.0, 1446.0], [1167.0, 1446.0], [1167.0, 1477.0], [1140.0, 1477.0]]}, {"text": "specific training data?", "confidence": 0.9993680119514465, "text_region": [[173.0, 1462.0], [454.0, 1462.0], [454.0, 1490.0], [173.0, 1490.0]]}, {"text": "Is it suitable for dynamic", "confidence": 0.9810428619384766, "text_region": [[170.0, 1521.0], [480.0, 1521.0], [480.0, 1550.0], [170.0, 1550.0]]}, {"text": "x", "confidence": 0.8446075320243835, "text_region": [[682.0, 1539.0], [702.0, 1539.0], [702.0, 1563.0], [682.0, 1563.0]]}, {"text": "x", "confidence": 0.7729629278182983, "text_region": [[1143.0, 1539.0], [1162.0, 1539.0], [1162.0, 1563.0], [1143.0, 1563.0]]}, {"text": "data?", "confidence": 0.9997541308403015, "text_region": [[170.0, 1550.0], [250.0, 1550.0], [250.0, 1580.0], [170.0, 1580.0]]}, {"text": "Does it offer clear", "confidence": 0.9992734789848328, "text_region": [[175.0, 1613.0], [394.0, 1613.0], [394.0, 1635.0], [175.0, 1635.0]]}, {"text": "x", "confidence": 0.860737144947052, "text_region": [[682.0, 1628.0], [702.0, 1628.0], [702.0, 1653.0], [682.0, 1653.0]]}, {"text": "V", "confidence": 0.38978636264801025, "text_region": [[881.0, 1626.0], [903.0, 1626.0], [903.0, 1648.0], [881.0, 1648.0]]}, {"text": "x", "confidence": 0.8853471875190735, "text_region": [[1143.0, 1628.0], [1162.0, 1628.0], [1162.0, 1655.0], [1143.0, 1655.0]]}, {"text": "interpretability of outputs?", "confidence": 0.9998350143432617, "text_region": [[170.0, 1642.0], [505.0, 1642.0], [505.0, 1670.0], [170.0, 1670.0]]}, {"text": "Low resource utilization", "confidence": 0.980044424533844, "text_region": [[170.0, 1716.0], [465.0, 1716.0], [465.0, 1745.0], [170.0, 1745.0]]}, {"text": "x", "confidence": 0.8263713717460632, "text_region": [[682.0, 1720.0], [702.0, 1720.0], [702.0, 1742.0], [682.0, 1742.0]]}, {"text": "x", "confidence": 0.7518199682235718, "text_region": [[884.0, 1720.0], [901.0, 1720.0], [901.0, 1740.0], [884.0, 1740.0]]}, {"text": "Quick deployment", "confidence": 0.999928891658783, "text_region": [[173.0, 1806.0], [403.0, 1806.0], [403.0, 1834.0], [173.0, 1834.0]]}, {"text": "x", "confidence": 0.8263713717460632, "text_region": [[682.0, 1810.0], [702.0, 1810.0], [702.0, 1832.0], [682.0, 1832.0]]}, {"text": "x", "confidence": 0.7382761836051941, "text_region": [[884.0, 1810.0], [901.0, 1810.0], [901.0, 1832.0], [884.0, 1832.0]]}, {"text": "Table 1.1: Comparing Fine-tuning, RAG and prompt engineering", "confidence": 0.9851132035255432, "text_region": [[385.0, 1920.0], [1101.0, 1922.0], [1100.0, 1953.0], [385.0, 1951.0]]}, {"text": "Galileo", "confidence": 0.9951367974281311, "text_region": [[243.0, 1989.0], [355.0, 1995.0], [353.0, 2034.0], [241.0, 2029.0]]}, {"text": "www.rungalileo.io.", "confidence": 0.9536100029945374, "text_region": [[1145.0, 2001.0], [1340.0, 2001.0], [1340.0, 2029.0], [1145.0, 2029.0]]}], "img_idx": 0}
