{"type": "text", "bbox": [777, 931, 1327, 1221], "res": [{"text": "In the second phase, there's supervised", "confidence": 0.9567227363586426, "text_region": [[779.0, 935.0], [1271.0, 936.0], [1271.0, 957.0], [779.0, 956.0]]}, {"text": "learning, where the model benefits from", "confidence": 0.9851050972938538, "text_region": [[779.0, 967.0], [1273.0, 965.0], [1273.0, 988.0], [779.0, 990.0]]}, {"text": "being trained with clear objectives, such as", "confidence": 0.9793820977210999, "text_region": [[780.0, 998.0], [1313.0, 999.0], [1313.0, 1023.0], [780.0, 1022.0]]}, {"text": "anguage translation or text classification.", "confidence": 0.9997318983078003, "text_region": [[780.0, 1033.0], [1298.0, 1031.0], [1298.0, 1054.0], [780.0, 1056.0]]}, {"text": "After having adjusted its weights, the model", "confidence": 0.9955154657363892, "text_region": [[781.0, 1065.0], [1322.0, 1065.0], [1322.0, 1088.0], [781.0, 1088.0]]}, {"text": "s now aligned with a user's end goal or.", "confidence": 0.9733282327651978, "text_region": [[780.0, 1097.0], [1266.0, 1097.0], [1266.0, 1120.0], [780.0, 1120.0]]}, {"text": "ntention. Now, when you ask it to classify.", "confidence": 0.9837851524353027, "text_region": [[780.0, 1130.0], [1286.0, 1130.0], [1286.0, 1154.0], [780.0, 1154.0]]}, {"text": " set of words by their sentiment, it'll do so", "confidence": 0.9959152936935425, "text_region": [[780.0, 1162.0], [1303.0, 1162.0], [1303.0, 1185.0], [780.0, 1185.0]]}, {"text": "perfectly!", "confidence": 0.9985550045967102, "text_region": [[779.0, 1193.0], [893.0, 1193.0], [893.0, 1217.0], [779.0, 1217.0]]}], "img_idx": 0}
{"type": "text", "bbox": [778, 1252, 1489, 2105], "res": [{"text": "In the third stage, the model is further", "confidence": 0.9867030382156372, "text_region": [[780.0, 1260.0], [1248.0, 1260.0], [1248.0, 1283.0], [780.0, 1283.0]]}, {"text": "mproved by supervised instruction fine-", "confidence": 0.9994001388549805, "text_region": [[781.0, 1292.0], [1279.0, 1292.0], [1279.0, 1316.0], [781.0, 1316.0]]}, {"text": "uning. This is possible by training the", "confidence": 0.9902579188346863, "text_region": [[781.0, 1325.0], [1241.0, 1325.0], [1241.0, 1349.0], [781.0, 1349.0]]}, {"text": "nodel on specific Iabeled datasets where.", "confidence": 0.9752591848373413, "text_region": [[781.0, 1357.0], [1298.0, 1357.0], [1298.0, 1379.0], [781.0, 1379.0]]}, {"text": "he model will update its weights to further", "confidence": 0.9974472522735596, "text_region": [[781.0, 1389.0], [1306.0, 1389.0], [1306.0, 1413.0], [781.0, 1413.0]]}, {"text": "educe the errors in its predictions/tasks", "confidence": 0.9998624920845032, "text_region": [[781.0, 1422.0], [1279.0, 1422.0], [1279.0, 1445.0], [781.0, 1445.0]]}, {"text": "After the model has been fine-tuned to", "confidence": 0.9991579651832581, "text_region": [[780.0, 1452.0], [1263.0, 1453.0], [1263.0, 1476.0], [780.0, 1475.0]]}, {"text": " specific domain, to refine the model's", "confidence": 0.9919653534889221, "text_region": [[781.0, 1487.0], [1265.0, 1485.0], [1265.0, 1508.0], [781.0, 1510.0]]}, {"text": "output further, we can use a technique", "confidence": 0.9677531719207764, "text_region": [[782.0, 1520.0], [1258.0, 1520.0], [1258.0, 1542.0], [782.0, 1542.0]]}, {"text": "called Reinforcement Learning from Human.", "confidence": 0.9801239371299744, "text_region": [[780.0, 1550.0], [1321.0, 1552.0], [1321.0, 1575.0], [780.0, 1573.0]]}, {"text": "Feedback (RLHF). Based on how we rate", "confidence": 0.9616471529006958, "text_region": [[781.0, 1583.0], [1271.0, 1583.0], [1271.0, 1606.0], [781.0, 1606.0]]}, {"text": "the quality of the model output or ask it to", "confidence": 0.9860374331474304, "text_region": [[781.0, 1616.0], [1298.0, 1616.0], [1298.0, 1640.0], [781.0, 1640.0]]}, {"text": "modify the output, the model keeps trying", "confidence": 0.9867334365844727, "text_region": [[779.0, 1647.0], [1297.0, 1649.0], [1297.0, 1676.0], [779.0, 1674.0]]}, {"text": "o make its output better to match what.", "confidence": 0.9817714095115662, "text_region": [[781.0, 1682.0], [1277.0, 1681.0], [1277.0, 1702.0], [781.0, 1703.0]]}, {"text": "we need, somewhat like a reward system.", "confidence": 0.9771623611450195, "text_region": [[780.0, 1714.0], [1294.0, 1715.0], [1294.0, 1738.0], [780.0, 1737.0]]}, {"text": "f you use ChatGPT, Gemini, or any other", "confidence": 0.9894366264343262, "text_region": [[781.0, 1747.0], [1273.0, 1746.0], [1273.0, 1769.0], [781.0, 1770.0]]}, {"text": "Al chatbot, you'll sometimes be prompted", "confidence": 0.9982703328132629, "text_region": [[781.0, 1780.0], [1299.0, 1780.0], [1299.0, 1803.0], [781.0, 1803.0]]}, {"text": "o select between different generated", "confidence": 0.9991474151611328, "text_region": [[781.0, 1811.0], [1248.0, 1811.0], [1248.0, 1834.0], [781.0, 1834.0]]}, {"text": "responses or asked to rate a response after.", "confidence": 0.9796846508979797, "text_region": [[780.0, 1845.0], [1318.0, 1843.0], [1318.0, 1866.0], [780.0, 1868.0]]}, {"text": "t has been generated-a classic example", "confidence": 0.9895206093788147, "text_region": [[781.0, 1877.0], [1298.0, 1877.0], [1298.0, 1900.0], [781.0, 1900.0]]}, {"text": "of an interactive feedback mechanism in", "confidence": 0.9636027216911316, "text_region": [[782.0, 1911.0], [1288.0, 1911.0], [1288.0, 1930.0], [782.0, 1930.0]]}, {"text": "action.", "confidence": 0.9995657205581665, "text_region": [[778.0, 1941.0], [862.0, 1941.0], [862.0, 1965.0], [778.0, 1965.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9944215416908264, "text_region": [[1147.0, 2005.0], [1334.0, 2004.0], [1335.0, 2025.0], [1147.0, 2026.0]]}], "img_idx": 0}
{"type": "text", "bbox": [154, 1352, 712, 1741], "res": [{"text": "LLMs have been trained on a large corpus of", "confidence": 0.9667953848838806, "text_region": [[157.0, 1357.0], [701.0, 1359.0], [701.0, 1379.0], [157.0, 1377.0]]}, {"text": "ext data. Say, books, articles, conversations", "confidence": 0.9810028672218323, "text_region": [[158.0, 1392.0], [701.0, 1392.0], [701.0, 1412.0], [158.0, 1412.0]]}, {"text": "and more. And the total size of the training", "confidence": 0.9912851452827454, "text_region": [[156.0, 1420.0], [681.0, 1422.0], [681.0, 1446.0], [156.0, 1444.0]]}, {"text": "data runs into petabytes. In the first stage,", "confidence": 0.9997787475585938, "text_region": [[156.0, 1452.0], [677.0, 1455.0], [677.0, 1480.0], [156.0, 1477.0]]}, {"text": "there's unsupervised learning, where it.", "confidence": 0.9769344329833984, "text_region": [[157.0, 1487.0], [632.0, 1488.0], [632.0, 1509.0], [157.0, 1508.0]]}, {"text": "earns to identify patterns and relationships.", "confidence": 0.985869824886322, "text_region": [[157.0, 1520.0], [694.0, 1520.0], [694.0, 1543.0], [157.0, 1543.0]]}, {"text": "n the data it's being fed without any aid", "confidence": 0.9880667924880981, "text_region": [[157.0, 1552.0], [655.0, 1552.0], [655.0, 1575.0], [157.0, 1575.0]]}, {"text": "from Iabels. As of the first stage, there's no.", "confidence": 0.9762842059135437, "text_region": [[157.0, 1583.0], [685.0, 1585.0], [685.0, 1608.0], [157.0, 1606.0]]}, {"text": "alignment-i.e., the model doesn't output", "confidence": 0.9878913760185242, "text_region": [[158.0, 1617.0], [664.0, 1617.0], [664.0, 1641.0], [158.0, 1641.0]]}, {"text": "something you want it to. So when you ask,.", "confidence": 0.9868150949478149, "text_region": [[158.0, 1651.0], [686.0, 1651.0], [686.0, 1674.0], [158.0, 1674.0]]}, {"text": "'Hey, what's up?\" it'll probably reply with a", "confidence": 0.9970423579216003, "text_region": [[158.0, 1680.0], [674.0, 1681.0], [674.0, 1706.0], [158.0, 1705.0]]}, {"text": "'What's up, with you?\"..", "confidence": 0.9739548563957214, "text_region": [[157.0, 1712.0], [430.0, 1713.0], [430.0, 1737.0], [157.0, 1736.0]]}], "img_idx": 0}
{"type": "text", "bbox": [152, 930, 721, 1318], "res": [{"text": "Before we take a quick look at what LLMs are", "confidence": 0.9818783402442932, "text_region": [[156.0, 936.0], [708.0, 936.0], [708.0, 956.0], [156.0, 956.0]]}, {"text": "we'll quickly revisit the concept of foundation", "confidence": 0.9950781464576721, "text_region": [[155.0, 966.0], [712.0, 966.0], [712.0, 990.0], [155.0, 990.0]]}, {"text": "models. Foundation models are large-scale", "confidence": 0.9872359037399292, "text_region": [[156.0, 1000.0], [699.0, 1000.0], [699.0, 1023.0], [156.0, 1023.0]]}, {"text": "neural networks trained on vast amounts of", "confidence": 0.9869457483291626, "text_region": [[155.0, 1032.0], [697.0, 1031.0], [697.0, 1052.0], [155.0, 1053.0]]}, {"text": "data. These then serve as a foundation for", "confidence": 0.9854151606559753, "text_region": [[156.0, 1065.0], [680.0, 1065.0], [680.0, 1086.0], [156.0, 1086.0]]}, {"text": "numerous tasks and applications. As we saw", "confidence": 0.9876217842102051, "text_region": [[155.0, 1097.0], [711.0, 1098.0], [711.0, 1119.0], [155.0, 1118.0]]}, {"text": "above, GPT-3 is an example of a foundation", "confidence": 0.9951783418655396, "text_region": [[155.0, 1130.0], [699.0, 1130.0], [699.0, 1153.0], [155.0, 1153.0]]}, {"text": "model for natural language processing.", "confidence": 0.975573718547821, "text_region": [[154.0, 1160.0], [642.0, 1162.0], [642.0, 1187.0], [154.0, 1185.0]]}, {"text": "(NLP) tasks. With foundation models, you.", "confidence": 0.9741801023483276, "text_region": [[157.0, 1192.0], [660.0, 1194.0], [660.0, 1218.0], [157.0, 1216.0]]}, {"text": "no longer need to train a model whenever", "confidence": 0.9794706106185913, "text_region": [[155.0, 1227.0], [678.0, 1227.0], [678.0, 1250.0], [155.0, 1250.0]]}, {"text": "you have a new task. You'll o cessing, and.", "confidence": 0.9897121787071228, "text_region": [[155.0, 1259.0], [685.0, 1259.0], [685.0, 1284.0], [155.0, 1284.0]]}, {"text": "generating human-like text..", "confidence": 0.9886391758918762, "text_region": [[154.0, 1291.0], [501.0, 1290.0], [501.0, 1314.0], [154.0, 1315.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [119, 0, 723, 2105], "res": [{"text": "F", "confidence": 0.15893803536891937, "text_region": [[239.0, 152.0], [323.0, 145.0], [333.0, 273.0], [249.0, 280.0]]}, {"text": "", "confidence": 0.0, "text_region": [[278.0, 252.0], [310.0, 252.0], [310.0, 285.0], [278.0, 285.0]]}, {"text": "R", "confidence": 0.17123858630657196, "text_region": [[253.0, 265.0], [356.0, 265.0], [356.0, 390.0], [253.0, 390.0]]}, {"text": "L", "confidence": 0.33663031458854675, "text_region": [[677.0, 452.0], [713.0, 452.0], [713.0, 476.0], [677.0, 476.0]]}, {"text": "WHAT ARE LLMS, AND", "confidence": 0.9794082641601562, "text_region": [[157.0, 794.0], [717.0, 794.0], [717.0, 838.0], [157.0, 838.0]]}, {"text": "Before we take a quick look at what LLMs are,.", "confidence": 0.9774458408355713, "text_region": [[148.0, 930.0], [710.0, 932.0], [710.0, 960.0], [148.0, 958.0]]}, {"text": "we'll quickly revisit the concept of foundation", "confidence": 0.979350745677948, "text_region": [[153.0, 967.0], [713.0, 967.0], [713.0, 989.0], [153.0, 989.0]]}, {"text": "models. Foundation models are large-scale.", "confidence": 0.9846787452697754, "text_region": [[150.0, 998.0], [704.0, 998.0], [704.0, 1026.0], [150.0, 1026.0]]}, {"text": "neural networks trained on vast amounts of", "confidence": 0.989800751209259, "text_region": [[150.0, 1028.0], [700.0, 1028.0], [700.0, 1057.0], [150.0, 1057.0]]}, {"text": "data. These then serve as a foundation for", "confidence": 0.9972435832023621, "text_region": [[153.0, 1061.0], [683.0, 1061.0], [683.0, 1090.0], [153.0, 1090.0]]}, {"text": "numerous tasks and applications. As we saw.", "confidence": 0.9902470707893372, "text_region": [[150.0, 1094.0], [715.0, 1094.0], [715.0, 1123.0], [150.0, 1123.0]]}, {"text": "above, GPT-3 is an example of a foundation.", "confidence": 0.9625651240348816, "text_region": [[153.0, 1125.0], [700.0, 1125.0], [700.0, 1153.0], [153.0, 1153.0]]}, {"text": "model for natural language processing", "confidence": 0.9925985336303711, "text_region": [[151.0, 1158.0], [643.0, 1160.0], [643.0, 1188.0], [150.0, 1186.0]]}, {"text": "(NLP) tasks. With foundation models, you", "confidence": 0.9854081869125366, "text_region": [[151.0, 1188.0], [660.0, 1191.0], [660.0, 1221.0], [150.0, 1219.0]]}, {"text": "no longer need to train a model whenever", "confidence": 0.9876257181167603, "text_region": [[150.0, 1224.0], [679.0, 1224.0], [679.0, 1252.0], [150.0, 1252.0]]}, {"text": "you have a new task. You'll o cessing, and", "confidence": 0.9979448914527893, "text_region": [[151.0, 1254.0], [687.0, 1256.0], [687.0, 1287.0], [150.0, 1285.0]]}, {"text": "generating human-like text.", "confidence": 0.9919933080673218, "text_region": [[150.0, 1289.0], [505.0, 1287.0], [505.0, 1318.0], [151.0, 1320.0]]}, {"text": "LLMs have been trained on a large corpus of", "confidence": 0.9884493350982666, "text_region": [[148.0, 1351.0], [706.0, 1353.0], [706.0, 1384.0], [148.0, 1381.0]]}, {"text": "text data. Say, books, articles, conversations,.", "confidence": 0.9825407862663269, "text_region": [[148.0, 1386.0], [706.0, 1388.0], [706.0, 1417.0], [148.0, 1414.0]]}, {"text": "and more. And the total size of the training", "confidence": 0.9846006035804749, "text_region": [[148.0, 1414.0], [683.0, 1419.0], [683.0, 1449.0], [148.0, 1445.0]]}, {"text": "data runs into petabytes. In the first stage,", "confidence": 0.9933245182037354, "text_region": [[151.0, 1449.0], [681.0, 1452.0], [681.0, 1482.0], [150.0, 1480.0]]}, {"text": "there's unsupervised learning, where it", "confidence": 0.9828585982322693, "text_region": [[150.0, 1484.0], [639.0, 1484.0], [639.0, 1513.0], [150.0, 1513.0]]}, {"text": "learns to identify patterns and relationships", "confidence": 0.9984027147293091, "text_region": [[150.0, 1515.0], [696.0, 1515.0], [696.0, 1544.0], [150.0, 1544.0]]}, {"text": "in the data it's being fed without any aid", "confidence": 0.9937846660614014, "text_region": [[150.0, 1550.0], [656.0, 1550.0], [656.0, 1579.0], [150.0, 1579.0]]}, {"text": "from labels. As of the first stage, there's no", "confidence": 0.9976969361305237, "text_region": [[148.0, 1579.0], [689.0, 1581.0], [689.0, 1612.0], [148.0, 1609.0]]}, {"text": "alignment--i.e., the model doesn't output", "confidence": 0.9773430228233337, "text_region": [[153.0, 1614.0], [666.0, 1614.0], [666.0, 1642.0], [153.0, 1642.0]]}, {"text": "something you want it to. So when you ask,", "confidence": 0.9864370226860046, "text_region": [[150.0, 1647.0], [687.0, 1647.0], [687.0, 1675.0], [150.0, 1675.0]]}, {"text": "\"Hey, what's up?\" it'll probably reply with a", "confidence": 0.9762726426124573, "text_region": [[153.0, 1680.0], [677.0, 1680.0], [677.0, 1708.0], [153.0, 1708.0]]}, {"text": "\"What's up, with you?\"", "confidence": 0.9443662762641907, "text_region": [[151.0, 1708.0], [432.0, 1710.0], [431.0, 1741.0], [150.0, 1739.0]]}, {"text": "Galileo", "confidence": 0.9971453547477722, "text_region": [[245.0, 1998.0], [352.0, 1998.0], [352.0, 2033.0], [245.0, 2033.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [49, 0, 1438, 2085], "res": [{"text": "A", "confidence": 0.2895187437534332, "text_region": [[659.0, 319.0], [804.0, 319.0], [804.0, 454.0], [659.0, 454.0]]}, {"text": "J", "confidence": 0.0892176702618599, "text_region": [[681.0, 454.0], [776.0, 454.0], [776.0, 478.0], [681.0, 478.0]]}, {"text": "WHAT ARE LLMS, AND HOW DO THEY WORK?", "confidence": 0.9671030044555664, "text_region": [[158.0, 793.0], [1349.0, 793.0], [1349.0, 836.0], [158.0, 836.0]]}, {"text": "Before we take a quick look at what LLMs are,.", "confidence": 0.9873844385147095, "text_region": [[151.0, 932.0], [711.0, 932.0], [711.0, 960.0], [151.0, 960.0]]}, {"text": "In the second phase, there's supervised", "confidence": 0.9927729964256287, "text_region": [[774.0, 932.0], [1275.0, 932.0], [1275.0, 960.0], [774.0, 960.0]]}, {"text": "we'll quickly revisit the concept of foundation", "confidence": 0.9896479845046997, "text_region": [[151.0, 964.0], [713.0, 964.0], [713.0, 993.0], [151.0, 993.0]]}, {"text": "learning, where the model benefits from", "confidence": 0.9959805607795715, "text_region": [[776.0, 964.0], [1277.0, 964.0], [1277.0, 993.0], [776.0, 993.0]]}, {"text": "models. Foundation models are large-scale", "confidence": 0.9981359839439392, "text_region": [[151.0, 997.0], [700.0, 997.0], [700.0, 1025.0], [151.0, 1025.0]]}, {"text": "being trained with clear objectives, such as", "confidence": 0.9997804164886475, "text_region": [[776.0, 997.0], [1316.0, 997.0], [1316.0, 1025.0], [776.0, 1025.0]]}, {"text": "neural networks trained on vast amounts of", "confidence": 0.999780535697937, "text_region": [[151.0, 1029.0], [700.0, 1029.0], [700.0, 1058.0], [151.0, 1058.0]]}, {"text": "Ianguage translation or text classification.", "confidence": 0.9926105737686157, "text_region": [[776.0, 1029.0], [1299.0, 1029.0], [1299.0, 1058.0], [776.0, 1058.0]]}, {"text": "data. These then serve as a foundation for.", "confidence": 0.9894945025444031, "text_region": [[153.0, 1064.0], [678.0, 1064.0], [678.0, 1086.0], [153.0, 1086.0]]}, {"text": "After having adjusted its weights, the model", "confidence": 0.9987970590591431, "text_region": [[776.0, 1062.0], [1325.0, 1062.0], [1325.0, 1090.0], [776.0, 1090.0]]}, {"text": "numerous tasks and applications. As we saw.", "confidence": 0.9770892858505249, "text_region": [[151.0, 1095.0], [713.0, 1095.0], [713.0, 1123.0], [151.0, 1123.0]]}, {"text": "is now aligned with a user's end goal or", "confidence": 0.9998642206192017, "text_region": [[774.0, 1095.0], [1269.0, 1095.0], [1269.0, 1123.0], [774.0, 1123.0]]}, {"text": "above, GPT-3 is an example of a foundation", "confidence": 0.995299220085144, "text_region": [[151.0, 1127.0], [700.0, 1127.0], [700.0, 1155.0], [151.0, 1155.0]]}, {"text": "intention. Now, when you ask it to classify", "confidence": 0.9815698862075806, "text_region": [[774.0, 1127.0], [1286.0, 1127.0], [1286.0, 1155.0], [774.0, 1155.0]]}, {"text": "model for natural language processing", "confidence": 0.9960400462150574, "text_region": [[151.0, 1155.0], [644.0, 1158.0], [644.0, 1188.0], [151.0, 1186.0]]}, {"text": "a set of words by their sentiment, it'll do so", "confidence": 0.9989480376243591, "text_region": [[774.0, 1160.0], [1303.0, 1160.0], [1303.0, 1188.0], [774.0, 1188.0]]}, {"text": "(NLP) tasks. With foundation models, you", "confidence": 0.9902859926223755, "text_region": [[151.0, 1188.0], [661.0, 1190.0], [661.0, 1221.0], [151.0, 1218.0]]}, {"text": "perfectly!", "confidence": 0.9998839497566223, "text_region": [[774.0, 1192.0], [893.0, 1192.0], [893.0, 1216.0], [774.0, 1216.0]]}, {"text": "no longer need to train a model whenever", "confidence": 0.9862494468688965, "text_region": [[151.0, 1225.0], [676.0, 1225.0], [676.0, 1253.0], [151.0, 1253.0]]}, {"text": "you have a new task. You'll o cessing, and", "confidence": 0.996964693069458, "text_region": [[151.0, 1258.0], [687.0, 1258.0], [687.0, 1286.0], [151.0, 1286.0]]}, {"text": "In the third stage, the model is further", "confidence": 0.9989919662475586, "text_region": [[774.0, 1258.0], [1254.0, 1258.0], [1254.0, 1286.0], [774.0, 1286.0]]}, {"text": "generating human-like text..", "confidence": 0.9881870150566101, "text_region": [[151.0, 1290.0], [505.0, 1290.0], [505.0, 1318.0], [151.0, 1318.0]]}, {"text": "improved by supervised instruction fine-", "confidence": 0.9992833137512207, "text_region": [[776.0, 1290.0], [1275.0, 1290.0], [1275.0, 1318.0], [776.0, 1318.0]]}, {"text": "tuning. This is possible by training the", "confidence": 0.9913023114204407, "text_region": [[772.0, 1320.0], [1241.0, 1320.0], [1241.0, 1349.0], [772.0, 1349.0]]}, {"text": "LLMs have been trained on a large corpus of", "confidence": 0.9951404333114624, "text_region": [[151.0, 1355.0], [704.0, 1355.0], [704.0, 1383.0], [151.0, 1383.0]]}, {"text": "model on specific labeled datasets where", "confidence": 0.9771648645401001, "text_region": [[776.0, 1355.0], [1299.0, 1355.0], [1299.0, 1383.0], [776.0, 1383.0]]}, {"text": "text data. Say, books, articles, conversations", "confidence": 0.992807149887085, "text_region": [[151.0, 1388.0], [704.0, 1388.0], [704.0, 1416.0], [151.0, 1416.0]]}, {"text": "the model will update its weights to further", "confidence": 0.9961829781532288, "text_region": [[774.0, 1388.0], [1308.0, 1388.0], [1308.0, 1416.0], [774.0, 1416.0]]}, {"text": "and more. And the total size of the training", "confidence": 0.9806997776031494, "text_region": [[153.0, 1420.0], [683.0, 1420.0], [683.0, 1449.0], [153.0, 1449.0]]}, {"text": "reduce the errors in its predictions/tasks.", "confidence": 0.9907353520393372, "text_region": [[776.0, 1418.0], [1284.0, 1418.0], [1284.0, 1446.0], [776.0, 1446.0]]}, {"text": "data runs into petabytes. In the first stage,", "confidence": 0.9895792603492737, "text_region": [[151.0, 1449.0], [678.0, 1453.0], [678.0, 1483.0], [151.0, 1479.0]]}, {"text": "After the model has been fine-tuned to.", "confidence": 0.9924247860908508, "text_region": [[778.0, 1455.0], [1264.0, 1455.0], [1264.0, 1477.0], [778.0, 1477.0]]}, {"text": "there's unsupervised learning, where it", "confidence": 0.9984426498413086, "text_region": [[151.0, 1486.0], [635.0, 1486.0], [635.0, 1514.0], [151.0, 1514.0]]}, {"text": "a specific domain, to refine the model's.", "confidence": 0.9851818680763245, "text_region": [[774.0, 1486.0], [1264.0, 1486.0], [1264.0, 1507.0], [774.0, 1507.0]]}, {"text": "learns to identify patterns and relationships", "confidence": 0.9984708428382874, "text_region": [[151.0, 1518.0], [698.0, 1518.0], [698.0, 1546.0], [151.0, 1546.0]]}, {"text": "output further, we can use a technique", "confidence": 0.9995613098144531, "text_region": [[774.0, 1518.0], [1260.0, 1518.0], [1260.0, 1546.0], [774.0, 1546.0]]}, {"text": "in the data it's being fed without any aid", "confidence": 0.9850106835365295, "text_region": [[151.0, 1549.0], [657.0, 1549.0], [657.0, 1577.0], [151.0, 1577.0]]}, {"text": "called Reinforcement Learning from Human", "confidence": 0.9844917058944702, "text_region": [[774.0, 1549.0], [1321.0, 1549.0], [1321.0, 1577.0], [774.0, 1577.0]]}, {"text": "from labels. As of the first stage, there's no", "confidence": 0.9985236525535583, "text_region": [[149.0, 1579.0], [687.0, 1581.0], [687.0, 1612.0], [149.0, 1609.0]]}, {"text": "Feedback (RLHF). Based on how we rate", "confidence": 0.9879689812660217, "text_region": [[776.0, 1581.0], [1273.0, 1581.0], [1273.0, 1609.0], [776.0, 1609.0]]}, {"text": "alignment-i.e., the model doesn't output", "confidence": 0.984778106212616, "text_region": [[151.0, 1614.0], [668.0, 1614.0], [668.0, 1642.0], [151.0, 1642.0]]}, {"text": "the quality of the model output or ask it to", "confidence": 0.9866085648536682, "text_region": [[774.0, 1614.0], [1301.0, 1614.0], [1301.0, 1642.0], [774.0, 1642.0]]}, {"text": "something you want it to. So when you ask,", "confidence": 0.9974857568740845, "text_region": [[151.0, 1648.0], [687.0, 1648.0], [687.0, 1677.0], [151.0, 1677.0]]}, {"text": "modify the output, the model keeps trying", "confidence": 0.999755322933197, "text_region": [[774.0, 1646.0], [1299.0, 1648.0], [1299.0, 1677.0], [774.0, 1674.0]]}, {"text": "\"Hey, what's up?\" it'll probably reply with a", "confidence": 0.9881440997123718, "text_region": [[151.0, 1677.0], [676.0, 1679.0], [676.0, 1709.0], [151.0, 1707.0]]}, {"text": "to make its output better to match what", "confidence": 0.987163245677948, "text_region": [[774.0, 1679.0], [1280.0, 1679.0], [1280.0, 1707.0], [774.0, 1707.0]]}, {"text": "\"What's up, with you?\".", "confidence": 0.9683104157447815, "text_region": [[149.0, 1709.0], [433.0, 1712.0], [433.0, 1742.0], [149.0, 1740.0]]}, {"text": "we need, somewhat like a reward system.", "confidence": 0.9974648952484131, "text_region": [[776.0, 1711.0], [1295.0, 1711.0], [1295.0, 1740.0], [776.0, 1740.0]]}, {"text": "If you use ChatGPT, Gemini, or any other", "confidence": 0.9912856817245483, "text_region": [[776.0, 1744.0], [1277.0, 1744.0], [1277.0, 1772.0], [776.0, 1772.0]]}, {"text": "Al chatbot, you'll sometimes be prompted", "confidence": 0.9981808662414551, "text_region": [[776.0, 1777.0], [1301.0, 1777.0], [1301.0, 1805.0], [776.0, 1805.0]]}, {"text": "to select between different generated", "confidence": 0.9996729493141174, "text_region": [[774.0, 1809.0], [1249.0, 1809.0], [1249.0, 1837.0], [774.0, 1837.0]]}, {"text": "responses or asked to rate a response after", "confidence": 0.9908594489097595, "text_region": [[776.0, 1842.0], [1319.0, 1842.0], [1319.0, 1870.0], [776.0, 1870.0]]}, {"text": "it has been generated-a classic example", "confidence": 0.9879242181777954, "text_region": [[774.0, 1874.0], [1301.0, 1874.0], [1301.0, 1903.0], [774.0, 1903.0]]}, {"text": "of an interactive feedback mechanism in", "confidence": 0.9988747835159302, "text_region": [[774.0, 1907.0], [1293.0, 1907.0], [1293.0, 1935.0], [774.0, 1935.0]]}, {"text": "action.", "confidence": 0.9998798370361328, "text_region": [[774.0, 1942.0], [861.0, 1942.0], [861.0, 1966.0], [774.0, 1966.0]]}, {"text": "Galileo", "confidence": 0.9922691583633423, "text_region": [[244.0, 1998.0], [349.0, 1998.0], [349.0, 2031.0], [244.0, 2031.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9688573479652405, "text_region": [[1145.0, 2000.0], [1338.0, 2000.0], [1338.0, 2029.0], [1145.0, 2029.0]]}], "img_idx": 0}
