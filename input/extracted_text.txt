{"type": "figure", "bbox": [0, 0, 1489, 2103], "res": [{"text": "Galileo", "confidence": 0.9995823502540588, "text_region": [[208.0, 153.0], [308.0, 153.0], [308.0, 184.0], [208.0, 184.0]]}, {"text": "Mastering", "confidence": 0.9999220371246338, "text_region": [[159.0, 1617.0], [1014.0, 1649.0], [1009.0, 1800.0], [153.0, 1768.0]]}, {"text": "RAG", "confidence": 0.9995770454406738, "text_region": [[153.0, 1796.0], [514.0, 1796.0], [514.0, 1950.0], [153.0, 1950.0]]}, {"text": "A comprehensive guide for building", "confidence": 0.974205493927002, "text_region": [[589.0, 1851.0], [1230.0, 1851.0], [1230.0, 1888.0], [589.0, 1888.0]]}, {"text": "enterprise-grade RAG systems", "confidence": 0.9843772053718567, "text_region": [[587.0, 1899.0], [1148.0, 1899.0], [1148.0, 1937.0], [587.0, 1937.0]]}], "img_idx": 0}

{"type": "text", "bbox": [198, 1016, 1290, 1243], "res": [{"text": "s begin by looking at Fig 1.3 to understand the workings of a simple RAG system. In the fir", "confidence": 0.9846304655075073, "text_region": [[199.0, 1022.0], [1285.0, 1021.0], [1285.0, 1044.0], [199.0, 1046.0]]}, {"text": "o, there's an encoder that converts your raw text and documents into mathematical forr", "confidence": 0.9890022873878479, "text_region": [[199.0, 1055.0], [1288.0, 1054.0], [1288.0, 1077.0], [199.0, 1079.0]]}, {"text": "he computer can understand them. So, all the words, sentences, or entire documents th", "confidence": 0.986882746219635, "text_region": [[200.0, 1087.0], [1287.0, 1085.0], [1287.0, 1108.0], [200.0, 1111.0]]}, {"text": "ke up your external database are converted into \"vectors.\" All these vectors (in the form.", "confidence": 0.9869605898857117, "text_region": [[199.0, 1119.0], [1283.0, 1116.0], [1283.0, 1144.0], [199.0, 1146.0]]}, {"text": "tor embeddings) will now be stored in a vector database. Note that this is a great way o.", "confidence": 0.9828279614448547, "text_region": [[198.0, 1148.0], [1288.0, 1151.0], [1288.0, 1178.0], [198.0, 1176.0]]}, {"text": "turing the semantics of different words, their relationship to other words, and what topic.", "confidence": 0.9913866519927979, "text_region": [[198.0, 1182.0], [1287.0, 1183.0], [1287.0, 1210.0], [198.0, 1209.0]]}, {"text": "se words represent.", "confidence": 0.994583010673523, "text_region": [[200.0, 1216.0], [437.0, 1216.0], [437.0, 1239.0], [200.0, 1239.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [150, 0, 1337, 932], "res": [{"text": "10", "confidence": 0.9987791776657104, "text_region": [[1310.0, 118.0], [1335.0, 118.0], [1335.0, 138.0], [1310.0, 138.0]]}, {"text": "HOW DO RAGs WORK?", "confidence": 0.9940603971481323, "text_region": [[156.0, 206.0], [759.0, 204.0], [760.0, 241.0], [156.0, 244.0]]}, {"text": "How RAG Works", "confidence": 0.9277275800704956, "text_region": [[621.0, 343.0], [868.0, 343.0], [868.0, 369.0], [621.0, 369.0]]}, {"text": "Encoder", "confidence": 0.9981117248535156, "text_region": [[479.0, 436.0], [543.0, 436.0], [543.0, 453.0], [479.0, 453.0]]}, {"text": "Vector Database", "confidence": 0.9776535630226135, "text_region": [[646.0, 436.0], [772.0, 436.0], [772.0, 453.0], [646.0, 453.0]]}, {"text": "Search", "confidence": 0.9973707795143127, "text_region": [[292.0, 590.0], [358.0, 590.0], [358.0, 612.0], [292.0, 612.0]]}, {"text": "Query", "confidence": 0.9981769323348999, "text_region": [[482.0, 588.0], [543.0, 593.0], [541.0, 613.0], [481.0, 609.0]]}, {"text": "Question +Context", "confidence": 0.9701905846595764, "text_region": [[648.0, 591.0], [795.0, 591.0], [795.0, 608.0], [648.0, 608.0]]}, {"text": "LLM", "confidence": 0.9971649646759033, "text_region": [[913.0, 591.0], [952.0, 591.0], [952.0, 609.0], [913.0, 609.0]]}, {"text": "Answer", "confidence": 0.9985876083374023, "text_region": [[1095.0, 590.0], [1156.0, 590.0], [1156.0, 607.0], [1095.0, 607.0]]}, {"text": "\"The population of Paris", "confidence": 0.9442529678344727, "text_region": [[1024.0, 691.0], [1229.0, 691.0], [1229.0, 711.0], [1024.0, 711.0]]}, {"text": "France,according to the", "confidence": 0.9681298732757568, "text_region": [[1023.0, 711.0], [1232.0, 712.0], [1232.0, 733.0], [1023.0, 732.0]]}, {"text": "most recent census", "confidence": 0.9733763933181763, "text_region": [[1024.0, 737.0], [1192.0, 737.0], [1192.0, 754.0], [1024.0, 754.0]]}, {"text": "\"What is the population", "confidence": 0.9654225707054138, "text_region": [[412.0, 755.0], [609.0, 756.0], [609.0, 777.0], [412.0, 775.0]]}, {"text": "report,is approximately", "confidence": 0.9878607988357544, "text_region": [[1024.0, 758.0], [1223.0, 758.0], [1223.0, 775.0], [1024.0, 775.0]]}, {"text": "of Paris,France?\"", "confidence": 0.9149518609046936, "text_region": [[412.0, 778.0], [561.0, 778.0], [561.0, 799.0], [412.0, 799.0]]}, {"text": "2.2million people.\"", "confidence": 0.9616719484329224, "text_region": [[1023.0, 777.0], [1184.0, 778.0], [1184.0, 799.0], [1023.0, 797.0]]}, {"text": "Galileo", "confidence": 0.9941333532333374, "text_region": [[736.0, 877.0], [790.0, 877.0], [790.0, 896.0], [736.0, 896.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [145, 0, 1353, 2081], "res": [{"text": "10", "confidence": 0.9994739294052124, "text_region": [[1306.0, 113.0], [1337.0, 113.0], [1337.0, 141.0], [1306.0, 141.0]]}, {"text": "HOW DO RAGs WORK?", "confidence": 0.9966054558753967, "text_region": [[156.0, 202.0], [760.0, 202.0], [760.0, 245.0], [156.0, 245.0]]}, {"text": "How RAG Works", "confidence": 0.9245285391807556, "text_region": [[618.0, 340.0], [871.0, 340.0], [871.0, 371.0], [618.0, 371.0]]}, {"text": "Encoder", "confidence": 0.9982291460037231, "text_region": [[478.0, 431.0], [545.0, 431.0], [545.0, 455.0], [478.0, 455.0]]}, {"text": "Vector Database", "confidence": 0.9839468598365784, "text_region": [[642.0, 429.0], [776.0, 429.0], [776.0, 460.0], [642.0, 460.0]]}, {"text": "Search", "confidence": 0.9785647392272949, "text_region": [[287.0, 585.0], [363.0, 585.0], [363.0, 616.0], [287.0, 616.0]]}, {"text": "Query", "confidence": 0.9978501200675964, "text_region": [[483.0, 587.0], [545.0, 587.0], [545.0, 616.0], [483.0, 616.0]]}, {"text": "Question +Context", "confidence": 0.9670178890228271, "text_region": [[645.0, 587.0], [796.0, 587.0], [796.0, 609.0], [645.0, 609.0]]}, {"text": "LLM", "confidence": 0.9942811131477356, "text_region": [[911.0, 585.0], [956.0, 585.0], [956.0, 611.0], [911.0, 611.0]]}, {"text": "Answer", "confidence": 0.9978953003883362, "text_region": [[1089.0, 583.0], [1160.0, 583.0], [1160.0, 613.0], [1089.0, 613.0]]}, {"text": "\"The population of Paris", "confidence": 0.9497013092041016, "text_region": [[1024.0, 689.0], [1229.0, 689.0], [1229.0, 711.0], [1024.0, 711.0]]}, {"text": "France,according to the", "confidence": 0.9707382917404175, "text_region": [[1022.0, 711.0], [1233.0, 711.0], [1233.0, 733.0], [1022.0, 733.0]]}, {"text": "most recent census", "confidence": 0.9651232957839966, "text_region": [[1022.0, 733.0], [1188.0, 730.0], [1189.0, 754.0], [1022.0, 757.0]]}, {"text": "\"What is the population", "confidence": 0.9385480284690857, "text_region": [[411.0, 750.0], [611.0, 750.0], [611.0, 778.0], [411.0, 778.0]]}, {"text": "ortis approximately", "confidence": 0.9262799620628357, "text_region": [[1053.0, 748.0], [1227.0, 750.0], [1226.0, 781.0], [1053.0, 778.0]]}, {"text": "repo", "confidence": 0.9928942918777466, "text_region": [[1029.0, 759.0], [1062.0, 759.0], [1062.0, 774.0], [1029.0, 774.0]]}, {"text": "of ParisFrance", "confidence": 0.9544867873191833, "text_region": [[409.0, 776.0], [560.0, 774.0], [560.0, 798.0], [409.0, 800.0]]}, {"text": "2.2 million people.", "confidence": 0.930167019367218, "text_region": [[1024.0, 776.0], [1184.0, 776.0], [1184.0, 800.0], [1024.0, 800.0]]}, {"text": "Galileo", "confidence": 0.9713816046714783, "text_region": [[707.0, 871.0], [791.0, 871.0], [791.0, 895.0], [707.0, 895.0]]}, {"text": "Fig 1.3: How RAG works.", "confidence": 0.974275529384613, "text_region": [[611.0, 954.0], [869.0, 954.0], [869.0, 982.0], [611.0, 982.0]]}, {"text": "Let's begin by looking at Fig 1.3 to understand the workings of a simple RAG system. In the first", "confidence": 0.9816445708274841, "text_region": [[149.0, 1019.0], [1313.0, 1019.0], [1313.0, 1047.0], [149.0, 1047.0]]}, {"text": "step, there's an encoder that converts your raw text and documents into mathematical form,.", "confidence": 0.9901759624481201, "text_region": [[149.0, 1049.0], [1313.0, 1051.0], [1313.0, 1082.0], [149.0, 1080.0]]}, {"text": "so the computer can understand them. So, all the words, sentences, or entire documents that", "confidence": 0.993153989315033, "text_region": [[149.0, 1084.0], [1317.0, 1084.0], [1317.0, 1112.0], [149.0, 1112.0]]}, {"text": "make up your external database are converted into \"vectors.\" All these vectors (in the form of", "confidence": 0.9956842064857483, "text_region": [[149.0, 1116.0], [1317.0, 1116.0], [1317.0, 1145.0], [149.0, 1145.0]]}, {"text": "vector embeddings) will now be stored in a vector database. Note that this is a great way of", "confidence": 0.9993659257888794, "text_region": [[149.0, 1149.0], [1300.0, 1149.0], [1300.0, 1177.0], [149.0, 1177.0]]}, {"text": "capturing the semantics of different words, their relationship to other words, and what topics", "confidence": 0.9971374273300171, "text_region": [[152.0, 1181.0], [1309.0, 1181.0], [1309.0, 1210.0], [152.0, 1210.0]]}, {"text": "these words represent..", "confidence": 0.9852778315544128, "text_region": [[147.0, 1212.0], [436.0, 1214.0], [436.0, 1242.0], [147.0, 1240.0]]}, {"text": "Learn more", "confidence": 0.9875062108039856, "text_region": [[323.0, 1355.0], [511.0, 1355.0], [511.0, 1383.0], [323.0, 1383.0]]}, {"text": "It's not possible to convert the vector embeddings back to the text. Remember.", "confidence": 0.9935386776924133, "text_region": [[196.0, 1431.0], [1191.0, 1431.0], [1191.0, 1459.0], [196.0, 1459.0]]}, {"text": "that this isn't a 1:1 mapping of text to vector. This is because the text undergoes a.", "confidence": 0.9865899085998535, "text_region": [[196.0, 1463.0], [1220.0, 1463.0], [1220.0, 1494.0], [196.0, 1494.0]]}, {"text": "dimensionality reduction, and only the essential features are retained. Consequently,.", "confidence": 0.9942726492881775, "text_region": [[196.0, 1496.0], [1280.0, 1496.0], [1280.0, 1524.0], [196.0, 1524.0]]}, {"text": "many words, sentences, and texts will have similar vector embeddings, and this helps", "confidence": 0.9916934967041016, "text_region": [[194.0, 1528.0], [1289.0, 1528.0], [1289.0, 1556.0], [194.0, 1556.0]]}, {"text": "determine their similarity or cluster them together. You'll see how the idea will form.", "confidence": 0.9915381073951721, "text_region": [[196.0, 1561.0], [1253.0, 1561.0], [1253.0, 1589.0], [196.0, 1589.0]]}, {"text": "the crux of the RAG system further down. So, each time you store a vector embedding.", "confidence": 0.9951595067977905, "text_region": [[192.0, 1591.0], [1280.0, 1593.0], [1280.0, 1624.0], [192.0, 1621.0]]}, {"text": "to the vector database, you'll also store a reference to the actual document in the", "confidence": 0.9872401356697083, "text_region": [[194.0, 1624.0], [1231.0, 1624.0], [1231.0, 1652.0], [194.0, 1652.0]]}, {"text": "form of a URL or maybe a document ID..", "confidence": 0.9812623262405396, "text_region": [[196.0, 1658.0], [691.0, 1658.0], [691.0, 1686.0], [196.0, 1686.0]]}, {"text": "In the first step, you'll ask, \"What is the population of Paris, France?\" Ideally, a model with an", "confidence": 0.9908670783042908, "text_region": [[152.0, 1795.0], [1286.0, 1795.0], [1286.0, 1823.0], [152.0, 1823.0]]}, {"text": "older training cutoff date and no recent source to refer to will give an outdated answer. In this.", "confidence": 0.9938154220581055, "text_region": [[152.0, 1827.0], [1320.0, 1827.0], [1320.0, 1856.0], [152.0, 1856.0]]}, {"text": "case, your prompt is first encoded using the same model that was used to create the vector", "confidence": 0.9918725490570068, "text_region": [[152.0, 1862.0], [1302.0, 1862.0], [1302.0, 1884.0], [152.0, 1884.0]]}, {"text": "embeddings for the external source (and stored in the vector database). So, the output would", "confidence": 0.9923939108848572, "text_region": [[152.0, 1892.0], [1326.0, 1892.0], [1326.0, 1921.0], [152.0, 1921.0]]}, {"text": "be a vector that'll represent your query..", "confidence": 0.9854890704154968, "text_region": [[147.0, 1925.0], [645.0, 1925.0], [645.0, 1953.0], [147.0, 1953.0]]}, {"text": "Galileo", "confidence": 0.9935593008995056, "text_region": [[245.0, 1999.0], [349.0, 1999.0], [349.0, 2031.0], [245.0, 2031.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9901229739189148, "text_region": [[1146.0, 2003.0], [1344.0, 2003.0], [1344.0, 2031.0], [1146.0, 2031.0]]}], "img_idx": 0}

{"type": "text", "bbox": [153, 186, 715, 512], "res": [{"text": "Now, the query vector needs to be matched", "confidence": 0.9993650913238525, "text_region": [[155.0, 192.0], [699.0, 191.0], [699.0, 216.0], [155.0, 217.0]]}, {"text": "against the vector database to find the.", "confidence": 0.9892735481262207, "text_region": [[157.0, 226.0], [642.0, 223.0], [642.0, 246.0], [157.0, 249.0]]}, {"text": "most similar document vectors. Say, top five.", "confidence": 0.9894887208938599, "text_region": [[156.0, 257.0], [705.0, 258.0], [705.0, 280.0], [156.0, 279.0]]}, {"text": "We're hoping that these top 5 vectors will", "confidence": 0.9781000018119812, "text_region": [[156.0, 290.0], [667.0, 290.0], [667.0, 313.0], [156.0, 313.0]]}, {"text": "nave some additional information similar to", "confidence": 0.9619850516319275, "text_region": [[157.0, 324.0], [698.0, 324.0], [698.0, 344.0], [157.0, 344.0]]}, {"text": "the query. So, now you have the documents", "confidence": 0.9885875582695007, "text_region": [[156.0, 355.0], [697.0, 355.0], [697.0, 379.0], [156.0, 379.0]]}, {"text": "retrieved with the help of indexes that.", "confidence": 0.9614788889884949, "text_region": [[158.0, 389.0], [633.0, 389.0], [633.0, 409.0], [158.0, 409.0]]}, {"text": "connect the vector embedding with the.", "confidence": 0.9738913178443909, "text_region": [[157.0, 421.0], [646.0, 421.0], [646.0, 442.0], [157.0, 442.0]]}, {"text": "original text/document) contextually.", "confidence": 0.989395260810852, "text_region": [[155.0, 450.0], [612.0, 451.0], [612.0, 478.0], [155.0, 477.0]]}, {"text": "relevant to the query..", "confidence": 0.9840058088302612, "text_region": [[157.0, 483.0], [417.0, 487.0], [417.0, 508.0], [157.0, 505.0]]}], "img_idx": 0}
{"type": "text", "bbox": [775, 186, 1318, 414], "res": [{"text": "Once trained on proprietary data, RAG", "confidence": 0.9872295260429382, "text_region": [[778.0, 193.0], [1252.0, 193.0], [1252.0, 217.0], [778.0, 217.0]]}, {"text": "systems can function as customer support", "confidence": 0.9978944063186646, "text_region": [[778.0, 224.0], [1311.0, 225.0], [1311.0, 249.0], [778.0, 248.0]]}, {"text": "chatbots, pulling information from the", "confidence": 0.9983500242233276, "text_region": [[778.0, 258.0], [1249.0, 258.0], [1249.0, 282.0], [778.0, 282.0]]}, {"text": "company's internal database, such as a", "confidence": 0.9732437133789062, "text_region": [[778.0, 291.0], [1277.0, 290.0], [1277.0, 311.0], [778.0, 312.0]]}, {"text": "ong set of FAQs, technical documentation", "confidence": 0.9849403500556946, "text_region": [[780.0, 324.0], [1306.0, 324.0], [1306.0, 345.0], [780.0, 345.0]]}, {"text": "and policies, which the LLM can use to", "confidence": 0.9676346182823181, "text_region": [[780.0, 356.0], [1246.0, 356.0], [1246.0, 376.0], [780.0, 376.0]]}, {"text": "auqment and improve its response", "confidence": 0.9689923524856567, "text_region": [[779.0, 389.0], [1218.0, 389.0], [1218.0, 409.0], [779.0, 409.0]]}], "img_idx": 0}
{"type": "text", "bbox": [153, 541, 715, 1065], "res": [{"text": "In the third step, the query and the retrieved", "confidence": 0.9861230254173279, "text_region": [[156.0, 549.0], [699.0, 549.0], [699.0, 573.0], [156.0, 573.0]]}, {"text": "components are combined to create d", "confidence": 0.979783833026886, "text_region": [[156.0, 584.0], [639.0, 582.0], [639.0, 603.0], [156.0, 606.0]]}, {"text": "oetter context for the model to understand.", "confidence": 0.9876963496208191, "text_region": [[158.0, 616.0], [691.0, 616.0], [691.0, 636.0], [158.0, 636.0]]}, {"text": "The retrieved component may be a short", "confidence": 0.9992143511772156, "text_region": [[155.0, 647.0], [666.0, 647.0], [666.0, 671.0], [155.0, 671.0]]}, {"text": "summary or perhaps some key facts from", "confidence": 0.9913634061813354, "text_region": [[155.0, 681.0], [678.0, 679.0], [678.0, 703.0], [155.0, 705.0]]}, {"text": "the top 5 matching documents or the entire", "confidence": 0.9777047038078308, "text_region": [[155.0, 711.0], [699.0, 712.0], [699.0, 736.0], [155.0, 735.0]]}, {"text": "content itself. The LLM, in this case, be it a", "confidence": 0.9856700301170349, "text_region": [[157.0, 746.0], [661.0, 746.0], [661.0, 766.0], [157.0, 766.0]]}, {"text": "foundation model or a fine-tuned version,", "confidence": 0.9963769912719727, "text_region": [[156.0, 776.0], [673.0, 778.0], [673.0, 800.0], [156.0, 798.0]]}, {"text": "then uses the prompt/query + retrieved", "confidence": 0.9983099699020386, "text_region": [[156.0, 810.0], [648.0, 810.0], [648.0, 834.0], [156.0, 834.0]]}, {"text": "component to generate an answer: \"The", "confidence": 0.9823416471481323, "text_region": [[156.0, 844.0], [654.0, 843.0], [655.0, 864.0], [156.0, 865.0]]}, {"text": "oopulation of Paris, France, according to the", "confidence": 0.9768467545509338, "text_region": [[156.0, 876.0], [706.0, 874.0], [706.0, 897.0], [156.0, 899.0]]}, {"text": "most recent census report, is approximately", "confidence": 0.9998819828033447, "text_region": [[155.0, 907.0], [702.0, 907.0], [702.0, 931.0], [155.0, 931.0]]}, {"text": "2.2 million people.\" You'll also be able to.", "confidence": 0.9776269793510437, "text_region": [[155.0, 938.0], [649.0, 939.0], [649.0, 964.0], [155.0, 963.0]]}, {"text": "access the source, which may appear as", "confidence": 0.9969325065612793, "text_region": [[156.0, 972.0], [664.0, 975.0], [664.0, 996.0], [156.0, 993.0]]}, {"text": "a link in the LLM response, to verify that the", "confidence": 0.9897294044494629, "text_region": [[156.0, 1005.0], [680.0, 1006.0], [680.0, 1027.0], [156.0, 1026.0]]}, {"text": "information is accurate.", "confidence": 0.9856474995613098, "text_region": [[156.0, 1036.0], [448.0, 1038.0], [448.0, 1059.0], [156.0, 1057.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [0, 149, 1474, 2105], "res": [{"text": "Now, the query vector needs to be matched", "confidence": 0.9985751509666443, "text_region": [[152.0, 190.0], [701.0, 190.0], [701.0, 216.0], [152.0, 216.0]]}, {"text": "Once trained on proprietary data, RAG", "confidence": 0.9990710616111755, "text_region": [[775.0, 190.0], [1254.0, 190.0], [1254.0, 216.0], [775.0, 216.0]]}, {"text": "against the vector database to find the", "confidence": 0.9885244369506836, "text_region": [[150.0, 222.0], [645.0, 220.0], [645.0, 249.0], [150.0, 251.0]]}, {"text": "systems can function as customer support", "confidence": 0.999498724937439, "text_region": [[775.0, 222.0], [1312.0, 222.0], [1312.0, 249.0], [775.0, 249.0]]}, {"text": "most similar document vectors. Say, top five.", "confidence": 0.9939972758293152, "text_region": [[152.0, 255.0], [707.0, 255.0], [707.0, 283.0], [152.0, 283.0]]}, {"text": "chatbots, pulling information from the", "confidence": 0.9921323657035828, "text_region": [[775.0, 255.0], [1252.0, 255.0], [1252.0, 281.0], [775.0, 281.0]]}, {"text": "We're hoping that these top 5 vectors will", "confidence": 0.9880889654159546, "text_region": [[152.0, 286.0], [667.0, 286.0], [667.0, 312.0], [152.0, 312.0]]}, {"text": "company's internal database, such as a", "confidence": 0.9990668296813965, "text_region": [[773.0, 288.0], [1278.0, 285.0], [1278.0, 314.0], [773.0, 316.0]]}, {"text": "have some additional information similar to", "confidence": 0.989696741104126, "text_region": [[152.0, 320.0], [701.0, 320.0], [701.0, 347.0], [152.0, 347.0]]}, {"text": "long set of FAQs, technical documentation,", "confidence": 0.9809793829917908, "text_region": [[777.0, 318.0], [1308.0, 318.0], [1308.0, 347.0], [777.0, 347.0]]}, {"text": "the query. So, now you have the documents", "confidence": 0.9983901977539062, "text_region": [[152.0, 353.0], [699.0, 353.0], [699.0, 379.0], [152.0, 379.0]]}, {"text": "and policies, which the LLM can use to", "confidence": 0.9926849007606506, "text_region": [[775.0, 353.0], [1250.0, 353.0], [1250.0, 379.0], [775.0, 379.0]]}, {"text": "(retrieved with the help of indexes that", "confidence": 0.9828611612319946, "text_region": [[152.0, 385.0], [633.0, 385.0], [633.0, 412.0], [152.0, 412.0]]}, {"text": "augment and improve its response.", "confidence": 0.9986422061920166, "text_region": [[775.0, 387.0], [1220.0, 387.0], [1220.0, 414.0], [775.0, 414.0]]}, {"text": "connect the vector embedding with the", "confidence": 0.9997188448905945, "text_region": [[152.0, 418.0], [649.0, 418.0], [649.0, 444.0], [152.0, 444.0]]}, {"text": "original text/document) contextually", "confidence": 0.9994180202484131, "text_region": [[154.0, 451.0], [611.0, 451.0], [611.0, 477.0], [154.0, 477.0]]}, {"text": "relevant to the query.", "confidence": 0.9847497940063477, "text_region": [[148.0, 479.0], [421.0, 483.0], [420.0, 512.0], [148.0, 507.0]]}, {"text": "In the third step, the query and the retrieved", "confidence": 0.9959467053413391, "text_region": [[148.0, 546.0], [701.0, 544.0], [701.0, 573.0], [148.0, 575.0]]}, {"text": "components are combined to create a", "confidence": 0.9979363679885864, "text_region": [[150.0, 581.0], [641.0, 581.0], [641.0, 607.0], [150.0, 607.0]]}, {"text": "better context for the model to understand.", "confidence": 0.9998554587364197, "text_region": [[152.0, 612.0], [691.0, 612.0], [691.0, 638.0], [152.0, 638.0]]}, {"text": "The retrieved component may be a short", "confidence": 0.9953382611274719, "text_region": [[154.0, 646.0], [667.0, 646.0], [667.0, 673.0], [154.0, 673.0]]}, {"text": "summary or perhaps some key facts from", "confidence": 0.9873661398887634, "text_region": [[152.0, 679.0], [681.0, 679.0], [681.0, 705.0], [152.0, 705.0]]}, {"text": "the top 5 matching documents or the entire", "confidence": 0.9915693998336792, "text_region": [[152.0, 711.0], [701.0, 711.0], [701.0, 738.0], [152.0, 738.0]]}, {"text": "content itself. The LLM, in this case, be it a", "confidence": 0.9965347647666931, "text_region": [[152.0, 740.0], [663.0, 740.0], [663.0, 766.0], [152.0, 766.0]]}, {"text": "foundation model or a fine-tuned version,", "confidence": 0.9954137206077576, "text_region": [[150.0, 772.0], [675.0, 777.0], [675.0, 803.0], [150.0, 799.0]]}, {"text": "then uses the prompt/query + retrieved", "confidence": 0.9946811199188232, "text_region": [[152.0, 807.0], [649.0, 807.0], [649.0, 836.0], [152.0, 836.0]]}, {"text": "component to generate an answer: \"The", "confidence": 0.9991929531097412, "text_region": [[152.0, 840.0], [657.0, 838.0], [657.0, 866.0], [152.0, 868.0]]}, {"text": "population of Paris, France, according to the", "confidence": 0.9981026649475098, "text_region": [[150.0, 872.0], [707.0, 870.0], [707.0, 899.0], [150.0, 901.0]]}, {"text": "most recent census report, is approximately", "confidence": 0.9905715584754944, "text_region": [[152.0, 907.0], [705.0, 907.0], [705.0, 933.0], [152.0, 933.0]]}, {"text": "2.2 million people.\" You'll also be able to", "confidence": 0.991269052028656, "text_region": [[152.0, 938.0], [649.0, 938.0], [649.0, 966.0], [152.0, 966.0]]}, {"text": "access the source, which may appear as", "confidence": 0.9995693564414978, "text_region": [[154.0, 972.0], [667.0, 972.0], [667.0, 999.0], [154.0, 999.0]]}, {"text": "a link in the LLM response, to verify that the", "confidence": 0.9920200109481812, "text_region": [[154.0, 1003.0], [683.0, 1003.0], [683.0, 1031.0], [154.0, 1031.0]]}, {"text": "information is accurate.", "confidence": 0.9996973872184753, "text_region": [[150.0, 1035.0], [453.0, 1035.0], [453.0, 1062.0], [150.0, 1062.0]]}, {"text": "Galileo", "confidence": 0.9902327656745911, "text_region": [[243.0, 1990.0], [353.0, 1995.0], [351.0, 2032.0], [242.0, 2027.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9993236660957336, "text_region": [[1146.0, 2001.0], [1338.0, 2001.0], [1338.0, 2028.0], [1146.0, 2028.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [1, 1246, 1466, 2105], "res": [{"text": "101", "confidence": 0.9885270595550537, "text_region": [[824.0, 1268.0], [849.0, 1263.0], [852.0, 1279.0], [827.0, 1284.0]]}, {"text": "101010101010001", "confidence": 0.9994840025901794, "text_region": [[705.0, 1362.0], [847.0, 1283.0], [859.0, 1303.0], [717.0, 1382.0]]}, {"text": "Galileo", "confidence": 0.9957236647605896, "text_region": [[248.0, 1994.0], [352.0, 1998.0], [351.0, 2031.0], [246.0, 2027.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9989702701568604, "text_region": [[1147.0, 2005.0], [1336.0, 2005.0], [1336.0, 2026.0], [1147.0, 2026.0]]}], "img_idx": 0}

{"type": "figure", "bbox": [0, 0, 1488, 2104], "res": [{"text": "7", "confidence": 0.11173919588327408, "text_region": [[1318.0, 121.0], [1329.0, 121.0], [1329.0, 134.0], [1318.0, 134.0]]}, {"text": "RAGVS.FINE-TUNING VS", "confidence": 0.9692713022232056, "text_region": [[157.0, 202.0], [839.0, 202.0], [839.0, 245.0], [157.0, 245.0]]}, {"text": "PROMPT ENGINEERING", "confidence": 0.980530321598053, "text_region": [[157.0, 254.0], [760.0, 254.0], [760.0, 298.0], [157.0, 298.0]]}, {"text": "We've already looked at RAG in some depth", "confidence": 0.9962643980979919, "text_region": [[151.0, 368.0], [700.0, 368.0], [700.0, 397.0], [151.0, 397.0]]}, {"text": "multiple epochs with the aim of reducing", "confidence": 0.986048698425293, "text_region": [[771.0, 366.0], [1289.0, 368.0], [1289.0, 399.0], [771.0, 397.0]]}, {"text": "in the previous sections. Now, let's quickly", "confidence": 0.9979895949363708, "text_region": [[148.0, 401.0], [669.0, 401.0], [669.0, 430.0], [148.0, 430.0]]}, {"text": "its loss, i.e., the model's predicted sentiment", "confidence": 0.9852070212364197, "text_region": [[771.0, 397.0], [1324.0, 399.0], [1324.0, 430.0], [771.0, 427.0]]}, {"text": "go through two more widely used terms", "confidence": 0.9792665243148804, "text_region": [[151.0, 434.0], [653.0, 434.0], [653.0, 462.0], [151.0, 462.0]]}, {"text": "label should be the same as the actual.", "confidence": 0.9634547829627991, "text_region": [[775.0, 434.0], [1271.0, 434.0], [1271.0, 462.0], [775.0, 462.0]]}, {"text": "concerning LLMs and when to use what.", "confidence": 0.9993728399276733, "text_region": [[151.0, 467.0], [647.0, 467.0], [647.0, 495.0], [151.0, 495.0]]}, {"text": "Prompt engineering is sometimes confused", "confidence": 0.9836732745170593, "text_region": [[773.0, 500.0], [1322.0, 500.0], [1322.0, 528.0], [773.0, 528.0]]}, {"text": "When you're fine-tuning an LLM, you're", "confidence": 0.9899783134460449, "text_region": [[151.0, 530.0], [636.0, 530.0], [636.0, 559.0], [151.0, 559.0]]}, {"text": "with fine-tuning. Prompt engineering", "confidence": 0.9874977469444275, "text_region": [[771.0, 528.0], [1238.0, 530.0], [1238.0, 561.0], [771.0, 559.0]]}, {"text": "training the model on smaller (and more", "confidence": 0.9836735129356384, "text_region": [[151.0, 563.0], [664.0, 563.0], [664.0, 592.0], [151.0, 592.0]]}, {"text": "involves no training at all. Rather, its a", "confidence": 0.9630076289176941, "text_region": [[773.0, 563.0], [1251.0, 563.0], [1251.0, 592.0], [773.0, 592.0]]}, {"text": "specific) datasets to help them perform", "confidence": 0.9891520738601685, "text_region": [[153.0, 596.0], [653.0, 596.0], [653.0, 625.0], [153.0, 625.0]]}, {"text": "technique where you provide additional", "confidence": 0.9764850735664368, "text_region": [[773.0, 596.0], [1275.0, 596.0], [1275.0, 625.0], [773.0, 625.0]]}, {"text": "better on specific tasks. For task-specific", "confidence": 0.976196825504303, "text_region": [[151.0, 629.0], [662.0, 629.0], [662.0, 658.0], [151.0, 658.0]]}, {"text": "context to the LLM in the form of examples", "confidence": 0.9904261827468872, "text_region": [[773.0, 629.0], [1304.0, 629.0], [1304.0, 658.0], [773.0, 658.0]]}, {"text": "fine-tuning, you'd typically do this by", "confidence": 0.9873603582382202, "text_region": [[148.0, 657.0], [616.0, 660.0], [615.0, 690.0], [148.0, 688.0]]}, {"text": "of how you expect it to reply to your prompt", "confidence": 0.980476975440979, "text_region": [[773.0, 662.0], [1322.0, 662.0], [1322.0, 690.0], [773.0, 690.0]]}, {"text": "preparing a labeled dataset and then fine-", "confidence": 0.9907907843589783, "text_region": [[148.0, 693.0], [686.0, 690.0], [686.0, 721.0], [148.0, 723.0]]}, {"text": "so that it's able to understand your intent", "confidence": 0.9945902228355408, "text_region": [[773.0, 695.0], [1293.0, 695.0], [1293.0, 723.0], [773.0, 723.0]]}, {"text": "tuning specific layers of the pre-trained", "confidence": 0.9963662028312683, "text_region": [[148.0, 725.0], [651.0, 725.0], [651.0, 754.0], [148.0, 754.0]]}, {"text": "better. So, instead of saying, \"Give me a", "confidence": 0.9939941763877869, "text_region": [[773.0, 725.0], [1269.0, 725.0], [1269.0, 756.0], [773.0, 756.0]]}, {"text": "model to perform a specific task accurately.", "confidence": 0.9859308004379272, "text_region": [[151.0, 758.0], [702.0, 758.0], [702.0, 787.0], [151.0, 787.0]]}, {"text": "code to implement RAG, you'll say,\"Give", "confidence": 0.9632626175880432, "text_region": [[773.0, 758.0], [1286.0, 758.0], [1286.0, 789.0], [773.0, 789.0]]}, {"text": "Let's say maybe you want to classify legal", "confidence": 0.9907101988792419, "text_region": [[148.0, 789.0], [675.0, 789.0], [675.0, 817.0], [148.0, 817.0]]}, {"text": "me an introductory code that shows the", "confidence": 0.9886053800582886, "text_region": [[773.0, 791.0], [1278.0, 791.0], [1278.0, 820.0], [773.0, 820.0]]}, {"text": "wordings into positive, neutral, and negative", "confidence": 0.9998021721839905, "text_region": [[151.0, 824.0], [704.0, 824.0], [704.0, 853.0], [151.0, 853.0]]}, {"text": "basic implementation of RAG, and make", "confidence": 0.9823864102363586, "text_region": [[775.0, 824.0], [1282.0, 824.0], [1282.0, 853.0], [775.0, 853.0]]}, {"text": "sentiments. So you'd have a large amount", "confidence": 0.9992052316665649, "text_region": [[151.0, 857.0], [684.0, 857.0], [684.0, 885.0], [151.0, 885.0]]}, {"text": "sure to use the dot product to determine the", "confidence": 0.9889069199562073, "text_region": [[773.0, 859.0], [1326.0, 859.0], [1326.0, 881.0], [773.0, 881.0]]}, {"text": "of labeled data with specific terminologies", "confidence": 0.9992548227310181, "text_region": [[148.0, 885.0], [686.0, 888.0], [686.0, 918.0], [148.0, 916.0]]}, {"text": "similarity between the query vector and the", "confidence": 0.9884403944015503, "text_region": [[775.0, 890.0], [1322.0, 890.0], [1322.0, 918.0], [775.0, 918.0]]}, {"text": "(Iabeled appropriately) and then fine-tune", "confidence": 0.9932679533958435, "text_region": [[153.0, 920.0], [691.0, 920.0], [691.0, 949.0], [153.0, 949.0]]}, {"text": "document vectors.\"", "confidence": 0.9997804164886475, "text_region": [[773.0, 920.0], [1023.0, 920.0], [1023.0, 949.0], [773.0, 949.0]]}, {"text": "the model by training it on this dataset for", "confidence": 0.996782124042511, "text_region": [[151.0, 953.0], [678.0, 953.0], [678.0, 982.0], [151.0, 982.0]]}, {"text": "Let's look at the differences in the three approaches in Table 1.1", "confidence": 0.9884588122367859, "text_region": [[151.0, 1056.0], [941.0, 1056.0], [941.0, 1085.0], [151.0, 1085.0]]}, {"text": "CHARACTERISTIC", "confidence": 0.9990288019180298, "text_region": [[173.0, 1172.0], [436.0, 1175.0], [436.0, 1206.0], [173.0, 1203.0]]}, {"text": "FINE-TUNING", "confidence": 0.9982870221138, "text_region": [[589.0, 1175.0], [788.0, 1175.0], [788.0, 1205.0], [589.0, 1205.0]]}, {"text": "RAG", "confidence": 0.9343883395195007, "text_region": [[857.0, 1173.0], [928.0, 1173.0], [928.0, 1205.0], [857.0, 1205.0]]}, {"text": "PROMPT ENGINEERING", "confidence": 0.9743779301643372, "text_region": [[985.0, 1175.0], [1318.0, 1175.0], [1318.0, 1203.0], [985.0, 1203.0]]}, {"text": "Can it make use of external", "confidence": 0.9831568598747253, "text_region": [[173.0, 1249.0], [518.0, 1249.0], [518.0, 1278.0], [173.0, 1278.0]]}, {"text": "knowledge sources?", "confidence": 0.9997589588165283, "text_region": [[168.0, 1278.0], [430.0, 1280.0], [429.0, 1311.0], [168.0, 1308.0]]}, {"text": "x", "confidence": 0.8620558977127075, "text_region": [[680.0, 1269.0], [702.0, 1269.0], [702.0, 1293.0], [680.0, 1293.0]]}, {"text": "x", "confidence": 0.7729629278182983, "text_region": [[1143.0, 1269.0], [1162.0, 1269.0], [1162.0, 1293.0], [1143.0, 1293.0]]}, {"text": "Does it minimize.", "confidence": 0.9589568972587585, "text_region": [[170.0, 1341.0], [374.0, 1341.0], [374.0, 1363.0], [170.0, 1363.0]]}, {"text": "hallucinations?", "confidence": 0.9995114803314209, "text_region": [[170.0, 1370.0], [365.0, 1370.0], [365.0, 1398.0], [170.0, 1398.0]]}, {"text": "Does it require domain-", "confidence": 0.9964432716369629, "text_region": [[173.0, 1429.0], [469.0, 1429.0], [469.0, 1457.0], [173.0, 1457.0]]}, {"text": "x", "confidence": 0.7652614712715149, "text_region": [[881.0, 1451.0], [903.0, 1451.0], [903.0, 1473.0], [881.0, 1473.0]]}, {"text": "x", "confidence": 0.8785978555679321, "text_region": [[1140.0, 1446.0], [1167.0, 1446.0], [1167.0, 1477.0], [1140.0, 1477.0]]}, {"text": "specific training data?", "confidence": 0.9993680119514465, "text_region": [[173.0, 1462.0], [454.0, 1462.0], [454.0, 1490.0], [173.0, 1490.0]]}, {"text": "Is it suitable for dynamic", "confidence": 0.9810428619384766, "text_region": [[170.0, 1521.0], [480.0, 1521.0], [480.0, 1550.0], [170.0, 1550.0]]}, {"text": "x", "confidence": 0.8446075320243835, "text_region": [[682.0, 1539.0], [702.0, 1539.0], [702.0, 1563.0], [682.0, 1563.0]]}, {"text": "x", "confidence": 0.7729629278182983, "text_region": [[1143.0, 1539.0], [1162.0, 1539.0], [1162.0, 1563.0], [1143.0, 1563.0]]}, {"text": "data?", "confidence": 0.9997541308403015, "text_region": [[170.0, 1550.0], [250.0, 1550.0], [250.0, 1580.0], [170.0, 1580.0]]}, {"text": "Does it offer clear", "confidence": 0.9992734789848328, "text_region": [[175.0, 1613.0], [394.0, 1613.0], [394.0, 1635.0], [175.0, 1635.0]]}, {"text": "x", "confidence": 0.860737144947052, "text_region": [[682.0, 1628.0], [702.0, 1628.0], [702.0, 1653.0], [682.0, 1653.0]]}, {"text": "V", "confidence": 0.38978636264801025, "text_region": [[881.0, 1626.0], [903.0, 1626.0], [903.0, 1648.0], [881.0, 1648.0]]}, {"text": "x", "confidence": 0.8853471875190735, "text_region": [[1143.0, 1628.0], [1162.0, 1628.0], [1162.0, 1655.0], [1143.0, 1655.0]]}, {"text": "interpretability of outputs?", "confidence": 0.9998350143432617, "text_region": [[170.0, 1642.0], [505.0, 1642.0], [505.0, 1670.0], [170.0, 1670.0]]}, {"text": "Low resource utilization", "confidence": 0.980044424533844, "text_region": [[170.0, 1716.0], [465.0, 1716.0], [465.0, 1745.0], [170.0, 1745.0]]}, {"text": "x", "confidence": 0.8263713717460632, "text_region": [[682.0, 1720.0], [702.0, 1720.0], [702.0, 1742.0], [682.0, 1742.0]]}, {"text": "x", "confidence": 0.7518199682235718, "text_region": [[884.0, 1720.0], [901.0, 1720.0], [901.0, 1740.0], [884.0, 1740.0]]}, {"text": "Quick deployment", "confidence": 0.999928891658783, "text_region": [[173.0, 1806.0], [403.0, 1806.0], [403.0, 1834.0], [173.0, 1834.0]]}, {"text": "x", "confidence": 0.8263713717460632, "text_region": [[682.0, 1810.0], [702.0, 1810.0], [702.0, 1832.0], [682.0, 1832.0]]}, {"text": "x", "confidence": 0.7382761836051941, "text_region": [[884.0, 1810.0], [901.0, 1810.0], [901.0, 1832.0], [884.0, 1832.0]]}, {"text": "Table 1.1: Comparing Fine-tuning, RAG and prompt engineering", "confidence": 0.9851132035255432, "text_region": [[385.0, 1920.0], [1101.0, 1922.0], [1100.0, 1953.0], [385.0, 1951.0]]}, {"text": "Galileo", "confidence": 0.9951367974281311, "text_region": [[243.0, 1989.0], [355.0, 1995.0], [353.0, 2034.0], [241.0, 2029.0]]}, {"text": "www.rungalileo.io.", "confidence": 0.9536100029945374, "text_region": [[1145.0, 2001.0], [1340.0, 2001.0], [1340.0, 2029.0], [1145.0, 2029.0]]}], "img_idx": 0}

{"type": "figure", "bbox": [0, 0, 1488, 2105], "res": [{"text": "Here's a thing to note. You can also use RAG and fine-tuning in conjunction to refine your LLM", "confidence": 0.9940111041069031, "text_region": [[151.0, 191.0], [1309.0, 191.0], [1309.0, 219.0], [151.0, 219.0]]}, {"text": "responses. Say a healthcare facility first fine-tunes its model on the proprietary dataset to", "confidence": 0.9954138994216919, "text_region": [[151.0, 221.0], [1275.0, 221.0], [1275.0, 250.0], [151.0, 250.0]]}, {"text": "adapt to the specific domain before using it in an RAG setup. Ideally, the responses would be", "confidence": 0.9973279237747192, "text_region": [[153.0, 259.0], [1306.0, 259.0], [1306.0, 281.0], [153.0, 281.0]]}, {"text": "much more refined and grounded in facts. This is akin to studying your textbook before your", "confidence": 0.9977913498878479, "text_region": [[151.0, 287.0], [1300.0, 287.0], [1300.0, 316.0], [151.0, 316.0]]}, {"text": "open-book exams (i.e., to familiarize yourself with the topics) and then using the material at", "confidence": 0.9955989718437195, "text_region": [[151.0, 318.0], [1298.0, 318.0], [1298.0, 346.0], [151.0, 346.0]]}, {"text": "hand to make your answers more accurate..", "confidence": 0.9760465621948242, "text_region": [[148.0, 351.0], [706.0, 353.0], [706.0, 382.0], [148.0, 379.0]]}, {"text": "In this chapter, we traced the evolution of LLMs and looked at their associated challenges.", "confidence": 0.9850761294364929, "text_region": [[148.0, 414.0], [1269.0, 419.0], [1269.0, 447.0], [148.0, 443.0]]}, {"text": "Then, we looked at RAGs and how they can help refine the LLM responses and address their", "confidence": 0.9919322729110718, "text_region": [[148.0, 447.0], [1287.0, 450.0], [1286.0, 478.0], [148.0, 476.0]]}, {"text": "challenges to a greater degree. As we move on to the following chapters, we'll explore RAGs in", "confidence": 0.9979661703109741, "text_region": [[151.0, 482.0], [1324.0, 482.0], [1324.0, 511.0], [151.0, 511.0]]}, {"text": "much more depth by asking and answering the following questions:.", "confidence": 0.9947503805160522, "text_region": [[151.0, 515.0], [1001.0, 515.0], [1001.0, 544.0], [151.0, 544.0]]}, {"text": "What should bea.", "confidence": 0.9323596954345703, "text_region": [[775.0, 857.0], [1003.0, 857.0], [1003.0, 886.0], [775.0, 886.0]]}, {"text": "done if the retrieval.", "confidence": 0.9794880151748657, "text_region": [[773.0, 897.0], [1052.0, 897.0], [1052.0, 925.0], [773.0, 925.0]]}, {"text": "How do we verify", "confidence": 0.9715355634689331, "text_region": [[308.0, 919.0], [547.0, 919.0], [547.0, 947.0], [308.0, 947.0]]}, {"text": "components aren't", "confidence": 0.9999056458473206, "text_region": [[773.0, 936.0], [1050.0, 936.0], [1050.0, 965.0], [773.0, 965.0]]}, {"text": "the correctness of", "confidence": 0.9883190989494324, "text_region": [[310.0, 958.0], [571.0, 958.0], [571.0, 987.0], [310.0, 987.0]]}, {"text": "accurate?", "confidence": 0.9994611740112305, "text_region": [[772.0, 976.0], [923.0, 971.0], [924.0, 1002.0], [773.0, 1007.0]]}, {"text": "the output?.", "confidence": 0.96792072057724, "text_region": [[308.0, 996.0], [476.0, 993.0], [476.0, 1024.0], [308.0, 1026.0]]}, {"text": "When documents are large,", "confidence": 0.9984705448150635, "text_region": [[848.0, 1085.0], [1245.0, 1090.0], [1244.0, 1121.0], [848.0, 1116.0]]}, {"text": "shouldn't they be split for.", "confidence": 0.9906386137008667, "text_region": [[848.0, 1127.0], [1211.0, 1127.0], [1211.0, 1156.0], [848.0, 1156.0]]}, {"text": "better retrieval instead of", "confidence": 0.9944930076599121, "text_region": [[848.0, 1164.0], [1213.0, 1164.0], [1213.0, 1193.0], [848.0, 1193.0]]}, {"text": "How and what", "confidence": 0.9999303221702576, "text_region": [[248.0, 1208.0], [458.0, 1208.0], [458.0, 1237.0], [248.0, 1237.0]]}, {"text": "bringing all the matched", "confidence": 0.9997938275337219, "text_region": [[848.0, 1206.0], [1205.0, 1206.0], [1205.0, 1234.0], [848.0, 1234.0]]}, {"text": "exactly to retrieve?", "confidence": 0.9761229753494263, "text_region": [[248.0, 1248.0], [520.0, 1248.0], [520.0, 1276.0], [248.0, 1276.0]]}, {"text": "documents back to the LLM?", "confidence": 0.9966751933097839, "text_region": [[848.0, 1243.0], [1253.0, 1243.0], [1253.0, 1272.0], [848.0, 1272.0]]}, {"text": "Al", "confidence": 0.8499853610992432, "text_region": [[664.0, 1430.0], [892.0, 1441.0], [882.0, 1642.0], [654.0, 1631.0]]}, {"text": "How to better", "confidence": 0.9998440146446228, "text_region": [[686.0, 1743.0], [884.0, 1743.0], [884.0, 1772.0], [686.0, 1772.0]]}, {"text": "prompt the LLM?", "confidence": 0.9980323910713196, "text_region": [[686.0, 1783.0], [923.0, 1778.0], [924.0, 1809.0], [687.0, 1814.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9986923336982727, "text_region": [[1147.0, 2004.0], [1335.0, 2004.0], [1335.0, 2026.0], [1147.0, 2026.0]]}], "img_idx": 0}

{"type": "figure", "bbox": [0, 0, 1488, 2104], "res": [{"text": "02", "confidence": 0.9896456599235535, "text_region": [[148.0, 208.0], [283.0, 208.0], [283.0, 296.0], [148.0, 296.0]]}, {"text": "CHALLENGES ASSOCIATED WITH", "confidence": 0.9812100529670715, "text_region": [[155.0, 331.0], [1078.0, 331.0], [1078.0, 375.0], [155.0, 375.0]]}, {"text": "BUILDING RAG SYSTEMS", "confidence": 0.952520489692688, "text_region": [[157.0, 405.0], [839.0, 405.0], [839.0, 449.0], [157.0, 449.0]]}, {"text": "In the previous chapter,we learned about", "confidence": 0.9665588140487671, "text_region": [[151.0, 515.0], [678.0, 515.0], [678.0, 544.0], [151.0, 544.0]]}, {"text": "To understand RAGs'pain points,we'll need", "confidence": 0.9412538409233093, "text_region": [[775.0, 515.0], [1317.0, 515.0], [1317.0, 544.0], [775.0, 544.0]]}, {"text": "the basic pitfalls of LLMs,how we can use", "confidence": 0.9427778720855713, "text_region": [[151.0, 550.0], [666.0, 550.0], [666.0, 579.0], [151.0, 579.0]]}, {"text": "to refer to this paper, which uses three", "confidence": 0.929517388343811, "text_region": [[773.0, 550.0], [1256.0, 550.0], [1256.0, 579.0], [773.0, 579.0]]}, {"text": "RAGs to address them, and how RAGs work", "confidence": 0.9472733736038208, "text_region": [[148.0, 581.0], [691.0, 583.0], [691.0, 614.0], [148.0, 611.0]]}, {"text": "case studies from research,education,", "confidence": 0.9518315196037292, "text_region": [[771.0, 583.0], [1260.0, 583.0], [1260.0, 611.0], [771.0, 611.0]]}, {"text": "In this chapter, we'll do a deeper dive into", "confidence": 0.9317373633384705, "text_region": [[151.0, 620.0], [673.0, 620.0], [673.0, 649.0], [151.0, 649.0]]}, {"text": "and biomedical domains,validates the", "confidence": 0.9625071287155151, "text_region": [[777.0, 622.0], [1264.0, 622.0], [1264.0, 644.0], [777.0, 644.0]]}, {"text": "RAGs by learning about the challenges", "confidence": 0.9584041237831116, "text_region": [[151.0, 655.0], [642.0, 655.0], [642.0, 684.0], [151.0, 684.0]]}, {"text": "responses manually,and draws conclusions", "confidence": 0.9784406423568726, "text_region": [[775.0, 655.0], [1331.0, 655.0], [1331.0, 684.0], [775.0, 684.0]]}, {"text": "associated with building such systems.By", "confidence": 0.9836257100105286, "text_region": [[151.0, 686.0], [678.0, 690.0], [677.0, 721.0], [150.0, 717.0]]}, {"text": "on the associated challenges.The paper", "confidence": 0.9697449207305908, "text_region": [[773.0, 686.0], [1282.0, 686.0], [1282.0, 717.0], [773.0, 717.0]]}, {"text": "the end of this chapter,you'll be fully aware", "confidence": 0.949906587600708, "text_region": [[151.0, 725.0], [695.0, 725.0], [695.0, 754.0], [151.0, 754.0]]}, {"text": "outlines seven key failure points that we'll", "confidence": 0.9470682740211487, "text_region": [[775.0, 725.0], [1293.0, 725.0], [1293.0, 754.0], [775.0, 754.0]]}, {"text": "of the steps you need to take to ensure your", "confidence": 0.9621383547782898, "text_region": [[153.0, 761.0], [702.0, 761.0], [702.0, 789.0], [153.0, 789.0]]}, {"text": "go through to guide the development of a", "confidence": 0.959925651550293, "text_region": [[773.0, 761.0], [1302.0, 756.0], [1302.0, 787.0], [773.0, 791.0]]}, {"text": "RAG system is robust.", "confidence": 0.9709998369216919, "text_region": [[151.0, 793.0], [423.0, 793.0], [423.0, 822.0], [151.0, 822.0]]}, {"text": "more robust RAG system.This is achieved", "confidence": 0.9670750498771667, "text_region": [[775.0, 796.0], [1295.0, 796.0], [1295.0, 824.0], [775.0, 824.0]]}, {"text": "by testing the performance of three RAG", "confidence": 0.9685189723968506, "text_region": [[775.0, 831.0], [1282.0, 831.0], [1282.0, 859.0], [775.0, 859.0]]}, {"text": "systems, as shown in Table 2.1.", "confidence": 0.996389627456665, "text_region": [[773.0, 864.0], [1156.0, 861.0], [1156.0, 892.0], [773.0, 894.0]]}, {"text": "Galileo", "confidence": 0.9955915808677673, "text_region": [[245.0, 1989.0], [355.0, 1995.0], [353.0, 2034.0], [243.0, 2029.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9919422268867493, "text_region": [[1145.0, 2001.0], [1340.0, 2001.0], [1340.0, 2029.0], [1145.0, 2029.0]]}], "img_idx": 0}

{"type": "text", "bbox": [155, 1572, 1114, 1607], "res": [{"text": "et's look at the seven key", "confidence": 0.9538733959197998, "text_region": [[161.0, 1582.0], [436.0, 1582.0], [436.0, 1600.0], [161.0, 1600.0]]}, {"text": "oain.pointsidentified.along with.accor", "confidence": 0.9091991782188416, "text_region": [[457.0, 1583.0], [882.0, 1583.0], [882.0, 1597.0], [457.0, 1597.0]]}, {"text": "oanving.examples", "confidence": 0.8626407384872437, "text_region": [[907.0, 1583.0], [1105.0, 1583.0], [1105.0, 1598.0], [907.0, 1598.0]]}], "img_idx": 0}
{"type": "text", "bbox": [530, 818, 1075, 852], "res": [{"text": "systems used for understanding various pain pc", "confidence": 0.993706226348877, "text_region": [[537.0, 827.0], [1071.0, 825.0], [1071.0, 847.0], [537.0, 848.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [146, 926, 1342, 1463], "res": [{"text": "Sample", "confidence": 0.9997672438621521, "text_region": [[1124.0, 967.0], [1224.0, 967.0], [1224.0, 994.0], [1124.0, 994.0]]}, {"text": "Case Study", "confidence": 0.9998041391372681, "text_region": [[165.0, 979.0], [312.0, 984.0], [311.0, 1012.0], [164.0, 1006.0]]}, {"text": "Domain", "confidence": 0.9996529221534729, "text_region": [[401.0, 982.0], [505.0, 982.0], [505.0, 1009.0], [401.0, 1009.0]]}, {"text": "Doc Types", "confidence": 0.9987155199050903, "text_region": [[568.0, 981.0], [703.0, 986.0], [702.0, 1013.0], [567.0, 1008.0]]}, {"text": "Dataset Size", "confidence": 0.9989035725593567, "text_region": [[746.0, 984.0], [906.0, 984.0], [906.0, 1006.0], [746.0, 1006.0]]}, {"text": "RAG Stages", "confidence": 0.9949551820755005, "text_region": [[924.0, 980.0], [1074.0, 986.0], [1073.0, 1013.0], [923.0, 1007.0]]}, {"text": "Questions", "confidence": 0.9997453689575195, "text_region": [[1125.0, 998.0], [1256.0, 998.0], [1256.0, 1024.0], [1125.0, 1024.0]]}, {"text": "Chunker,", "confidence": 0.9405439496040344, "text_region": [[926.0, 1061.0], [1039.0, 1064.0], [1039.0, 1091.0], [926.0, 1088.0]]}, {"text": "What are the", "confidence": 0.9998977780342102, "text_region": [[1124.0, 1064.0], [1286.0, 1064.0], [1286.0, 1090.0], [1124.0, 1090.0]]}, {"text": "Cognitive", "confidence": 0.999780535697937, "text_region": [[166.0, 1095.0], [286.0, 1095.0], [286.0, 1122.0], [166.0, 1122.0]]}, {"text": "Rewriter,", "confidence": 0.9996852874755859, "text_region": [[927.0, 1091.0], [1036.0, 1095.0], [1035.0, 1123.0], [926.0, 1118.0]]}, {"text": "key points", "confidence": 0.9994041323661804, "text_region": [[1124.0, 1095.0], [1252.0, 1092.0], [1253.0, 1123.0], [1124.0, 1126.0]]}, {"text": "Research", "confidence": 0.9994309544563293, "text_region": [[403.0, 1111.0], [520.0, 1111.0], [520.0, 1134.0], [403.0, 1134.0]]}, {"text": "PDFs", "confidence": 0.997848391532898, "text_region": [[566.0, 1105.0], [631.0, 1108.0], [630.0, 1137.0], [564.0, 1133.0]]}, {"text": "(Any size)", "confidence": 0.9989503622055054, "text_region": [[748.0, 1107.0], [870.0, 1107.0], [870.0, 1138.0], [748.0, 1138.0]]}, {"text": "Reviewer*", "confidence": 0.9998874664306641, "text_region": [[163.0, 1126.0], [289.0, 1122.0], [290.0, 1148.0], [164.0, 1152.0]]}, {"text": "Retriever,", "confidence": 0.9995715022087097, "text_region": [[925.0, 1122.0], [1043.0, 1125.0], [1043.0, 1152.0], [924.0, 1149.0]]}, {"text": "covered in this", "confidence": 0.992351770401001, "text_region": [[1124.0, 1126.0], [1306.0, 1125.0], [1306.0, 1148.0], [1124.0, 1149.0]]}, {"text": "Reader", "confidence": 0.999682605266571, "text_region": [[926.0, 1154.0], [1019.0, 1154.0], [1019.0, 1182.0], [926.0, 1182.0]]}, {"text": "paper?", "confidence": 0.9999255537986755, "text_region": [[1121.0, 1157.0], [1214.0, 1153.0], [1215.0, 1180.0], [1122.0, 1185.0]]}, {"text": "Chunker,", "confidence": 0.9993205070495605, "text_region": [[926.0, 1194.0], [1038.0, 1197.0], [1038.0, 1224.0], [926.0, 1221.0]]}, {"text": "What were the", "confidence": 0.999859094619751, "text_region": [[1125.0, 1214.0], [1305.0, 1214.0], [1305.0, 1236.0], [1125.0, 1236.0]]}, {"text": "Videos,", "confidence": 0.9995439648628235, "text_region": [[568.0, 1224.0], [661.0, 1228.0], [660.0, 1256.0], [567.0, 1251.0]]}, {"text": "Rewriter,", "confidence": 0.9486048221588135, "text_region": [[928.0, 1229.0], [1034.0, 1229.0], [1034.0, 1253.0], [928.0, 1253.0]]}, {"text": "Al Tutor*", "confidence": 0.9941844940185547, "text_region": [[166.0, 1244.0], [272.0, 1244.0], [272.0, 1267.0], [166.0, 1267.0]]}, {"text": "Education", "confidence": 0.9997811913490295, "text_region": [[401.0, 1242.0], [528.0, 1242.0], [528.0, 1268.0], [401.0, 1268.0]]}, {"text": "38", "confidence": 0.999884843826294, "text_region": [[745.0, 1241.0], [780.0, 1241.0], [780.0, 1268.0], [745.0, 1268.0]]}, {"text": "topics covered", "confidence": 0.9999270439147949, "text_region": [[1125.0, 1244.0], [1311.0, 1244.0], [1311.0, 1269.0], [1125.0, 1269.0]]}, {"text": "HTML, PDF", "confidence": 0.9995129704475403, "text_region": [[566.0, 1255.0], [691.0, 1258.0], [690.0, 1285.0], [566.0, 1282.0]]}, {"text": "Retriever,", "confidence": 0.9995715022087097, "text_region": [[925.0, 1255.0], [1043.0, 1258.0], [1043.0, 1285.0], [924.0, 1282.0]]}, {"text": "in week 6?", "confidence": 0.9986411333084106, "text_region": [[1123.0, 1272.0], [1254.0, 1272.0], [1254.0, 1298.0], [1123.0, 1298.0]]}, {"text": "Reader", "confidence": 0.9987627863883972, "text_region": [[927.0, 1289.0], [1018.0, 1289.0], [1018.0, 1312.0], [927.0, 1312.0]]}, {"text": "Define", "confidence": 0.9994222521781921, "text_region": [[1123.0, 1329.0], [1206.0, 1329.0], [1206.0, 1356.0], [1123.0, 1356.0]]}, {"text": "Chunker,", "confidence": 0.9994076490402222, "text_region": [[926.0, 1341.0], [1038.0, 1344.0], [1038.0, 1372.0], [926.0, 1369.0]]}, {"text": "Scientific", "confidence": 0.999791145324707, "text_region": [[567.0, 1360.0], [683.0, 1357.0], [683.0, 1384.0], [568.0, 1387.0]]}, {"text": "pseudotumor", "confidence": 0.9998218417167664, "text_region": [[1124.0, 1361.0], [1296.0, 1358.0], [1296.0, 1384.0], [1124.0, 1387.0]]}, {"text": "BioASQ", "confidence": 0.9889512062072754, "text_region": [[165.0, 1374.0], [257.0, 1374.0], [257.0, 1401.0], [165.0, 1401.0]]}, {"text": "Biomedical", "confidence": 0.9994972348213196, "text_region": [[401.0, 1374.0], [543.0, 1374.0], [543.0, 1400.0], [401.0, 1400.0]]}, {"text": "4017", "confidence": 0.9998283386230469, "text_region": [[748.0, 1374.0], [803.0, 1374.0], [803.0, 1398.0], [748.0, 1398.0]]}, {"text": "Retriever,", "confidence": 0.9591096639633179, "text_region": [[925.0, 1371.0], [1043.0, 1374.0], [1043.0, 1401.0], [924.0, 1398.0]]}, {"text": "PDFs", "confidence": 0.9967325329780579, "text_region": [[567.0, 1386.0], [632.0, 1390.0], [631.0, 1417.0], [565.0, 1414.0]]}, {"text": "cerebri. How is it", "confidence": 0.9903887510299683, "text_region": [[1125.0, 1392.0], [1326.0, 1392.0], [1326.0, 1414.0], [1125.0, 1414.0]]}, {"text": "Reader", "confidence": 0.9997779726982117, "text_region": [[926.0, 1404.0], [1019.0, 1404.0], [1019.0, 1431.0], [926.0, 1431.0]]}, {"text": "treated?", "confidence": 0.9998375177383423, "text_region": [[1124.0, 1420.0], [1230.0, 1420.0], [1230.0, 1444.0], [1124.0, 1444.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [141, 46, 1341, 780], "res": [{"text": "15", "confidence": 0.9994794130325317, "text_region": [[1312.0, 111.0], [1337.0, 111.0], [1337.0, 134.0], [1312.0, 134.0]]}, {"text": "Key Features", "confidence": 0.9995681643486023, "text_region": [[163.0, 241.0], [333.0, 241.0], [333.0, 266.0], [163.0, 266.0]]}, {"text": "Function", "confidence": 0.999284029006958, "text_region": [[663.0, 238.0], [780.0, 238.0], [780.0, 265.0], [663.0, 265.0]]}, {"text": "RAG System", "confidence": 0.9994286298751831, "text_region": [[1021.0, 241.0], [1176.0, 241.0], [1176.0, 266.0], [1021.0, 266.0]]}, {"text": "Assists researchers by ran", "confidence": 0.9999282360076904, "text_region": [[652.0, 329.0], [977.0, 330.0], [977.0, 356.0], [652.0, 354.0]]}, {"text": "Document ranking for research", "confidence": 0.9871160984039307, "text_region": [[166.0, 345.0], [555.0, 345.0], [555.0, 371.0], [166.0, 371.0]]}, {"text": "king documents based on", "confidence": 0.9949413537979126, "text_region": [[653.0, 361.0], [980.0, 358.0], [980.0, 385.0], [654.0, 388.0]]}, {"text": "relevance. Question answering", "confidence": 0.9998499751091003, "text_region": [[164.0, 373.0], [549.0, 377.0], [548.0, 403.0], [163.0, 399.0]]}, {"text": "Cognitive Reviewer", "confidence": 0.9833554029464722, "text_region": [[1021.0, 376.0], [1259.0, 376.0], [1259.0, 402.0], [1021.0, 402.0]]}, {"text": "a research objective and", "confidence": 0.9778583645820618, "text_region": [[655.0, 393.0], [965.0, 393.0], [965.0, 414.0], [655.0, 414.0]]}, {"text": "based on uploaded documents", "confidence": 0.9977695941925049, "text_region": [[166.0, 408.0], [563.0, 408.0], [563.0, 430.0], [166.0, 430.0]]}, {"text": "answering questions.", "confidence": 0.99974125623703, "text_region": [[653.0, 422.0], [916.0, 422.0], [916.0, 447.0], [653.0, 447.0]]}, {"text": "Helps students by", "confidence": 0.9995901584625244, "text_region": [[652.0, 478.0], [875.0, 479.0], [875.0, 506.0], [652.0, 505.0]]}, {"text": "Indexes PDFs, videos, and text", "confidence": 0.9975940585136414, "text_region": [[166.0, 511.0], [532.0, 511.0], [532.0, 533.0], [166.0, 533.0]]}, {"text": "answering questions about.", "confidence": 0.9871177077293396, "text_region": [[652.0, 510.0], [995.0, 509.0], [995.0, 535.0], [652.0, 537.0]]}, {"text": "documents. Transcribes videos using", "confidence": 0.9898574948310852, "text_region": [[165.0, 537.0], [630.0, 540.0], [630.0, 566.0], [165.0, 562.0]]}, {"text": "their learning content", "confidence": 0.9989553689956665, "text_region": [[652.0, 540.0], [925.0, 540.0], [925.0, 566.0], [652.0, 566.0]]}, {"text": "Al Tutor", "confidence": 0.9415909051895142, "text_region": [[1020.0, 540.0], [1115.0, 540.0], [1115.0, 563.0], [1020.0, 563.0]]}, {"text": "Whisper. Generalizes queries.", "confidence": 0.9835455417633057, "text_region": [[165.0, 568.0], [526.0, 570.0], [526.0, 595.0], [165.0, 594.0]]}, {"text": "and providing source", "confidence": 0.9996052980422974, "text_region": [[655.0, 571.0], [920.0, 571.0], [920.0, 596.0], [655.0, 596.0]]}, {"text": "verification.", "confidence": 0.9997155070304871, "text_region": [[653.0, 598.0], [799.0, 600.0], [798.0, 626.0], [652.0, 623.0]]}, {"text": "Provides precise answers", "confidence": 0.9802129864692688, "text_region": [[655.0, 655.0], [967.0, 656.0], [967.0, 679.0], [655.0, 678.0]]}, {"text": "Utilizes the BioAsQ dataset. Handles", "confidence": 0.9917823076248169, "text_region": [[165.0, 668.0], [610.0, 669.0], [610.0, 695.0], [165.0, 693.0]]}, {"text": "to biomedical questions", "confidence": 0.9985366463661194, "text_region": [[655.0, 686.0], [956.0, 686.0], [956.0, 711.0], [655.0, 711.0]]}, {"text": "yes/no, text summarization, factoid,", "confidence": 0.9998557567596436, "text_region": [[166.0, 701.0], [608.0, 701.0], [608.0, 726.0], [166.0, 726.0]]}, {"text": "Biomedical Q&A", "confidence": 0.9846820831298828, "text_region": [[1020.0, 698.0], [1221.0, 700.0], [1221.0, 725.0], [1020.0, 724.0]]}, {"text": "using a domain-specific", "confidence": 0.9895761013031006, "text_region": [[652.0, 714.0], [960.0, 715.0], [960.0, 742.0], [652.0, 740.0]]}, {"text": "and list questions", "confidence": 0.997882604598999, "text_region": [[166.0, 732.0], [387.0, 732.0], [387.0, 753.0], [166.0, 753.0]]}, {"text": "dataset.", "confidence": 0.9996063113212585, "text_region": [[653.0, 744.0], [757.0, 744.0], [757.0, 771.0], [653.0, 771.0]]}], "img_idx": 0}

{"type": "text", "bbox": [154, 566, 744, 953], "res": [{"text": "Let's say a user asks, \"What are the latest.", "confidence": 0.9590354561805725, "text_region": [[158.0, 575.0], [664.0, 574.0], [664.0, 595.0], [158.0, 596.0]]}, {"text": "treatments for COViD-19?\" but the dataset", "confidence": 0.95525062084198, "text_region": [[157.0, 610.0], [680.0, 610.0], [680.0, 630.0], [157.0, 630.0]]}, {"text": "does not include any documents on", "confidence": 0.9873396158218384, "text_region": [[156.0, 645.0], [605.0, 645.0], [605.0, 668.0], [156.0, 668.0]]}, {"text": "COviD-19 treatments. In this case, the", "confidence": 0.9630206227302551, "text_region": [[156.0, 679.0], [619.0, 680.0], [619.0, 701.0], [156.0, 700.0]]}, {"text": "LLM should have responded by saying it", "confidence": 0.9988905191421509, "text_region": [[155.0, 712.0], [649.0, 715.0], [649.0, 739.0], [155.0, 736.0]]}, {"text": "didn't know but instead outputs erroneous,", "confidence": 0.9894585609436035, "text_region": [[157.0, 748.0], [685.0, 751.0], [685.0, 773.0], [157.0, 770.0]]}, {"text": "irrelevant information. This can happen if the", "confidence": 0.9682492613792419, "text_region": [[157.0, 784.0], [711.0, 786.0], [711.0, 807.0], [157.0, 805.0]]}, {"text": "indexing process hasn't included all relevant.", "confidence": 0.9894862174987793, "text_region": [[157.0, 820.0], [710.0, 820.0], [710.0, 843.0], [157.0, 843.0]]}, {"text": "documents to accurately retrieve the required.", "confidence": 0.9809433221817017, "text_region": [[157.0, 853.0], [729.0, 854.0], [729.0, 877.0], [157.0, 876.0]]}, {"text": "information. This can also happen if you fail to", "confidence": 0.9822966456413269, "text_region": [[154.0, 886.0], [728.0, 888.0], [728.0, 915.0], [154.0, 914.0]]}, {"text": "provide enough context in your prompt.", "confidence": 0.9868550300598145, "text_region": [[157.0, 923.0], [647.0, 925.0], [647.0, 948.0], [157.0, 946.0]]}], "img_idx": 0}
{"type": "text", "bbox": [154, 1529, 736, 1811], "res": [{"text": "Here's an example to help you understand", "confidence": 0.995293140411377, "text_region": [[157.0, 1538.0], [681.0, 1538.0], [681.0, 1561.0], [157.0, 1561.0]]}, {"text": "this better. Say a user asks, \"What are the", "confidence": 0.9965920448303223, "text_region": [[157.0, 1573.0], [665.0, 1573.0], [665.0, 1596.0], [157.0, 1596.0]]}, {"text": "causes of diabetes?\" The answer is in a.", "confidence": 0.9942951202392578, "text_region": [[157.0, 1607.0], [642.0, 1607.0], [642.0, 1630.0], [157.0, 1630.0]]}, {"text": "document ranked 15th, but the system only", "confidence": 0.9806993007659912, "text_region": [[156.0, 1641.0], [688.0, 1644.0], [687.0, 1667.0], [156.0, 1664.0]]}, {"text": "returns the top 10 documents (since K has", "confidence": 0.9971081614494324, "text_region": [[157.0, 1678.0], [676.0, 1678.0], [676.0, 1700.0], [157.0, 1700.0]]}, {"text": "been set to 10). In this case, the user may.", "confidence": 0.989820122718811, "text_region": [[156.0, 1709.0], [664.0, 1712.0], [664.0, 1739.0], [156.0, 1736.0]]}, {"text": "receive incomplete information (this depends", "confidence": 0.9993963837623596, "text_region": [[158.0, 1746.0], [725.0, 1746.0], [725.0, 1770.0], [158.0, 1770.0]]}, {"text": "on the documents that are in the top 10).", "confidence": 0.9898926615715027, "text_region": [[158.0, 1782.0], [658.0, 1782.0], [658.0, 1804.0], [158.0, 1804.0]]}], "img_idx": 0}
{"type": "text", "bbox": [154, 1143, 734, 1493], "res": [{"text": "The answer to a question is present in the.", "confidence": 0.9821063876152039, "text_region": [[157.0, 1152.0], [672.0, 1152.0], [672.0, 1176.0], [157.0, 1176.0]]}, {"text": "document but did not rank highly enough to", "confidence": 0.9921165704727173, "text_region": [[157.0, 1188.0], [705.0, 1188.0], [705.0, 1212.0], [157.0, 1212.0]]}, {"text": "be included in the results returned to the user", "confidence": 0.9906920790672302, "text_region": [[157.0, 1222.0], [722.0, 1224.0], [722.0, 1244.0], [157.0, 1242.0]]}, {"text": "Recall that the retrieval process picks the top", "confidence": 0.9892554879188538, "text_region": [[156.0, 1255.0], [714.0, 1258.0], [714.0, 1282.0], [156.0, 1279.0]]}, {"text": "K documents that match the query from all", "confidence": 0.9976665377616882, "text_region": [[156.0, 1291.0], [695.0, 1292.0], [695.0, 1316.0], [156.0, 1315.0]]}, {"text": "theoretically ranked documents. So, if you", "confidence": 0.9973105192184448, "text_region": [[157.0, 1328.0], [675.0, 1328.0], [675.0, 1351.0], [157.0, 1351.0]]}, {"text": "set the K value too low or if the top relevant", "confidence": 0.9973927140235901, "text_region": [[156.0, 1362.0], [692.0, 1363.0], [692.0, 1386.0], [156.0, 1385.0]]}, {"text": "documents are replaced by those much", "confidence": 0.9995344877243042, "text_region": [[157.0, 1398.0], [658.0, 1398.0], [658.0, 1420.0], [157.0, 1420.0]]}, {"text": "below the list during the ranking process,..", "confidence": 0.9693067073822021, "text_region": [[156.0, 1430.0], [663.0, 1433.0], [662.0, 1457.0], [156.0, 1454.0]]}, {"text": "such a scenario is likely..", "confidence": 0.9871468544006348, "text_region": [[155.0, 1465.0], [450.0, 1467.0], [450.0, 1491.0], [155.0, 1489.0]]}], "img_idx": 0}
{"type": "text", "bbox": [154, 285, 724, 533], "res": [{"text": "A question is posed that cannot be answered", "confidence": 0.9932191371917725, "text_region": [[157.0, 296.0], [719.0, 294.0], [719.0, 316.0], [157.0, 318.0]]}, {"text": "with the available documents. In the ideal", "confidence": 0.9924299120903015, "text_region": [[157.0, 330.0], [676.0, 330.0], [676.0, 352.0], [157.0, 352.0]]}, {"text": "scenario, the RAG system responds with a", "confidence": 0.9983617663383484, "text_region": [[157.0, 365.0], [675.0, 365.0], [675.0, 388.0], [157.0, 388.0]]}, {"text": "message like \"Sorry, I don't know.\" However,", "confidence": 0.9957726001739502, "text_region": [[158.0, 401.0], [691.0, 401.0], [691.0, 424.0], [158.0, 424.0]]}, {"text": "for questions related to content without clear", "confidence": 0.997163712978363, "text_region": [[158.0, 435.0], [715.0, 435.0], [715.0, 457.0], [158.0, 457.0]]}, {"text": "answers, the system might be misled into", "confidence": 0.9992936253547668, "text_region": [[158.0, 470.0], [671.0, 470.0], [671.0, 493.0], [158.0, 493.0]]}, {"text": "oroviding a response.", "confidence": 0.9973413348197937, "text_region": [[158.0, 504.0], [423.0, 505.0], [423.0, 528.0], [158.0, 527.0]]}], "img_idx": 0}
{"type": "title", "bbox": [154, 184, 568, 244], "res": [{"text": "MISSING CONTENT", "confidence": 0.9895341396331787, "text_region": [[156.0, 200.0], [563.0, 203.0], [563.0, 235.0], [156.0, 232.0]]}], "img_idx": 0}
{"type": "title", "bbox": [151, 1031, 1025, 1092], "res": [{"text": "MI$SED THE TOP-RANKED DOCUMENTS", "confidence": 0.9256861805915833, "text_region": [[155.0, 1051.0], [1018.0, 1051.0], [1018.0, 1082.0], [155.0, 1082.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [154, 138, 1353, 2103], "res": [{"text": "MISSING CONTENT", "confidence": 0.982264518737793, "text_region": [[160.0, 199.0], [566.0, 199.0], [566.0, 234.0], [160.0, 234.0]]}, {"text": "A question is posed that cannot be answered.", "confidence": 0.9897812008857727, "text_region": [[158.0, 294.0], [720.0, 294.0], [720.0, 320.0], [158.0, 320.0]]}, {"text": "with the available documents. In the ideal", "confidence": 0.9910687208175659, "text_region": [[158.0, 330.0], [676.0, 330.0], [676.0, 351.0], [158.0, 351.0]]}, {"text": "scenario, the RAG system responds with a", "confidence": 0.9718254804611206, "text_region": [[156.0, 363.0], [679.0, 363.0], [679.0, 390.0], [156.0, 390.0]]}, {"text": "message like \"Sorry, I don't know.\" However,.", "confidence": 0.9758527278900146, "text_region": [[156.0, 398.0], [693.0, 398.0], [693.0, 425.0], [156.0, 425.0]]}, {"text": "Mitigation strategy", "confidence": 0.9857856631278992, "text_region": [[956.0, 402.0], [1255.0, 408.0], [1255.0, 445.0], [955.0, 439.0]]}, {"text": "for questions related to content without clear.", "confidence": 0.9910545945167542, "text_region": [[156.0, 433.0], [716.0, 433.0], [716.0, 459.0], [156.0, 459.0]]}, {"text": "answers, the system might be misled into", "confidence": 0.9812405705451965, "text_region": [[158.0, 468.0], [672.0, 468.0], [672.0, 494.0], [158.0, 494.0]]}, {"text": "providing a response.", "confidence": 0.9960299134254456, "text_region": [[156.0, 500.0], [425.0, 502.0], [424.0, 531.0], [156.0, 529.0]]}, {"text": "You'll need to make sure all the", "confidence": 0.9993987083435059, "text_region": [[849.0, 506.0], [1239.0, 506.0], [1239.0, 533.0], [849.0, 533.0]]}, {"text": "documents are indexed properly.", "confidence": 0.9816679954528809, "text_region": [[849.0, 541.0], [1264.0, 543.0], [1263.0, 572.0], [849.0, 570.0]]}, {"text": "Let's say a user asks, \"What are the latest", "confidence": 0.9960619211196899, "text_region": [[154.0, 572.0], [666.0, 572.0], [666.0, 599.0], [154.0, 599.0]]}, {"text": "Sometimes, this might get.", "confidence": 0.9801568984985352, "text_region": [[849.0, 576.0], [1182.0, 578.0], [1182.0, 607.0], [849.0, 605.0]]}, {"text": "treatments for COvID-19?\" but the dataset", "confidence": 0.9711739420890808, "text_region": [[154.0, 605.0], [683.0, 607.0], [683.0, 635.0], [154.0, 633.0]]}, {"text": "expensive due to the frequent", "confidence": 0.9843407273292542, "text_region": [[851.0, 615.0], [1226.0, 615.0], [1226.0, 642.0], [851.0, 642.0]]}, {"text": "does not include any documents on", "confidence": 0.9953685998916626, "text_region": [[154.0, 639.0], [608.0, 642.0], [608.0, 670.0], [154.0, 668.0]]}, {"text": "need to update the dataset. In this.", "confidence": 0.9761509299278259, "text_region": [[853.0, 652.0], [1280.0, 652.0], [1280.0, 672.0], [853.0, 672.0]]}, {"text": "COVID-19 treatments. In this case, the", "confidence": 0.9767414927482605, "text_region": [[154.0, 674.0], [622.0, 676.0], [622.0, 705.0], [154.0, 703.0]]}, {"text": "case, you'll at least want to index", "confidence": 0.9838820099830627, "text_region": [[849.0, 682.0], [1263.0, 682.0], [1263.0, 709.0], [849.0, 709.0]]}, {"text": "LLM should have responded by saying it", "confidence": 0.9992206692695618, "text_region": [[154.0, 709.0], [654.0, 711.0], [654.0, 740.0], [154.0, 738.0]]}, {"text": "all the frequently asked questions", "confidence": 0.9832453727722168, "text_region": [[853.0, 719.0], [1274.0, 719.0], [1274.0, 746.0], [853.0, 746.0]]}, {"text": "didn't know but instead outputs erroneous,", "confidence": 0.9998952746391296, "text_region": [[154.0, 744.0], [687.0, 746.0], [687.0, 775.0], [154.0, 772.0]]}, {"text": "and also index the summaries of", "confidence": 0.9868058562278748, "text_region": [[851.0, 754.0], [1263.0, 754.0], [1263.0, 781.0], [851.0, 781.0]]}, {"text": "irrelevant information. This can happen if the.", "confidence": 0.994408130645752, "text_region": [[156.0, 783.0], [714.0, 783.0], [714.0, 809.0], [156.0, 809.0]]}, {"text": "each document (in a much shorter", "confidence": 0.9994138479232788, "text_region": [[851.0, 789.0], [1291.0, 789.0], [1291.0, 816.0], [851.0, 816.0]]}, {"text": "indexing process hasn't included all relevant.", "confidence": 0.9795494675636292, "text_region": [[156.0, 818.0], [712.0, 818.0], [712.0, 846.0], [156.0, 846.0]]}, {"text": "format) so the retrieval is better.", "confidence": 0.9692318439483643, "text_region": [[849.0, 824.0], [1253.0, 824.0], [1253.0, 850.0], [849.0, 850.0]]}, {"text": "documents to accurately retrieve the required", "confidence": 0.9993083477020264, "text_region": [[156.0, 852.0], [731.0, 852.0], [731.0, 879.0], [156.0, 879.0]]}, {"text": "information. This can also happen if you fail to", "confidence": 0.989619255065918, "text_region": [[156.0, 887.0], [729.0, 887.0], [729.0, 916.0], [156.0, 916.0]]}, {"text": "provide enough context in your prompt.", "confidence": 0.9765257835388184, "text_region": [[156.0, 924.0], [645.0, 924.0], [645.0, 951.0], [156.0, 951.0]]}, {"text": "MISSED THE TOP-RANKED DOCUMENTS", "confidence": 0.9953541159629822, "text_region": [[160.0, 1049.0], [1016.0, 1049.0], [1016.0, 1084.0], [160.0, 1084.0]]}, {"text": "The answer to a question is present in the", "confidence": 0.9996906518936157, "text_region": [[156.0, 1151.0], [674.0, 1151.0], [674.0, 1178.0], [156.0, 1178.0]]}, {"text": "document but did not rank highly enough to", "confidence": 0.9889189600944519, "text_region": [[154.0, 1182.0], [708.0, 1184.0], [708.0, 1213.0], [154.0, 1211.0]]}, {"text": "be included in the results returned to the user..", "confidence": 0.9948480725288391, "text_region": [[156.0, 1221.0], [724.0, 1221.0], [724.0, 1247.0], [156.0, 1247.0]]}, {"text": "Recall that the retrieval process picks the top", "confidence": 0.9892310500144958, "text_region": [[156.0, 1251.0], [714.0, 1256.0], [714.0, 1284.0], [156.0, 1280.0]]}, {"text": "Mitigation strategy", "confidence": 0.999814510345459, "text_region": [[956.0, 1256.0], [1255.0, 1258.0], [1255.0, 1295.0], [955.0, 1292.0]]}, {"text": "K documents that match the query from all.", "confidence": 0.9785334467887878, "text_region": [[156.0, 1290.0], [695.0, 1290.0], [695.0, 1317.0], [156.0, 1317.0]]}, {"text": "theoretically ranked documents. So, if you", "confidence": 0.9996731281280518, "text_region": [[154.0, 1323.0], [679.0, 1325.0], [678.0, 1354.0], [154.0, 1352.0]]}, {"text": "set the K value too low or if the top relevant", "confidence": 0.987449049949646, "text_region": [[154.0, 1358.0], [693.0, 1360.0], [693.0, 1389.0], [154.0, 1387.0]]}, {"text": "A good way to address this problem", "confidence": 0.9972820281982422, "text_region": [[849.0, 1360.0], [1305.0, 1358.0], [1305.0, 1387.0], [849.0, 1389.0]]}, {"text": "documents are replaced by those much", "confidence": 0.9942200779914856, "text_region": [[156.0, 1395.0], [660.0, 1395.0], [660.0, 1423.0], [156.0, 1423.0]]}, {"text": "would be to also include metadata", "confidence": 0.985407292842865, "text_region": [[849.0, 1395.0], [1291.0, 1395.0], [1291.0, 1421.0], [849.0, 1421.0]]}, {"text": "below the list during the ranking process,", "confidence": 0.9953387975692749, "text_region": [[154.0, 1427.0], [664.0, 1430.0], [664.0, 1458.0], [154.0, 1456.0]]}, {"text": "information in each document. This", "confidence": 0.9998153448104858, "text_region": [[851.0, 1430.0], [1295.0, 1430.0], [1295.0, 1456.0], [851.0, 1456.0]]}, {"text": "such a scenario is likely.", "confidence": 0.9973649382591248, "text_region": [[154.0, 1462.0], [454.0, 1467.0], [453.0, 1495.0], [154.0, 1491.0]]}, {"text": "metadata can contain additional", "confidence": 0.9901253581047058, "text_region": [[853.0, 1468.0], [1270.0, 1468.0], [1270.0, 1489.0], [853.0, 1489.0]]}, {"text": "information about the document", "confidence": 0.9970479607582092, "text_region": [[851.0, 1499.0], [1268.0, 1499.0], [1268.0, 1526.0], [851.0, 1526.0]]}, {"text": "Here's an example to help you understand", "confidence": 0.9919115304946899, "text_region": [[156.0, 1536.0], [683.0, 1536.0], [683.0, 1563.0], [156.0, 1563.0]]}, {"text": "itself, the file name, and keywords.", "confidence": 0.9882563352584839, "text_region": [[851.0, 1536.0], [1274.0, 1536.0], [1274.0, 1563.0], [851.0, 1563.0]]}, {"text": "this better. Say a user asks, \"What are the", "confidence": 0.9894389510154724, "text_region": [[158.0, 1571.0], [670.0, 1571.0], [670.0, 1597.0], [158.0, 1597.0]]}, {"text": "This will help the LLM make.", "confidence": 0.9831007719039917, "text_region": [[851.0, 1571.0], [1184.0, 1571.0], [1184.0, 1597.0], [851.0, 1597.0]]}, {"text": "causes of diabetes?\" The answer is in a", "confidence": 0.9987274408340454, "text_region": [[156.0, 1606.0], [643.0, 1606.0], [643.0, 1632.0], [156.0, 1632.0]]}, {"text": "contextual connections between", "confidence": 0.9998724460601807, "text_region": [[853.0, 1606.0], [1263.0, 1606.0], [1263.0, 1632.0], [853.0, 1632.0]]}, {"text": "document ranked 15th, but the system only", "confidence": 0.9966269731521606, "text_region": [[154.0, 1638.0], [689.0, 1640.0], [689.0, 1669.0], [154.0, 1667.0]]}, {"text": "different document chunks and", "confidence": 0.9926389455795288, "text_region": [[853.0, 1640.0], [1247.0, 1640.0], [1247.0, 1667.0], [853.0, 1667.0]]}, {"text": "returns the top 10 documents (since K has", "confidence": 0.9884026646614075, "text_region": [[156.0, 1675.0], [679.0, 1675.0], [679.0, 1702.0], [156.0, 1702.0]]}, {"text": "bring them together to form a", "confidence": 0.9807047843933105, "text_region": [[851.0, 1677.0], [1228.0, 1677.0], [1228.0, 1704.0], [851.0, 1704.0]]}, {"text": "been set to 10). In this case, the user may", "confidence": 0.9934629201889038, "text_region": [[156.0, 1708.0], [664.0, 1710.0], [664.0, 1739.0], [156.0, 1737.0]]}, {"text": "cohesive answer. Another way would", "confidence": 0.9998807311058044, "text_region": [[853.0, 1712.0], [1313.0, 1712.0], [1313.0, 1739.0], [853.0, 1739.0]]}, {"text": "receive incomplete information (this depends", "confidence": 0.9996384978294373, "text_region": [[158.0, 1745.0], [726.0, 1745.0], [726.0, 1773.0], [158.0, 1773.0]]}, {"text": "be to engineer a RAG pipeline with", "confidence": 0.9971738457679749, "text_region": [[851.0, 1747.0], [1280.0, 1747.0], [1280.0, 1773.0], [851.0, 1773.0]]}, {"text": "on the documents that are in the top 10)", "confidence": 0.9906355738639832, "text_region": [[158.0, 1780.0], [658.0, 1780.0], [658.0, 1806.0], [158.0, 1806.0]]}, {"text": "tested configurations for variables", "confidence": 0.992673933506012, "text_region": [[851.0, 1782.0], [1282.0, 1782.0], [1282.0, 1808.0], [851.0, 1808.0]]}, {"text": "like chunk size, embedding strategy,", "confidence": 0.9933596849441528, "text_region": [[849.0, 1812.0], [1303.0, 1817.0], [1303.0, 1845.0], [849.0, 1841.0]]}, {"text": "retrieval strategy, and context size.", "confidence": 0.9871193170547485, "text_region": [[851.0, 1851.0], [1282.0, 1851.0], [1282.0, 1880.0], [851.0, 1880.0]]}, {"text": "Galileo", "confidence": 0.9961112141609192, "text_region": [[243.0, 1992.0], [352.0, 1997.0], [351.0, 2034.0], [241.0, 2029.0]]}, {"text": "www.rungalileo.io", "confidence": 0.992837131023407, "text_region": [[1145.0, 2003.0], [1345.0, 2003.0], [1345.0, 2029.0], [1145.0, 2029.0]]}], "img_idx": 0}

{"type": "text", "bbox": [154, 770, 754, 981], "res": [{"text": "A quick example is you asking, \"What are the.", "confidence": 0.9798603653907776, "text_region": [[157.0, 779.0], [709.0, 778.0], [709.0, 801.0], [157.0, 802.0]]}, {"text": "symptoms of multiple sclerosis?\" In response.", "confidence": 0.9832605123519897, "text_region": [[157.0, 813.0], [713.0, 811.0], [714.0, 837.0], [157.0, 839.0]]}, {"text": "to your question, several documents are.", "confidence": 0.9826760292053223, "text_region": [[158.0, 850.0], [657.0, 848.0], [657.0, 871.0], [158.0, 873.0]]}, {"text": "retrieved, but only a few make it into the final.", "confidence": 0.9958975911140442, "text_region": [[157.0, 884.0], [714.0, 883.0], [714.0, 906.0], [157.0, 907.0]]}, {"text": "context. So, the response you get may either be", "confidence": 0.9942482709884644, "text_region": [[158.0, 920.0], [742.0, 920.0], [742.0, 942.0], [158.0, 942.0]]}, {"text": "missing some critical information or generic.", "confidence": 0.9951172471046448, "text_region": [[158.0, 954.0], [707.0, 954.0], [707.0, 975.0], [158.0, 975.0]]}], "img_idx": 0}
{"type": "text", "bbox": [155, 352, 744, 736], "res": [{"text": "Documents containing the answer are", "confidence": 0.9759187698364258, "text_region": [[157.0, 359.0], [632.0, 360.0], [631.0, 381.0], [157.0, 380.0]]}, {"text": "retrieved from the database but fail to fit into", "confidence": 0.9847434163093567, "text_region": [[158.0, 394.0], [713.0, 394.0], [713.0, 414.0], [158.0, 414.0]]}, {"text": "the context for generating a response. This", "confidence": 0.9989042282104492, "text_region": [[158.0, 428.0], [684.0, 428.0], [684.0, 451.0], [158.0, 451.0]]}, {"text": "occurs when many documents are returned,", "confidence": 0.9746265411376953, "text_region": [[157.0, 464.0], [709.0, 464.0], [709.0, 487.0], [157.0, 487.0]]}, {"text": "eading to a consolidation process where", "confidence": 0.9994708299636841, "text_region": [[158.0, 499.0], [669.0, 499.0], [669.0, 522.0], [158.0, 522.0]]}, {"text": "the relevant answer retrieval is hindered. This", "confidence": 0.9911436438560486, "text_region": [[158.0, 532.0], [714.0, 532.0], [714.0, 555.0], [158.0, 555.0]]}, {"text": "nappens because any LLM will have a token", "confidence": 0.9779664874076843, "text_region": [[158.0, 570.0], [698.0, 568.0], [698.0, 589.0], [158.0, 591.0]]}, {"text": "imit, and anything more than this is truncated,", "confidence": 0.9917225241661072, "text_region": [[158.0, 604.0], [735.0, 604.0], [735.0, 627.0], [158.0, 627.0]]}, {"text": "so when a larger set of relevant documents is", "confidence": 0.9889360070228577, "text_region": [[158.0, 639.0], [722.0, 639.0], [722.0, 662.0], [158.0, 662.0]]}, {"text": "retrieved, some part of it will be truncated to", "confidence": 0.9949628114700317, "text_region": [[158.0, 674.0], [705.0, 674.0], [705.0, 697.0], [158.0, 697.0]]}, {"text": "oe part of the context limit.", "confidence": 0.9740047454833984, "text_region": [[158.0, 708.0], [487.0, 708.0], [487.0, 731.0], [158.0, 731.0]]}], "img_idx": 0}
{"type": "text", "bbox": [153, 1159, 730, 1547], "res": [{"text": "The answer is present in the context, but the", "confidence": 0.9879063367843628, "text_region": [[156.0, 1171.0], [699.0, 1170.0], [699.0, 1191.0], [156.0, 1192.0]]}, {"text": "model fails to extract the correct information.", "confidence": 0.9783482551574707, "text_region": [[157.0, 1206.0], [714.0, 1206.0], [714.0, 1227.0], [157.0, 1227.0]]}, {"text": "This typically happens when there is", "confidence": 0.9969996213912964, "text_region": [[155.0, 1240.0], [604.0, 1239.0], [604.0, 1263.0], [155.0, 1264.0]]}, {"text": "excessive noise or conflicting information", "confidence": 0.9848889708518982, "text_region": [[156.0, 1275.0], [667.0, 1276.0], [667.0, 1297.0], [156.0, 1296.0]]}, {"text": "in the context. For instance, a user asks", "confidence": 0.9899306893348694, "text_region": [[156.0, 1310.0], [641.0, 1312.0], [641.0, 1333.0], [156.0, 1331.0]]}, {"text": "'What are the complications of untreated", "confidence": 0.9981178045272827, "text_region": [[156.0, 1345.0], [672.0, 1345.0], [672.0, 1368.0], [156.0, 1368.0]]}, {"text": "nypertension?\" The correct document is in", "confidence": 0.9817396998405457, "text_region": [[157.0, 1380.0], [679.0, 1378.0], [679.0, 1402.0], [157.0, 1405.0]]}, {"text": "the context, but the model fails to extract the", "confidence": 0.9884308576583862, "text_region": [[157.0, 1417.0], [710.0, 1417.0], [710.0, 1437.0], [157.0, 1437.0]]}, {"text": "relevant information. So, the user might get a", "confidence": 0.9895318746566772, "text_region": [[156.0, 1450.0], [713.0, 1452.0], [713.0, 1473.0], [156.0, 1471.0]]}, {"text": "generic response like \"hypertension can lead", "confidence": 0.9992675185203552, "text_region": [[155.0, 1486.0], [713.0, 1483.0], [713.0, 1508.0], [155.0, 1511.0]]}, {"text": "to serious health issues.\"", "confidence": 0.9869201183319092, "text_region": [[157.0, 1521.0], [458.0, 1521.0], [458.0, 1541.0], [157.0, 1541.0]]}], "img_idx": 0}
{"type": "title", "bbox": [153, 186, 955, 299], "res": [{"text": "NOT IN CONTEXT - CONSOLDATION", "confidence": 0.8268358111381531, "text_region": [[159.0, 205.0], [947.0, 205.0], [947.0, 231.0], [159.0, 231.0]]}, {"text": "STRATEGY LMITATIONS", "confidence": 0.8379966616630554, "text_region": [[159.0, 257.0], [675.0, 257.0], [675.0, 287.0], [159.0, 287.0]]}], "img_idx": 0}
{"type": "title", "bbox": [154, 1052, 525, 1112], "res": [{"text": "NOT EXTRACTED", "confidence": 0.9031901955604553, "text_region": [[160.0, 1071.0], [517.0, 1071.0], [517.0, 1100.0], [160.0, 1100.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [150, 240, 1386, 2105], "res": [{"text": "STRATEGY LIMITATIONS", "confidence": 0.9628337025642395, "text_region": [[158.0, 256.0], [677.0, 256.0], [677.0, 289.0], [158.0, 289.0]]}, {"text": "Documents containing the answer are", "confidence": 0.9977017045021057, "text_region": [[154.0, 357.0], [635.0, 357.0], [635.0, 384.0], [154.0, 384.0]]}, {"text": "retrieved from the database but fail to fit into", "confidence": 0.9900679588317871, "text_region": [[154.0, 392.0], [716.0, 392.0], [716.0, 417.0], [154.0, 417.0]]}, {"text": "the context for generating a response. This", "confidence": 0.9930618405342102, "text_region": [[154.0, 426.0], [687.0, 426.0], [687.0, 454.0], [154.0, 454.0]]}, {"text": "occurs when many documents are returned,", "confidence": 0.9997129440307617, "text_region": [[154.0, 463.0], [710.0, 463.0], [710.0, 489.0], [154.0, 489.0]]}, {"text": "leading to a consolidation process where", "confidence": 0.9839727282524109, "text_region": [[154.0, 496.0], [670.0, 496.0], [670.0, 524.0], [154.0, 524.0]]}, {"text": "Mitigation strategy.", "confidence": 0.9488617777824402, "text_region": [[967.0, 489.0], [1264.0, 493.0], [1264.0, 528.0], [967.0, 523.0]]}, {"text": "the relevant answer retrieval is hindered. This", "confidence": 0.9909417033195496, "text_region": [[154.0, 531.0], [716.0, 531.0], [716.0, 557.0], [154.0, 557.0]]}, {"text": "happens because any LLM will have a token", "confidence": 0.9890209436416626, "text_region": [[152.0, 566.0], [700.0, 564.0], [700.0, 592.0], [152.0, 594.0]]}, {"text": "limit, and anything more than this is truncated,", "confidence": 0.9942110180854797, "text_region": [[154.0, 601.0], [737.0, 601.0], [737.0, 629.0], [154.0, 629.0]]}, {"text": "One possible way to fix this issue is", "confidence": 0.9815115928649902, "text_region": [[855.0, 596.0], [1286.0, 596.0], [1286.0, 621.0], [855.0, 621.0]]}, {"text": "so when a larger set of relevant documents is", "confidence": 0.990993082523346, "text_region": [[154.0, 638.0], [724.0, 638.0], [724.0, 664.0], [154.0, 664.0]]}, {"text": "to train a retriever model to better", "confidence": 0.9788662791252136, "text_region": [[855.0, 634.0], [1276.0, 634.0], [1276.0, 654.0], [855.0, 654.0]]}, {"text": "retrieved, some part of it will be truncated to", "confidence": 0.989823579788208, "text_region": [[152.0, 673.0], [708.0, 673.0], [708.0, 698.0], [152.0, 698.0]]}, {"text": "capture the relationship between", "confidence": 0.9987852573394775, "text_region": [[855.0, 665.0], [1270.0, 665.0], [1270.0, 693.0], [855.0, 693.0]]}, {"text": "be part of the context limit..", "confidence": 0.9868910312652588, "text_region": [[152.0, 706.0], [488.0, 704.0], [488.0, 731.0], [152.0, 734.0]]}, {"text": "query and documents. Another way", "confidence": 0.9998054504394531, "text_region": [[853.0, 702.0], [1299.0, 702.0], [1299.0, 728.0], [853.0, 728.0]]}, {"text": "would be to have a larger context", "confidence": 0.9970853328704834, "text_region": [[851.0, 733.0], [1274.0, 735.0], [1274.0, 763.0], [851.0, 761.0]]}, {"text": "window size (the paper mentions", "confidence": 0.9992310404777527, "text_region": [[851.0, 768.0], [1268.0, 770.0], [1268.0, 798.0], [851.0, 796.0]]}, {"text": "A quick example is you asking, \"What are the", "confidence": 0.9873718023300171, "text_region": [[154.0, 778.0], [710.0, 778.0], [710.0, 803.0], [154.0, 803.0]]}, {"text": "symptoms of multiple sclerosis?\" In response", "confidence": 0.9989662766456604, "text_region": [[154.0, 811.0], [716.0, 811.0], [716.0, 838.0], [154.0, 838.0]]}, {"text": "that the model performed better", "confidence": 0.9994948506355286, "text_region": [[853.0, 805.0], [1260.0, 805.0], [1260.0, 833.0], [853.0, 833.0]]}, {"text": "to your question, several documents are", "confidence": 0.984136700630188, "text_region": [[154.0, 848.0], [660.0, 848.0], [660.0, 873.0], [154.0, 873.0]]}, {"text": "with a larger context size, i.e., 8k of", "confidence": 0.9899121522903442, "text_region": [[853.0, 840.0], [1280.0, 840.0], [1280.0, 867.0], [853.0, 867.0]]}, {"text": "retrieved, but only a few make it into the final", "confidence": 0.9926173090934753, "text_region": [[150.0, 881.0], [716.0, 879.0], [716.0, 906.0], [150.0, 908.0]]}, {"text": "GPT-4 vs. 4k of GPT-3.5)", "confidence": 0.9980707168579102, "text_region": [[855.0, 875.0], [1152.0, 875.0], [1152.0, 901.0], [855.0, 901.0]]}, {"text": "context. So, the response you get may either be", "confidence": 0.9871736764907837, "text_region": [[154.0, 918.0], [745.0, 918.0], [745.0, 945.0], [154.0, 945.0]]}, {"text": "missing some critical information or generic.", "confidence": 0.9946741461753845, "text_region": [[152.0, 953.0], [708.0, 953.0], [708.0, 980.0], [152.0, 980.0]]}, {"text": "NOT EXTRACTED", "confidence": 0.9791824817657471, "text_region": [[158.0, 1068.0], [519.0, 1068.0], [519.0, 1101.0], [158.0, 1101.0]]}, {"text": "The answer is present in the context, but the", "confidence": 0.9922317266464233, "text_region": [[154.0, 1169.0], [702.0, 1169.0], [702.0, 1194.0], [154.0, 1194.0]]}, {"text": "model fails to extract the correct information.", "confidence": 0.9956151843070984, "text_region": [[154.0, 1204.0], [716.0, 1204.0], [716.0, 1229.0], [154.0, 1229.0]]}, {"text": "This typically happens when there is", "confidence": 0.9879240393638611, "text_region": [[154.0, 1239.0], [606.0, 1239.0], [606.0, 1266.0], [154.0, 1266.0]]}, {"text": "excessive noise or conflicting information", "confidence": 0.9908532500267029, "text_region": [[154.0, 1275.0], [670.0, 1275.0], [670.0, 1301.0], [154.0, 1301.0]]}, {"text": "Mitigation strategy.", "confidence": 0.9663162231445312, "text_region": [[967.0, 1295.0], [1265.0, 1301.0], [1264.0, 1340.0], [967.0, 1333.0]]}, {"text": "in the context. For instance, a user asks,", "confidence": 0.9791426062583923, "text_region": [[150.0, 1307.0], [643.0, 1309.0], [642.0, 1336.0], [150.0, 1334.0]]}, {"text": "\"What are the complications of untreated", "confidence": 0.9979612231254578, "text_region": [[154.0, 1343.0], [673.0, 1343.0], [673.0, 1369.0], [154.0, 1369.0]]}, {"text": "hypertension?\" The correct document is in", "confidence": 0.9958623647689819, "text_region": [[154.0, 1380.0], [679.0, 1380.0], [679.0, 1406.0], [154.0, 1406.0]]}, {"text": "The best way to address this", "confidence": 0.9969913363456726, "text_region": [[853.0, 1402.0], [1210.0, 1402.0], [1210.0, 1427.0], [853.0, 1427.0]]}, {"text": "the context, but the model fails to extract the", "confidence": 0.9889198541641235, "text_region": [[156.0, 1417.0], [708.0, 1417.0], [708.0, 1437.0], [156.0, 1437.0]]}, {"text": "problem is to fine-tune the model", "confidence": 0.9994887113571167, "text_region": [[851.0, 1437.0], [1274.0, 1435.0], [1274.0, 1462.0], [851.0, 1464.0]]}, {"text": "relevant information. So, the user might get a", "confidence": 0.997723400592804, "text_region": [[152.0, 1450.0], [716.0, 1450.0], [716.0, 1476.0], [152.0, 1476.0]]}, {"text": "to better understand the domain", "confidence": 0.9997566938400269, "text_region": [[849.0, 1470.0], [1266.0, 1472.0], [1266.0, 1499.0], [849.0, 1497.0]]}, {"text": "generic response like \"hypertension can lead", "confidence": 0.9734203219413757, "text_region": [[150.0, 1481.0], [716.0, 1479.0], [716.0, 1512.0], [150.0, 1514.0]]}, {"text": "context, irrespective of noise or", "confidence": 0.9997691512107849, "text_region": [[851.0, 1507.0], [1241.0, 1505.0], [1241.0, 1532.0], [851.0, 1534.0]]}, {"text": "to serious health issues.'", "confidence": 0.9986130595207214, "text_region": [[154.0, 1522.0], [455.0, 1522.0], [455.0, 1542.0], [154.0, 1542.0]]}, {"text": "conflicting information. In this case,", "confidence": 0.9809489250183105, "text_region": [[853.0, 1542.0], [1293.0, 1542.0], [1293.0, 1569.0], [853.0, 1569.0]]}, {"text": "extensive data pre-processing", "confidence": 0.9999179840087891, "text_region": [[851.0, 1575.0], [1239.0, 1579.0], [1239.0, 1606.0], [851.0, 1602.0]]}, {"text": "to clean and structure the data", "confidence": 0.999805748462677, "text_region": [[851.0, 1612.0], [1247.0, 1612.0], [1247.0, 1637.0], [851.0, 1637.0]]}, {"text": "is important before the training", "confidence": 0.9816604852676392, "text_region": [[851.0, 1644.0], [1241.0, 1649.0], [1241.0, 1676.0], [851.0, 1672.0]]}, {"text": "process.", "confidence": 0.9991295337677002, "text_region": [[851.0, 1684.0], [956.0, 1679.0], [958.0, 1706.0], [852.0, 1711.0]]}, {"text": "Galileo", "confidence": 0.9910891652107239, "text_region": [[246.0, 1992.0], [353.0, 1997.0], [352.0, 2032.0], [244.0, 2027.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9960396885871887, "text_region": [[1150.0, 2006.0], [1336.0, 2006.0], [1336.0, 2025.0], [1150.0, 2025.0]]}], "img_idx": 0}

{"type": "text", "bbox": [152, 285, 751, 707], "res": [{"text": "The question involves extracting information", "confidence": 0.9968027472496033, "text_region": [[155.0, 293.0], [706.0, 294.0], [706.0, 317.0], [155.0, 316.0]]}, {"text": "in a specific format, such as a table or list,", "confidence": 0.9985038042068481, "text_region": [[155.0, 330.0], [673.0, 330.0], [673.0, 353.0], [155.0, 353.0]]}, {"text": "and the model disregards the instruction. This", "confidence": 0.9939463138580322, "text_region": [[155.0, 364.0], [723.0, 364.0], [723.0, 387.0], [155.0, 387.0]]}, {"text": "is a common problem you might face when", "confidence": 0.9919825792312622, "text_region": [[155.0, 400.0], [701.0, 400.0], [701.0, 423.0], [155.0, 423.0]]}, {"text": "interacting with LLMs. This can be due to the", "confidence": 0.9865254163742065, "text_region": [[155.0, 435.0], [698.0, 435.0], [698.0, 458.0], [155.0, 458.0]]}, {"text": "model's inability to interpret specific formatting", "confidence": 0.9995495676994324, "text_region": [[154.0, 468.0], [741.0, 471.0], [741.0, 495.0], [154.0, 492.0]]}, {"text": "instructions, either due to inadequate training", "confidence": 0.9996017217636108, "text_region": [[155.0, 502.0], [722.0, 506.0], [722.0, 531.0], [155.0, 526.0]]}, {"text": "or if your instruction is vague. However, you", "confidence": 0.9899117946624756, "text_region": [[156.0, 539.0], [692.0, 540.0], [692.0, 564.0], [156.0, 563.0]]}, {"text": "can quickly address this issue with a follow-up", "confidence": 0.995611310005188, "text_region": [[156.0, 575.0], [731.0, 575.0], [731.0, 598.0], [156.0, 598.0]]}, {"text": "prompt where you instruct the LLM to give you", "confidence": 0.9907032251358032, "text_region": [[156.0, 611.0], [723.0, 611.0], [723.0, 634.0], [156.0, 634.0]]}, {"text": "the same response in the form of a table, list,", "confidence": 0.9863792061805725, "text_region": [[155.0, 645.0], [712.0, 645.0], [712.0, 668.0], [155.0, 668.0]]}, {"text": "Or format you'd like", "confidence": 0.9776976704597473, "text_region": [[157.0, 680.0], [395.0, 680.0], [395.0, 701.0], [157.0, 701.0]]}], "img_idx": 0}
{"type": "text", "bbox": [153, 1118, 735, 1642], "res": [{"text": "In this scenario, the model is either vague in", "confidence": 0.9978989958763123, "text_region": [[156.0, 1125.0], [699.0, 1125.0], [699.0, 1149.0], [156.0, 1149.0]]}, {"text": "its response or highly specific and, therefore,", "confidence": 0.9860849380493164, "text_region": [[156.0, 1160.0], [706.0, 1160.0], [706.0, 1184.0], [156.0, 1184.0]]}, {"text": "may not be a very apt response to your", "confidence": 0.9797576069831848, "text_region": [[156.0, 1195.0], [645.0, 1194.0], [645.0, 1218.0], [156.0, 1219.0]]}, {"text": "query. This usually happens if your query is.", "confidence": 0.9874787330627441, "text_region": [[157.0, 1230.0], [684.0, 1229.0], [684.0, 1253.0], [157.0, 1254.0]]}, {"text": "not very specific or lacks context. Say, \"what.", "confidence": 0.966454029083252, "text_region": [[155.0, 1264.0], [705.0, 1263.0], [705.0, 1288.0], [155.0, 1289.0]]}, {"text": "are the effects of stress?\". Here, the LLM has", "confidence": 0.989616870880127, "text_region": [[157.0, 1300.0], [691.0, 1300.0], [691.0, 1321.0], [157.0, 1321.0]]}, {"text": "no way of knowing if you want to know about", "confidence": 0.9943569898605347, "text_region": [[157.0, 1335.0], [714.0, 1335.0], [714.0, 1359.0], [157.0, 1359.0]]}, {"text": "osychological effects, short or long terms, etc.", "confidence": 0.995938241481781, "text_region": [[157.0, 1370.0], [722.0, 1369.0], [722.0, 1393.0], [157.0, 1394.0]]}, {"text": "So, it'll typically provide a generic answer that.", "confidence": 0.9780367016792297, "text_region": [[158.0, 1405.0], [723.0, 1405.0], [723.0, 1429.0], [158.0, 1429.0]]}, {"text": "may not answer your question or, in some", "confidence": 0.9933319091796875, "text_region": [[157.0, 1440.0], [675.0, 1440.0], [675.0, 1464.0], [157.0, 1464.0]]}, {"text": "cases, throw a lot of information at you! So", "confidence": 0.9858787655830383, "text_region": [[157.0, 1473.0], [681.0, 1473.0], [681.0, 1497.0], [157.0, 1497.0]]}, {"text": "what's happening is the LLM, having seen", "confidence": 0.9946190118789673, "text_region": [[156.0, 1510.0], [665.0, 1510.0], [665.0, 1534.0], [156.0, 1534.0]]}, {"text": "ooth in-depth answers and overviews in its", "confidence": 0.9820461273193359, "text_region": [[157.0, 1546.0], [688.0, 1546.0], [688.0, 1566.0], [157.0, 1566.0]]}, {"text": "training data, is unable to tune both detail", "confidence": 0.9997714757919312, "text_region": [[155.0, 1579.0], [679.0, 1578.0], [679.0, 1602.0], [155.0, 1603.0]]}, {"text": "and conciseness to your needs", "confidence": 0.9969489574432373, "text_region": [[157.0, 1615.0], [541.0, 1615.0], [541.0, 1636.0], [157.0, 1636.0]]}], "img_idx": 0}
{"type": "title", "bbox": [154, 1008, 694, 1064], "res": [{"text": "NCORRECT SPECIFICITY", "confidence": 0.935641884803772, "text_region": [[159.0, 1024.0], [688.0, 1024.0], [688.0, 1053.0], [159.0, 1053.0]]}], "img_idx": 0}
{"type": "title", "bbox": [153, 185, 531, 246], "res": [{"text": "WRONG FORMAT", "confidence": 0.9933347105979919, "text_region": [[159.0, 203.0], [526.0, 203.0], [526.0, 233.0], [159.0, 233.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [146, 296, 1473, 2105], "res": [{"text": "The question involves extracting information", "confidence": 0.9943849444389343, "text_region": [[154.0, 296.0], [708.0, 296.0], [708.0, 320.0], [154.0, 320.0]]}, {"text": "in a specific format, such as a table or list,", "confidence": 0.99892657995224, "text_region": [[152.0, 328.0], [676.0, 328.0], [676.0, 353.0], [152.0, 353.0]]}, {"text": "and the model disregards the instruction. This", "confidence": 0.9996761679649353, "text_region": [[152.0, 364.0], [723.0, 364.0], [723.0, 388.0], [152.0, 388.0]]}, {"text": "is a common problem you might face when", "confidence": 0.9931281805038452, "text_region": [[152.0, 398.0], [702.0, 398.0], [702.0, 424.0], [152.0, 424.0]]}, {"text": "Mitigation strategy", "confidence": 0.9987332224845886, "text_region": [[957.0, 416.0], [1257.0, 424.0], [1255.0, 464.0], [956.0, 456.0]]}, {"text": "interacting with LLMs. This can be due to the", "confidence": 0.9881861209869385, "text_region": [[152.0, 434.0], [698.0, 434.0], [698.0, 458.0], [152.0, 458.0]]}, {"text": "model's inability to interpret specific formatting", "confidence": 0.9997174739837646, "text_region": [[150.0, 467.0], [742.0, 469.0], [742.0, 496.0], [150.0, 494.0]]}, {"text": "instructions, either due to inadequate training.", "confidence": 0.9750798344612122, "text_region": [[148.0, 498.0], [725.0, 501.0], [725.0, 534.0], [148.0, 530.0]]}, {"text": "or if your instruction is vague. However, you", "confidence": 0.981092095375061, "text_region": [[152.0, 537.0], [691.0, 539.0], [691.0, 565.0], [152.0, 564.0]]}, {"text": "The onus is on the user to provide.", "confidence": 0.9865330457687378, "text_region": [[853.0, 537.0], [1269.0, 537.0], [1269.0, 562.0], [853.0, 562.0]]}, {"text": "can quickly address this issue with a follow-up.", "confidence": 0.9944343566894531, "text_region": [[154.0, 573.0], [732.0, 573.0], [732.0, 599.0], [154.0, 599.0]]}, {"text": "clear instructions of what specific.", "confidence": 0.9820816516876221, "text_region": [[851.0, 573.0], [1269.0, 573.0], [1269.0, 597.0], [851.0, 597.0]]}, {"text": "prompt where you instruct the LLM to give you", "confidence": 0.9979906678199768, "text_region": [[150.0, 607.0], [725.0, 609.0], [725.0, 635.0], [150.0, 633.0]]}, {"text": "format they'd like to receive the.", "confidence": 0.9956102967262268, "text_region": [[851.0, 607.0], [1245.0, 607.0], [1245.0, 631.0], [851.0, 631.0]]}, {"text": "the same response in the form of a table, list,", "confidence": 0.972449541091919, "text_region": [[150.0, 641.0], [712.0, 643.0], [711.0, 669.0], [150.0, 667.0]]}, {"text": "response in. It also helps to have", "confidence": 0.9801586270332336, "text_region": [[849.0, 643.0], [1256.0, 641.0], [1256.0, 667.0], [849.0, 669.0]]}, {"text": "or format you'd like.", "confidence": 0.9678134918212891, "text_region": [[152.0, 679.0], [397.0, 679.0], [397.0, 705.0], [152.0, 705.0]]}, {"text": "multiple format types in the training.", "confidence": 0.9937453866004944, "text_region": [[851.0, 679.0], [1300.0, 679.0], [1300.0, 705.0], [851.0, 705.0]]}, {"text": "dataset as part of the model fine-", "confidence": 0.9977946281433105, "text_region": [[851.0, 712.0], [1273.0, 712.0], [1273.0, 739.0], [851.0, 739.0]]}, {"text": "tuning process, so the LLM can be", "confidence": 0.9957399368286133, "text_region": [[851.0, 748.0], [1269.0, 748.0], [1269.0, 775.0], [851.0, 775.0]]}, {"text": "more accurate when responding", "confidence": 0.9998518824577332, "text_region": [[849.0, 780.0], [1264.0, 784.0], [1264.0, 811.0], [849.0, 807.0]]}, {"text": "INCORRECT SPECIFICITY", "confidence": 0.988967776298523, "text_region": [[152.0, 1018.0], [691.0, 1018.0], [691.0, 1055.0], [152.0, 1055.0]]}, {"text": "In this scenario, the model is either vague in", "confidence": 0.9928938150405884, "text_region": [[152.0, 1123.0], [698.0, 1123.0], [698.0, 1148.0], [152.0, 1148.0]]}, {"text": "its response or highly specific and, therefore,", "confidence": 0.9775229692459106, "text_region": [[152.0, 1159.0], [706.0, 1159.0], [706.0, 1185.0], [152.0, 1185.0]]}, {"text": "may not be a very apt response to your", "confidence": 0.9815381765365601, "text_region": [[152.0, 1195.0], [646.0, 1195.0], [646.0, 1219.0], [152.0, 1219.0]]}, {"text": "query. This usually happens if your query is", "confidence": 0.9866897463798523, "text_region": [[152.0, 1229.0], [687.0, 1229.0], [687.0, 1255.0], [152.0, 1255.0]]}, {"text": "not very specific or lacks context. Say, \"What", "confidence": 0.9941264986991882, "text_region": [[152.0, 1261.0], [704.0, 1261.0], [704.0, 1287.0], [152.0, 1287.0]]}, {"text": "Mitigation strategy", "confidence": 0.9996851682662964, "text_region": [[957.0, 1253.0], [1256.0, 1257.0], [1256.0, 1291.0], [956.0, 1287.0]]}, {"text": "are the effects of stress?\". Here, the LLM has", "confidence": 0.9847415685653687, "text_region": [[152.0, 1298.0], [693.0, 1298.0], [693.0, 1323.0], [152.0, 1323.0]]}, {"text": "no way of knowing if you want to know about.", "confidence": 0.9849860668182373, "text_region": [[152.0, 1332.0], [713.0, 1332.0], [713.0, 1357.0], [152.0, 1357.0]]}, {"text": "psychological effects, short or long terms, etc.", "confidence": 0.9828864932060242, "text_region": [[154.0, 1368.0], [721.0, 1368.0], [721.0, 1395.0], [154.0, 1395.0]]}, {"text": "An interactive query generation", "confidence": 0.9957684278488159, "text_region": [[851.0, 1361.0], [1249.0, 1361.0], [1249.0, 1387.0], [851.0, 1387.0]]}, {"text": "LLM that suggests alternate queries", "confidence": 0.9777121543884277, "text_region": [[847.0, 1391.0], [1296.0, 1393.0], [1296.0, 1425.0], [847.0, 1423.0]]}, {"text": "So, it'll typically provide a generic answer that", "confidence": 0.9929099082946777, "text_region": [[154.0, 1404.0], [723.0, 1404.0], [723.0, 1430.0], [154.0, 1430.0]]}, {"text": "with additional context can be a", "confidence": 0.9964013695716858, "text_region": [[849.0, 1428.0], [1256.0, 1430.0], [1256.0, 1457.0], [849.0, 1455.0]]}, {"text": "may not answer your question or, in some", "confidence": 0.994655966758728, "text_region": [[152.0, 1438.0], [676.0, 1438.0], [676.0, 1464.0], [152.0, 1464.0]]}, {"text": "cases, throw a lot of information at you! So", "confidence": 0.9967131018638611, "text_region": [[152.0, 1472.0], [683.0, 1474.0], [683.0, 1500.0], [152.0, 1498.0]]}, {"text": "great strategy here. The user can", "confidence": 0.9985716938972473, "text_region": [[851.0, 1466.0], [1266.0, 1466.0], [1266.0, 1493.0], [851.0, 1493.0]]}, {"text": "then refine the query by adding", "confidence": 0.9938759207725525, "text_region": [[849.0, 1498.0], [1245.0, 1502.0], [1245.0, 1528.0], [849.0, 1525.0]]}, {"text": "what's happening is the LLM, having seen", "confidence": 0.9930415153503418, "text_region": [[154.0, 1510.0], [666.0, 1510.0], [666.0, 1534.0], [154.0, 1534.0]]}, {"text": "both in-depth answers and overviews in its", "confidence": 0.9932599067687988, "text_region": [[152.0, 1543.0], [691.0, 1543.0], [691.0, 1568.0], [152.0, 1568.0]]}, {"text": "or removing information before", "confidence": 0.9838407635688782, "text_region": [[851.0, 1536.0], [1245.0, 1536.0], [1245.0, 1562.0], [851.0, 1562.0]]}, {"text": "training data, is unable to tune both detail", "confidence": 0.9997551441192627, "text_region": [[152.0, 1579.0], [679.0, 1579.0], [679.0, 1604.0], [152.0, 1604.0]]}, {"text": "sending it to the LLM.", "confidence": 0.9994027614593506, "text_region": [[851.0, 1572.0], [1107.0, 1572.0], [1107.0, 1596.0], [851.0, 1596.0]]}, {"text": "and conciseness to your needs", "confidence": 0.999695360660553, "text_region": [[152.0, 1615.0], [542.0, 1615.0], [542.0, 1640.0], [152.0, 1640.0]]}, {"text": "Galileo", "confidence": 0.9957697987556458, "text_region": [[243.0, 1992.0], [352.0, 1996.0], [350.0, 2032.0], [242.0, 2027.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9903985261917114, "text_region": [[1147.0, 2003.0], [1339.0, 2003.0], [1339.0, 2028.0], [1147.0, 2028.0]]}], "img_idx": 0}

{"type": "text", "bbox": [154, 284, 748, 602], "res": [{"text": "Incomplete answers are accurate but", "confidence": 0.9742740988731384, "text_region": [[157.0, 295.0], [625.0, 294.0], [625.0, 315.0], [157.0, 316.0]]}, {"text": "Iack some information, even though that", "confidence": 0.9895949959754944, "text_region": [[157.0, 330.0], [663.0, 330.0], [663.0, 353.0], [157.0, 353.0]]}, {"text": "information was present in the context and", "confidence": 0.9990888237953186, "text_region": [[157.0, 364.0], [691.0, 364.0], [691.0, 387.0], [157.0, 387.0]]}, {"text": "available for extraction. Say you ask, \"What are", "confidence": 0.9892677664756775, "text_region": [[156.0, 398.0], [736.0, 399.0], [736.0, 423.0], [156.0, 422.0]]}, {"text": "the treatments for osteoarthritis?\" and you only", "confidence": 0.999640703201294, "text_region": [[155.0, 433.0], [740.0, 434.0], [740.0, 458.0], [155.0, 457.0]]}, {"text": "get some medication options even though", "confidence": 0.9995598196983337, "text_region": [[157.0, 470.0], [686.0, 470.0], [686.0, 494.0], [157.0, 494.0]]}, {"text": "the documents that it's referring to have all", "confidence": 0.995737612247467, "text_region": [[157.0, 505.0], [693.0, 505.0], [693.0, 527.0], [157.0, 527.0]]}, {"text": "medication techniques available along with", "confidence": 0.998624324798584, "text_region": [[157.0, 539.0], [701.0, 539.0], [701.0, 563.0], [157.0, 563.0]]}, {"text": "therapy and lifestyle changes..", "confidence": 0.9778303503990173, "text_region": [[156.0, 572.0], [528.0, 574.0], [528.0, 598.0], [156.0, 596.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [141, 235, 1269, 2105], "res": [{"text": "Incomplete answers are accurate but.", "confidence": 0.9881541728973389, "text_region": [[153.0, 293.0], [629.0, 293.0], [629.0, 319.0], [153.0, 319.0]]}, {"text": "Iack some information, even though that", "confidence": 0.9853445291519165, "text_region": [[153.0, 329.0], [664.0, 329.0], [664.0, 354.0], [153.0, 354.0]]}, {"text": "information was present in the context and", "confidence": 0.9918440580368042, "text_region": [[153.0, 364.0], [691.0, 364.0], [691.0, 389.0], [153.0, 389.0]]}, {"text": "available for extraction. Say you ask, \"What are", "confidence": 0.9950202107429504, "text_region": [[153.0, 399.0], [738.0, 399.0], [738.0, 424.0], [153.0, 424.0]]}, {"text": "Mitigation strateg.", "confidence": 0.968163013458252, "text_region": [[987.0, 424.0], [1263.0, 426.0], [1263.0, 459.0], [987.0, 457.0]]}, {"text": "the treatments for osteoarthritis?\" and you only.", "confidence": 0.9870190620422363, "text_region": [[151.0, 434.0], [742.0, 434.0], [742.0, 459.0], [151.0, 459.0]]}, {"text": "get some medication options even though", "confidence": 0.9950639605522156, "text_region": [[151.0, 469.0], [687.0, 467.0], [687.0, 494.0], [151.0, 496.0]]}, {"text": "the documents that it's referring to have all", "confidence": 0.99833083152771, "text_region": [[153.0, 504.0], [693.0, 504.0], [693.0, 529.0], [153.0, 529.0]]}, {"text": "medication techniques available along with", "confidence": 0.9935697913169861, "text_region": [[153.0, 539.0], [703.0, 539.0], [703.0, 566.0], [153.0, 566.0]]}, {"text": "The model will require additional.", "confidence": 0.9705883264541626, "text_region": [[854.0, 533.0], [1261.0, 533.0], [1261.0, 558.0], [854.0, 558.0]]}, {"text": "therapy and lifestyle changes.", "confidence": 0.9988740086555481, "text_region": [[153.0, 574.0], [529.0, 574.0], [529.0, 601.0], [153.0, 601.0]]}, {"text": "training on diverse summarizatio", "confidence": 0.9998849034309387, "text_region": [[852.0, 568.0], [1265.0, 568.0], [1265.0, 595.0], [852.0, 595.0]]}, {"text": "data (specific to the domain) to", "confidence": 0.9993947744369507, "text_region": [[854.0, 603.0], [1255.0, 603.0], [1255.0, 630.0], [854.0, 630.0]]}, {"text": "In this case, the LLM cannot integrate multiple", "confidence": 0.9957104325294495, "text_region": [[153.0, 644.0], [723.0, 644.0], [723.0, 669.0], [153.0, 669.0]]}, {"text": "understand which summaries wc", "confidence": 0.9843634963035583, "text_region": [[852.0, 638.0], [1267.0, 638.0], [1267.0, 664.0], [852.0, 664.0]]}, {"text": "pieces of related information into a cohesive", "confidence": 0.9942710995674133, "text_region": [[153.0, 679.0], [711.0, 679.0], [711.0, 704.0], [153.0, 704.0]]}, {"text": "best in which areas. Once the mc", "confidence": 0.9834411144256592, "text_region": [[852.0, 673.0], [1265.0, 673.0], [1265.0, 699.0], [852.0, 699.0]]}, {"text": "and complete answer, which provides you with", "confidence": 0.9996944069862366, "text_region": [[153.0, 714.0], [738.0, 714.0], [738.0, 740.0], [153.0, 740.0]]}, {"text": "has improved its summarization", "confidence": 0.9848319888114929, "text_region": [[854.0, 712.0], [1255.0, 712.0], [1255.0, 732.0], [854.0, 732.0]]}, {"text": "an accurate but partial response.", "confidence": 0.9997966885566711, "text_region": [[153.0, 749.0], [572.0, 749.0], [572.0, 775.0], [153.0, 775.0]]}, {"text": "capabilities, it can prioritize what", "confidence": 0.9893592000007629, "text_region": [[852.0, 743.0], [1265.0, 743.0], [1265.0, 769.0], [852.0, 769.0]]}, {"text": "information to include in its respo", "confidence": 0.9781133532524109, "text_region": [[848.0, 776.0], [1267.0, 779.0], [1267.0, 806.0], [848.0, 804.0]]}, {"text": "so it's detailed while maintaining", "confidence": 0.9867494106292725, "text_region": [[850.0, 812.0], [1263.0, 814.0], [1263.0, 841.0], [850.0, 839.0]]}, {"text": "conciseness.", "confidence": 0.9998930096626282, "text_region": [[850.0, 847.0], [1015.0, 849.0], [1014.0, 876.0], [850.0, 874.0]]}, {"text": "Apart from the seven pain points we saw above, there can also be other challenges.", "confidence": 0.9972520470619202, "text_region": [[153.0, 971.0], [1195.0, 971.0], [1195.0, 999.0], [153.0, 999.0]]}, {"text": "associated with RAGs, which you might already be familiar with. They're detailed below:", "confidence": 0.9979162812232971, "text_region": [[153.0, 1008.0], [1242.0, 1008.0], [1242.0, 1034.0], [153.0, 1034.0]]}, {"text": "Speed of retrieval:.", "confidence": 0.9804309010505676, "text_region": [[329.0, 1090.0], [564.0, 1090.0], [564.0, 1117.0], [329.0, 1117.0]]}, {"text": "LLM combined with RAG can be much slower than standard LLMs. This woul.", "confidence": 0.994442880153656, "text_region": [[337.0, 1160.0], [1263.0, 1160.0], [1263.0, 1186.0], [337.0, 1186.0]]}, {"text": "require additional focus on optimizing tokenization, encoding, and retrieval.", "confidence": 0.9913917779922485, "text_region": [[327.0, 1197.0], [1263.0, 1197.0], [1263.0, 1223.0], [327.0, 1223.0]]}, {"text": "Safety:", "confidence": 0.9998046159744263, "text_region": [[148.0, 1304.0], [249.0, 1309.0], [248.0, 1342.0], [146.0, 1337.0]]}, {"text": "It's possible that the documents used for RAG can be poisoned through external.", "confidence": 0.9953352808952332, "text_region": [[151.0, 1378.0], [1152.0, 1380.0], [1151.0, 1408.0], [151.0, 1406.0]]}, {"text": "attacks and then inject misinformation. This will ultimately be reflected in the LLM.", "confidence": 0.9880500435829163, "text_region": [[151.0, 1415.0], [1161.0, 1415.0], [1161.0, 1441.0], [151.0, 1441.0]]}, {"text": "response.", "confidence": 0.9994702935218811, "text_region": [[155.0, 1454.0], [274.0, 1454.0], [274.0, 1476.0], [155.0, 1476.0]]}, {"text": "Bias and privacy:", "confidence": 0.999310314655304, "text_region": [[329.0, 1560.0], [550.0, 1560.0], [550.0, 1587.0], [329.0, 1587.0]]}, {"text": "There can be scenarios when documents used in the RAG system can hav.", "confidence": 0.9853073358535767, "text_region": [[335.0, 1630.0], [1265.0, 1630.0], [1265.0, 1655.0], [335.0, 1655.0]]}, {"text": "personal details or perhaps biases. When these documents are retrieved as.", "confidence": 0.9858194589614868, "text_region": [[329.0, 1665.0], [1267.0, 1665.0], [1267.0, 1690.0], [329.0, 1690.0]]}, {"text": "of the retrieval process, the LLM will augment its response by looking at ther.", "confidence": 0.9721894264221191, "text_region": [[329.0, 1700.0], [1267.0, 1700.0], [1267.0, 1725.0], [329.0, 1725.0]]}, {"text": "eventually resulting in privacy concerns and perpetuation of bias..", "confidence": 0.9894877076148987, "text_region": [[329.0, 1735.0], [1144.0, 1735.0], [1144.0, 1760.0], [329.0, 1760.0]]}, {"text": "In the next chapter, we'll look at ways to enhance the reliability of RAG systems throug!.", "confidence": 0.9863395690917969, "text_region": [[186.0, 1842.0], [1263.0, 1844.0], [1263.0, 1871.0], [186.0, 1869.0]]}, {"text": "wide range of prompting techniques-and explore fun techniques you can use the nex", "confidence": 0.9991474151611328, "text_region": [[188.0, 1881.0], [1265.0, 1881.0], [1265.0, 1906.0], [188.0, 1906.0]]}, {"text": "time you use LLMs!.", "confidence": 0.9735616445541382, "text_region": [[188.0, 1914.0], [423.0, 1914.0], [423.0, 1939.0], [188.0, 1939.0]]}, {"text": "Galileo", "confidence": 0.9969307780265808, "text_region": [[247.0, 1996.0], [353.0, 1996.0], [353.0, 2031.0], [247.0, 2031.0]]}, {"text": "www.runga", "confidence": 0.9930820465087891, "text_region": [[1148.0, 2006.0], [1265.0, 2006.0], [1265.0, 2027.0], [1148.0, 2027.0]]}], "img_idx": 0}

{"type": "figure", "bbox": [0, 0, 1487, 2104], "res": [{"text": "PREFACE", "confidence": 0.9988039135932922, "text_region": [[150.0, 206.0], [438.0, 206.0], [438.0, 259.0], [150.0, 259.0]]}, {"text": "It's fascinating how quickly we've gotten", "confidence": 0.9959618449211121, "text_region": [[150.0, 381.0], [657.0, 381.0], [657.0, 410.0], [150.0, 410.0]]}, {"text": "Generation (RAG), which helps provide", "confidence": 0.9772299528121948, "text_region": [[772.0, 377.0], [1259.0, 379.0], [1259.0, 410.0], [772.0, 408.0]]}, {"text": "accustomed to \"prompt and you shall get'", "confidence": 0.9867280721664429, "text_region": [[153.0, 414.0], [682.0, 414.0], [682.0, 436.0], [153.0, 436.0]]}, {"text": "additional context to enhance LLM responses", "confidence": 0.9854433536529541, "text_region": [[774.0, 412.0], [1332.0, 412.0], [1332.0, 434.0], [774.0, 434.0]]}, {"text": "wizardry, haven't we? What was once far-", "confidence": 0.9926906824111938, "text_region": [[150.0, 441.0], [670.0, 441.0], [670.0, 469.0], [150.0, 469.0]]}, {"text": "by pulling in information from external", "confidence": 0.9751642942428589, "text_region": [[774.0, 441.0], [1252.0, 441.0], [1252.0, 469.0], [774.0, 469.0]]}, {"text": "fetched, a bold idea in a sci-fi novel, has", "confidence": 0.9927322268486023, "text_region": [[148.0, 473.0], [655.0, 473.0], [655.0, 495.0], [148.0, 495.0]]}, {"text": "databases or documents the user provides.", "confidence": 0.9953145384788513, "text_region": [[774.0, 471.0], [1321.0, 471.0], [1321.0, 500.0], [774.0, 500.0]]}, {"text": "already found widespread popularity, so", "confidence": 0.9888226389884949, "text_region": [[150.0, 502.0], [659.0, 502.0], [659.0, 530.0], [150.0, 530.0]]}, {"text": "This means each response now is more", "confidence": 0.9908227920532227, "text_region": [[777.0, 504.0], [1270.0, 504.0], [1270.0, 526.0], [777.0, 526.0]]}, {"text": "much so that we run to answering engines", "confidence": 0.9997099041938782, "text_region": [[150.0, 530.0], [686.0, 530.0], [686.0, 559.0], [150.0, 559.0]]}, {"text": "specific, contextual, and in-depth-instead", "confidence": 0.9948170781135559, "text_region": [[774.0, 530.0], [1312.0, 530.0], [1312.0, 559.0], [774.0, 559.0]]}, {"text": "for quick recipes, lesson plans, travel", "confidence": 0.9874778389930725, "text_region": [[148.0, 561.0], [611.0, 561.0], [611.0, 590.0], [148.0, 590.0]]}, {"text": "of just relying on an LLM>s pre-learned", "confidence": 0.992656409740448, "text_region": [[774.0, 561.0], [1250.0, 561.0], [1250.0, 590.0], [774.0, 590.0]]}, {"text": "itineraries, homework help, and a medley of", "confidence": 0.9965823888778687, "text_region": [[150.0, 592.0], [699.0, 592.0], [699.0, 620.0], [150.0, 620.0]]}, {"text": "information. It also addresses the problem", "confidence": 0.9978569746017456, "text_region": [[772.0, 592.0], [1301.0, 592.0], [1301.0, 614.0], [772.0, 614.0]]}, {"text": "other things-life advice, even!", "confidence": 0.9748968482017517, "text_region": [[153.0, 625.0], [535.0, 625.0], [535.0, 647.0], [153.0, 647.0]]}, {"text": "of \"hallucinations\" to a great extent-along", "confidence": 0.9798451066017151, "text_region": [[772.0, 618.0], [1310.0, 620.0], [1310.0, 651.0], [772.0, 649.0]]}, {"text": "with enabling real-time context, in addition", "confidence": 0.9956426620483398, "text_region": [[774.0, 653.0], [1312.0, 653.0], [1312.0, 675.0], [774.0, 675.0]]}, {"text": " Large language models (Llms), a term", "confidence": 0.9615882635116577, "text_region": [[146.0, 679.0], [631.0, 677.0], [631.0, 708.0], [146.0, 710.0]]}, {"text": "to user-provided information, and factuality.", "confidence": 0.9928609132766724, "text_region": [[772.0, 682.0], [1325.0, 682.0], [1325.0, 710.0], [772.0, 710.0]]}, {"text": "sometimes interchangeably used", "confidence": 0.9913553595542908, "text_region": [[153.0, 714.0], [575.0, 714.0], [575.0, 736.0], [153.0, 736.0]]}, {"text": "of responses.", "confidence": 0.9958192110061646, "text_region": [[774.0, 714.0], [945.0, 714.0], [945.0, 741.0], [774.0, 741.0]]}, {"text": "with OpenAI's ChatGPT, have become", "confidence": 0.9907616972923279, "text_region": [[150.0, 741.0], [624.0, 741.0], [624.0, 769.0], [150.0, 769.0]]}, {"text": "mainstream-ranking in the top 5% of all", "confidence": 0.9986502528190613, "text_region": [[150.0, 769.0], [657.0, 769.0], [657.0, 798.0], [150.0, 798.0]]}, {"text": "However, implementing an enterprise-", "confidence": 0.9894988536834717, "text_region": [[774.0, 774.0], [1252.0, 774.0], [1252.0, 796.0], [774.0, 796.0]]}, {"text": "news coverage topics, just in the year 2023.", "confidence": 0.9923534989356995, "text_region": [[150.0, 802.0], [693.0, 802.0], [693.0, 831.0], [150.0, 831.0]]}, {"text": "level RAG system is rife with challenges.", "confidence": 0.977756142616272, "text_region": [[774.0, 802.0], [1268.0, 802.0], [1268.0, 831.0], [774.0, 831.0]]}, {"text": "As they become increasingly used across", "confidence": 0.9924171566963196, "text_region": [[150.0, 831.0], [673.0, 831.0], [673.0, 859.0], [150.0, 859.0]]}, {"text": "Firstly, there's no \"go-to\" framework that", "confidence": 0.9821704030036926, "text_region": [[774.0, 831.0], [1279.0, 831.0], [1279.0, 859.0], [774.0, 859.0]]}, {"text": "all industries, LLMs are poised to augment", "confidence": 0.973650336265564, "text_region": [[150.0, 861.0], [675.0, 861.0], [675.0, 890.0], [150.0, 890.0]]}, {"text": "developers can use as a reference before", "confidence": 0.9995468258857727, "text_region": [[774.0, 861.0], [1297.0, 861.0], [1297.0, 890.0], [774.0, 890.0]]}, {"text": "creative and technical tasks alike.", "confidence": 0.9964891672134399, "text_region": [[153.0, 894.0], [573.0, 894.0], [573.0, 916.0], [153.0, 916.0]]}, {"text": "they journey into this space. Then, there's", "confidence": 0.9970083236694336, "text_region": [[774.0, 892.0], [1290.0, 892.0], [1290.0, 920.0], [774.0, 920.0]]}, {"text": "very little research into productionizing these", "confidence": 0.9896074533462524, "text_region": [[774.0, 925.0], [1332.0, 925.0], [1332.0, 947.0], [774.0, 947.0]]}, {"text": "Ultimately, LLMs aren't magic. They've been", "confidence": 0.9948083758354187, "text_region": [[148.0, 951.0], [688.0, 951.0], [688.0, 980.0], [148.0, 980.0]]}, {"text": "complex systems, including the scenarios to", "confidence": 0.9998682737350464, "text_region": [[774.0, 951.0], [1330.0, 951.0], [1330.0, 980.0], [774.0, 980.0]]}, {"text": "trained on huge amounts of data and", "confidence": 0.9926145076751709, "text_region": [[153.0, 984.0], [626.0, 984.0], [626.0, 1006.0], [153.0, 1006.0]]}, {"text": "consider before and during this step. Lastly,", "confidence": 0.9998947978019714, "text_region": [[774.0, 982.0], [1319.0, 982.0], [1319.0, 1010.0], [774.0, 1010.0]]}, {"text": "these models have learned how to apply", "confidence": 0.9997344017028809, "text_region": [[148.0, 1008.0], [664.0, 1010.0], [664.0, 1041.0], [148.0, 1039.0]]}, {"text": "how does one monitor and refine the system", "confidence": 0.9920470118522644, "text_region": [[770.0, 1010.0], [1334.0, 1010.0], [1334.0, 1039.0], [770.0, 1039.0]]}, {"text": "information about one context to another.", "confidence": 0.9985837936401367, "text_region": [[150.0, 1041.0], [677.0, 1041.0], [677.0, 1070.0], [150.0, 1070.0]]}, {"text": "continuously after deployment?.", "confidence": 0.9871701002120972, "text_region": [[772.0, 1041.0], [1173.0, 1041.0], [1173.0, 1070.0], [772.0, 1070.0]]}, {"text": "This has made them smart autocomplete", "confidence": 0.9829767346382141, "text_region": [[153.0, 1074.0], [673.0, 1074.0], [673.0, 1096.0], [153.0, 1096.0]]}, {"text": "bots-generating coherent and relevant", "confidence": 0.9941676259040833, "text_region": [[150.0, 1105.0], [653.0, 1105.0], [653.0, 1127.0], [150.0, 1127.0]]}, {"text": "This \"ebook\" aims to be your go-to guide", "confidence": 0.9995870590209961, "text_region": [[774.0, 1100.0], [1288.0, 1100.0], [1288.0, 1129.0], [774.0, 1129.0]]}, {"text": "responses in most situations.", "confidence": 0.9826081395149231, "text_region": [[150.0, 1131.0], [516.0, 1131.0], [516.0, 1159.0], [150.0, 1159.0]]}, {"text": "for all things RAG-related. If you're a", "confidence": 0.9853904843330383, "text_region": [[774.0, 1131.0], [1230.0, 1131.0], [1230.0, 1159.0], [774.0, 1159.0]]}, {"text": "machine learning engineer, a data scientist,.", "confidence": 0.9818754196166992, "text_region": [[774.0, 1162.0], [1325.0, 1162.0], [1325.0, 1190.0], [774.0, 1190.0]]}, {"text": "But setting aside the discussion and debate", "confidence": 0.9787802696228027, "text_region": [[150.0, 1190.0], [701.0, 1190.0], [701.0, 1219.0], [150.0, 1219.0]]}, {"text": "an Al researcher, or a technical product", "confidence": 0.9696542620658875, "text_region": [[777.0, 1194.0], [1270.0, 1194.0], [1270.0, 1216.0], [777.0, 1216.0]]}, {"text": "on whether LLMs can truly understand,", "confidence": 0.9979850053787231, "text_region": [[150.0, 1221.0], [633.0, 1221.0], [633.0, 1249.0], [150.0, 1249.0]]}, {"text": "manager looking to educate, experiment", "confidence": 0.9978351593017578, "text_region": [[774.0, 1221.0], [1290.0, 1221.0], [1290.0, 1249.0], [774.0, 1249.0]]}, {"text": "interpret, and communicate, we, engineers.", "confidence": 0.9866877198219299, "text_region": [[148.0, 1249.0], [690.0, 1251.0], [690.0, 1280.0], [148.0, 1278.0]]}, {"text": "with, and build enterprise-level RAG-", "confidence": 0.9972290992736816, "text_region": [[774.0, 1251.0], [1230.0, 1251.0], [1230.0, 1280.0], [774.0, 1280.0]]}, {"text": "scientists, and users, must look at LLMs as", "confidence": 0.9770635366439819, "text_region": [[153.0, 1284.0], [670.0, 1284.0], [670.0, 1306.0], [153.0, 1306.0]]}, {"text": "powered LLM applications, this ebook can", "confidence": 0.9760324358940125, "text_region": [[777.0, 1284.0], [1292.0, 1284.0], [1292.0, 1306.0], [777.0, 1306.0]]}, {"text": "smart assistants-tools-that will provide us.", "confidence": 0.9841560125350952, "text_region": [[150.0, 1311.0], [701.0, 1311.0], [701.0, 1339.0], [150.0, 1339.0]]}, {"text": "be a great guide for you to refer to. Having", "confidence": 0.9909334778785706, "text_region": [[770.0, 1308.0], [1306.0, 1313.0], [1305.0, 1341.0], [770.0, 1337.0]]}, {"text": "with a gentle footing in all our tasks.", "confidence": 0.9980373978614807, "text_region": [[150.0, 1341.0], [602.0, 1341.0], [602.0, 1370.0], [150.0, 1370.0]]}, {"text": "said that, if you're a grad student or a", "confidence": 0.9951387643814087, "text_region": [[774.0, 1341.0], [1248.0, 1341.0], [1248.0, 1370.0], [774.0, 1370.0]]}, {"text": "computer scientist enthusiast looking for a", "confidence": 0.994324266910553, "text_region": [[777.0, 1374.0], [1308.0, 1374.0], [1308.0, 1396.0], [777.0, 1396.0]]}, {"text": "That said, this ebook assumes that you", "confidence": 0.99912029504776, "text_region": [[150.0, 1400.0], [639.0, 1400.0], [639.0, 1429.0], [150.0, 1429.0]]}, {"text": "comprehensive resource to understand the", "confidence": 0.9983161687850952, "text_region": [[774.0, 1403.0], [1317.0, 1400.0], [1317.0, 1425.0], [775.0, 1427.0]]}, {"text": "already have a basic understanding of", "confidence": 0.9899827241897583, "text_region": [[150.0, 1431.0], [642.0, 1431.0], [642.0, 1460.0], [150.0, 1460.0]]}, {"text": "nuances of qn RAG system, this ebook can", "confidence": 0.9653112292289734, "text_region": [[772.0, 1431.0], [1303.0, 1431.0], [1303.0, 1453.0], [772.0, 1453.0]]}, {"text": "how LLMs work and can build simple LLM", "confidence": 0.988222599029541, "text_region": [[150.0, 1462.0], [651.0, 1462.0], [651.0, 1484.0], [150.0, 1484.0]]}, {"text": "serve as a great starting point. The book is", "confidence": 0.976233720779419, "text_region": [[772.0, 1462.0], [1306.0, 1462.0], [1306.0, 1490.0], [772.0, 1490.0]]}, {"text": "applications. In the scope of this ebook,", "confidence": 0.9930569529533386, "text_region": [[148.0, 1490.0], [646.0, 1488.0], [646.0, 1519.0], [148.0, 1521.0]]}, {"text": "divided into six chapters:", "confidence": 0.9938369393348694, "text_region": [[772.0, 1490.0], [1087.0, 1493.0], [1086.0, 1521.0], [772.0, 1519.0]]}, {"text": "we're more interested in an architectural", "confidence": 0.9976699352264404, "text_region": [[150.0, 1521.0], [664.0, 1521.0], [664.0, 1550.0], [150.0, 1550.0]]}, {"text": "approach called Retrieval Augmented", "confidence": 0.9994773864746094, "text_region": [[150.0, 1552.0], [633.0, 1552.0], [633.0, 1580.0], [150.0, 1580.0]]}, {"text": "Galileo", "confidence": 0.9972215294837952, "text_region": [[242.0, 1992.0], [355.0, 1997.0], [353.0, 2034.0], [241.0, 2029.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9799603819847107, "text_region": [[1146.0, 2001.0], [1339.0, 2001.0], [1339.0, 2029.0], [1146.0, 2029.0]]}], "img_idx": 0}

{"type": "figure", "bbox": [0, 0, 1488, 2104], "res": [{"text": "20", "confidence": 0.9907227754592896, "text_region": [[1309.0, 116.0], [1331.0, 116.0], [1331.0, 138.0], [1309.0, 138.0]]}, {"text": "03", "confidence": 0.9877040386199951, "text_region": [[148.0, 206.0], [288.0, 206.0], [288.0, 298.0], [148.0, 298.0]]}, {"text": "REDUCE HALLUCINATIONSTHROUGH", "confidence": 0.9820504784584045, "text_region": [[157.0, 333.0], [1207.0, 333.0], [1207.0, 377.0], [157.0, 377.0]]}, {"text": "PROMPTING TECHNIQUES", "confidence": 0.9796178936958313, "text_region": [[153.0, 403.0], [886.0, 403.0], [886.0, 454.0], [153.0, 454.0]]}, {"text": "In the previous chapter, we looked at the different limitations associated with RAG systems. In", "confidence": 0.9970013499259949, "text_region": [[148.0, 511.0], [1318.0, 511.0], [1318.0, 539.0], [148.0, 539.0]]}, {"text": " this chapter, and all subsequent chapters, we will bridge these gaps. Our aim is to explore and.", "confidence": 0.9843952655792236, "text_region": [[146.0, 544.0], [1326.0, 546.0], [1326.0, 576.0], [146.0, 574.0]]}, {"text": " understand techniques that can help us improve the reliability, accuracy, and preciseness of.", "confidence": 0.990744948387146, "text_region": [[148.0, 579.0], [1318.0, 581.0], [1317.0, 611.0], [148.0, 609.0]]}, {"text": "RAG systems.", "confidence": 0.9996109008789062, "text_region": [[151.0, 618.0], [321.0, 618.0], [321.0, 644.0], [151.0, 644.0]]}, {"text": "Let's first look at different prompting techniques that can help reduce the likelihood of.", "confidence": 0.9925041198730469, "text_region": [[151.0, 682.0], [1222.0, 684.0], [1222.0, 715.0], [151.0, 712.0]]}, {"text": "incorrect content in the responses. Read on!.", "confidence": 0.9840543270111084, "text_region": [[151.0, 721.0], [706.0, 721.0], [706.0, 752.0], [151.0, 752.0]]}, {"text": "Galileo", "confidence": 0.9943222999572754, "text_region": [[243.0, 1989.0], [355.0, 1995.0], [353.0, 2034.0], [241.0, 2029.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9974594116210938, "text_region": [[1145.0, 2001.0], [1337.0, 1999.0], [1338.0, 2027.0], [1145.0, 2030.0]]}], "img_idx": 0}

{"type": "text", "bbox": [198, 308, 1290, 408], "res": [{"text": "idea behind chain of thought prompting is simple and effective: guide the model throu", "confidence": 0.9968475103378296, "text_region": [[204.0, 314.0], [1287.0, 315.0], [1287.0, 340.0], [204.0, 339.0]]}, {"text": "nples and it'll mimic your logic to answer your next set of queries. This is how you'd", "confidence": 0.9904572367668152, "text_region": [[203.0, 349.0], [1231.0, 349.0], [1231.0, 373.0], [203.0, 373.0]]}, {"text": "struct your prompt:", "confidence": 0.9928364157676697, "text_region": [[200.0, 382.0], [439.0, 384.0], [439.0, 405.0], [200.0, 403.0]]}], "img_idx": 0}
{"type": "text", "bbox": [198, 438, 1290, 603], "res": [{"text": "re a helpful chatbot who answers questions based on the provided context only. If the", "confidence": 0.9859820008277893, "text_region": [[203.0, 446.0], [1281.0, 446.0], [1281.0, 470.0], [203.0, 470.0]]}, {"text": "wer to the question is not in the context, you can politely say that you do not have the", "confidence": 0.9989467859268188, "text_region": [[203.0, 479.0], [1275.0, 479.0], [1275.0, 503.0], [203.0, 503.0]]}, {"text": "wer. Make sure you think step-by-step. Here's an example that you can go through to", "confidence": 0.9997740387916565, "text_region": [[201.0, 512.0], [1273.0, 512.0], [1273.0, 536.0], [201.0, 536.0]]}, {"text": "erstand the steps you need to follow to arrive at a logical conclusion before you provic", "confidence": 0.9939873218536377, "text_region": [[201.0, 544.0], [1285.0, 544.0], [1285.0, 568.0], [201.0, 568.0]]}, {"text": "r response.", "confidence": 0.9972093105316162, "text_region": [[199.0, 578.0], [336.0, 578.0], [336.0, 600.0], [199.0, 600.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [150, 704, 1377, 2104], "res": [{"text": "and heat, making life possible on Earth", "confidence": 0.9833077788352966, "text_region": [[157.0, 710.0], [641.0, 710.0], [641.0, 730.0], [157.0, 730.0]]}, {"text": "Question: What is the sun made of?.", "confidence": 0.9879173040390015, "text_region": [[157.0, 773.0], [603.0, 773.0], [603.0, 793.0], [157.0, 793.0]]}, {"text": "Understand the context first: The context discusses the sun, its location, composition, and", "confidence": 0.9920001029968262, "text_region": [[153.0, 834.0], [1269.0, 835.0], [1269.0, 860.0], [153.0, 859.0]]}, {"text": "energy generation process..", "confidence": 0.9847263693809509, "text_region": [[151.0, 867.0], [495.0, 864.0], [495.0, 894.0], [152.0, 897.0]]}, {"text": "Identify key information: The sun is composed primarily of hydrogen and helium.", "confidence": 0.9970637559890747, "text_region": [[153.0, 929.0], [1176.0, 930.0], [1176.0, 959.0], [153.0, 958.0]]}, {"text": "Go through it in a logical sequence like I've mentioned:", "confidence": 0.9905766248703003, "text_region": [[156.0, 966.0], [842.0, 966.0], [842.0, 991.0], [156.0, 991.0]]}, {"text": "Step1: The question asks about the composition of the sun.", "confidence": 0.9940700531005859, "text_region": [[154.0, 1031.0], [895.0, 1031.0], [895.0, 1055.0], [154.0, 1055.0]]}, {"text": "Step 2: According to the context, the sun is made primarily of hydrogen and helium", "confidence": 0.979949951171875, "text_region": [[156.0, 1063.0], [1199.0, 1063.0], [1199.0, 1088.0], [156.0, 1088.0]]}, {"text": "Step 3: Therefore, the answer is that the sun is made primarily of hydrogen and helium.", "confidence": 0.9834698438644409, "text_region": [[156.0, 1096.0], [1243.0, 1096.0], [1243.0, 1121.0], [156.0, 1121.0]]}, {"text": "Be polite when answering the question. If you don't have enough context to answer the", "confidence": 0.9977606534957886, "text_region": [[156.0, 1163.0], [1241.0, 1163.0], [1241.0, 1184.0], [156.0, 1184.0]]}, {"text": "question, then politely decline to do so. However, in this scenario, you have enough context", "confidence": 0.9909645318984985, "text_region": [[156.0, 1194.0], [1293.0, 1194.0], [1293.0, 1219.0], [156.0, 1219.0]]}, {"text": "and should be able to answer the question.", "confidence": 0.991669237613678, "text_region": [[152.0, 1225.0], [696.0, 1226.0], [696.0, 1251.0], [151.0, 1249.0]]}, {"text": "Answer: The sun is made primarily of hydrogen and helium", "confidence": 0.9995737075805664, "text_region": [[153.0, 1289.0], [899.0, 1290.0], [899.0, 1315.0], [153.0, 1314.0]]}, {"text": "Standard Prompting", "confidence": 0.9998906254768372, "text_region": [[193.0, 1373.0], [457.0, 1376.0], [457.0, 1401.0], [193.0, 1398.0]]}, {"text": "Chain-of-Thought Prompting.", "confidence": 0.9765517115592957, "text_region": [[731.0, 1373.0], [1109.0, 1375.0], [1109.0, 1401.0], [731.0, 1400.0]]}, {"text": "Model Input", "confidence": 0.9938331842422485, "text_region": [[222.0, 1436.0], [346.0, 1436.0], [346.0, 1457.0], [222.0, 1457.0]]}, {"text": "Model Input", "confidence": 0.9990387558937073, "text_region": [[753.0, 1435.0], [880.0, 1435.0], [880.0, 1459.0], [753.0, 1459.0]]}, {"text": "Q: Roger has 5 tennis balls. He buys 2", "confidence": 0.9996153116226196, "text_region": [[205.0, 1483.0], [576.0, 1483.0], [576.0, 1503.0], [205.0, 1503.0]]}, {"text": "Q: Roger has 5 tennis balls. He buys 2 more cans of", "confidence": 0.997658371925354, "text_region": [[738.0, 1483.0], [1247.0, 1483.0], [1247.0, 1503.0], [738.0, 1503.0]]}, {"text": "more cans of tennis balls. Each can has.", "confidence": 0.9660662412643433, "text_region": [[205.0, 1508.0], [600.0, 1508.0], [600.0, 1526.0], [205.0, 1526.0]]}, {"text": "tennis balls. Each can has 3 tennis balls. How many", "confidence": 0.9973945021629333, "text_region": [[736.0, 1505.0], [1249.0, 1508.0], [1249.0, 1528.0], [735.0, 1525.0]]}, {"text": "3 tennis balls. How many tennis balls.", "confidence": 0.9865540862083435, "text_region": [[205.0, 1529.0], [572.0, 1529.0], [572.0, 1548.0], [205.0, 1548.0]]}, {"text": "tennis balls does he have now?.", "confidence": 0.9790937304496765, "text_region": [[737.0, 1529.0], [1051.0, 1529.0], [1051.0, 1548.0], [737.0, 1548.0]]}, {"text": "does he have now?", "confidence": 0.9808535575866699, "text_region": [[205.0, 1553.0], [399.0, 1553.0], [399.0, 1572.0], [205.0, 1572.0]]}, {"text": "A: Roger started with 5 balls. 2 cans of 3 tennis balls", "confidence": 0.9863271713256836, "text_region": [[738.0, 1576.0], [1250.0, 1576.0], [1250.0, 1596.0], [738.0, 1596.0]]}, {"text": "A: The answer is 1l..", "confidence": 0.9100043773651123, "text_region": [[205.0, 1601.0], [387.0, 1601.0], [387.0, 1621.0], [205.0, 1621.0]]}, {"text": "each is 6 tennis balls. 5+6=1l. The answer is 1l.", "confidence": 0.9858691096305847, "text_region": [[738.0, 1601.0], [1191.0, 1601.0], [1191.0, 1620.0], [738.0, 1620.0]]}, {"text": "Q: The cafeteria had 23 apples. If they.", "confidence": 0.9902850985527039, "text_region": [[205.0, 1642.0], [579.0, 1642.0], [579.0, 1662.0], [205.0, 1662.0]]}, {"text": "Q: The cafeteria had 23 apples. If they used 20 to", "confidence": 0.9709724187850952, "text_region": [[738.0, 1642.0], [1225.0, 1642.0], [1225.0, 1662.0], [738.0, 1662.0]]}, {"text": "used 20 to make lunch and bought 6", "confidence": 0.9889323115348816, "text_region": [[206.0, 1666.0], [575.0, 1666.0], [575.0, 1687.0], [206.0, 1687.0]]}, {"text": "make lunch and bought 6 more, how many apples.", "confidence": 0.9899067878723145, "text_region": [[736.0, 1662.0], [1246.0, 1665.0], [1246.0, 1688.0], [735.0, 1685.0]]}, {"text": "more, how many apples do they have?.", "confidence": 0.9947507381439209, "text_region": [[206.0, 1693.0], [592.0, 1693.0], [592.0, 1713.0], [206.0, 1713.0]]}, {"text": "do they have?", "confidence": 0.9992367625236511, "text_region": [[738.0, 1687.0], [880.0, 1687.0], [880.0, 1707.0], [738.0, 1707.0]]}, {"text": "Model Output", "confidence": 0.9951120018959045, "text_region": [[215.0, 1754.0], [358.0, 1754.0], [358.0, 1774.0], [215.0, 1774.0]]}, {"text": "Model Output", "confidence": 0.9992699027061462, "text_region": [[756.0, 1754.0], [898.0, 1754.0], [898.0, 1774.0], [756.0, 1774.0]]}, {"text": "A: The cafeteria had 23 apples originally. They", "confidence": 0.9878454804420471, "text_region": [[725.0, 1799.0], [1182.0, 1799.0], [1182.0, 1820.0], [725.0, 1820.0]]}, {"text": "A: The answer is 27.", "confidence": 0.9571588635444641, "text_region": [[203.0, 1812.0], [390.0, 1812.0], [390.0, 1833.0], [203.0, 1833.0]]}, {"text": "used 20 to make lunch. So they had 23 - 20 = 3.", "confidence": 0.9802982807159424, "text_region": [[725.0, 1823.0], [1194.0, 1823.0], [1194.0, 1843.0], [725.0, 1843.0]]}, {"text": "They bought 6 more apples, so they have 3 + 6 =", "confidence": 0.9853998422622681, "text_region": [[721.0, 1843.0], [1207.0, 1841.0], [1207.0, 1866.0], [721.0, 1868.0]]}, {"text": "9. The answer is 9.", "confidence": 0.9981076121330261, "text_region": [[724.0, 1868.0], [904.0, 1868.0], [904.0, 1887.0], [724.0, 1887.0]]}, {"text": "Fig 3.1: Chain of Thought prompting.", "confidence": 0.9920266270637512, "text_region": [[541.0, 1923.0], [938.0, 1926.0], [937.0, 1951.0], [541.0, 1948.0]]}, {"text": "Galileo", "confidence": 0.9959301948547363, "text_region": [[247.0, 1998.0], [352.0, 1998.0], [352.0, 2030.0], [247.0, 2030.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9984337091445923, "text_region": [[1145.0, 2005.0], [1335.0, 2002.0], [1336.0, 2027.0], [1146.0, 2030.0]]}], "img_idx": 0}

{"type": "text", "bbox": [152, 184, 1291, 286], "res": [{"text": "If you look at Fig 3.1, you'll see how guiding the model through a series of logical operations", "confidence": 0.9895061254501343, "text_region": [[157.0, 194.0], [1278.0, 194.0], [1278.0, 218.0], [157.0, 218.0]]}, {"text": "or steps helps it better understand how to approach each of the queries, compared to a.", "confidence": 0.9883872866630554, "text_region": [[156.0, 226.0], [1253.0, 226.0], [1253.0, 251.0], [156.0, 251.0]]}, {"text": "standard prompt, which fails to give the correct response..", "confidence": 0.9881487488746643, "text_region": [[156.0, 257.0], [872.0, 259.0], [872.0, 282.0], [156.0, 280.0]]}], "img_idx": 0}
{"type": "text", "bbox": [153, 313, 1335, 482], "res": [{"text": "While chain of thought prompting is a great technique for enhancing the model's reasoning,", "confidence": 0.9960669875144958, "text_region": [[155.0, 321.0], [1302.0, 322.0], [1302.0, 349.0], [155.0, 347.0]]}, {"text": "designing the prompt itself can be quite challenging. You'll also notice how the results depend", "confidence": 0.9888203144073486, "text_region": [[158.0, 358.0], [1326.0, 358.0], [1326.0, 380.0], [158.0, 380.0]]}, {"text": "on the results of intermediary steps (or the thought process that the model follows), so if", "confidence": 0.9919164180755615, "text_region": [[157.0, 387.0], [1256.0, 386.0], [1256.0, 413.0], [157.0, 415.0]]}, {"text": "any of the steps are flawed, you'll end up with an incorrect response. Think \"error propagates", "confidence": 0.9947837591171265, "text_region": [[155.0, 419.0], [1308.0, 421.0], [1308.0, 448.0], [155.0, 445.0]]}, {"text": "through the chain.\"", "confidence": 0.9431451559066772, "text_region": [[155.0, 453.0], [392.0, 453.0], [392.0, 475.0], [155.0, 475.0]]}], "img_idx": 0}
{"type": "text", "bbox": [152, 1369, 592, 1439], "res": [{"text": "The idea behind ThoT prompting is", "confidence": 0.9996581673622131, "text_region": [[154.0, 1376.0], [586.0, 1378.0], [586.0, 1404.0], [154.0, 1402.0]]}, {"text": "instructing the model to:.", "confidence": 0.9890577793121338, "text_region": [[154.0, 1411.0], [458.0, 1413.0], [458.0, 1435.0], [154.0, 1432.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [105, 479, 1479, 2105], "res": [{"text": "THREAD OF THOUGHT (THOT)", "confidence": 0.8012259602546692, "text_region": [[157.0, 540.0], [941.0, 540.0], [941.0, 592.0], [157.0, 592.0]]}, {"text": "The Thread of Thought (ThoT)", "confidence": 0.9788488149642944, "text_region": [[153.0, 660.0], [521.0, 660.0], [521.0, 689.0], [153.0, 689.0]]}, {"text": "prompting technique is very", "confidence": 0.9940803050994873, "text_region": [[155.0, 696.0], [503.0, 696.0], [503.0, 720.0], [155.0, 720.0]]}, {"text": "intuitive and works very well when", "confidence": 0.9889690279960632, "text_region": [[151.0, 725.0], [577.0, 726.0], [577.0, 755.0], [151.0, 753.0]]}, {"text": "the retrieved information (or", "confidence": 0.9701652526855469, "text_region": [[155.0, 762.0], [509.0, 762.0], [509.0, 784.0], [155.0, 784.0]]}, {"text": "context) is \"chaotic.\" What does", "confidence": 0.990641713142395, "text_region": [[155.0, 794.0], [550.0, 794.0], [550.0, 818.0], [155.0, 818.0]]}, {"text": "this mean? A chaotic context is", "confidence": 0.9924739003181458, "text_region": [[153.0, 828.0], [543.0, 828.0], [543.0, 850.0], [153.0, 850.0]]}, {"text": "something that is often full of", "confidence": 0.9831869006156921, "text_region": [[153.0, 860.0], [519.0, 857.0], [519.0, 880.0], [153.0, 884.0]]}, {"text": "unrelated, complex information", "confidence": 0.999786913394928, "text_region": [[155.0, 892.0], [546.0, 892.0], [546.0, 916.0], [155.0, 916.0]]}, {"text": "that will most likely not contribute", "confidence": 0.9989537000656128, "text_region": [[155.0, 924.0], [570.0, 924.0], [570.0, 948.0], [155.0, 948.0]]}, {"text": "anything to the model's response.", "confidence": 0.9923708438873291, "text_region": [[157.0, 958.0], [574.0, 958.0], [574.0, 982.0], [157.0, 982.0]]}, {"text": "It is also characterized by a lack", "confidence": 0.9897187352180481, "text_region": [[153.0, 989.0], [553.0, 989.0], [553.0, 1013.0], [153.0, 1013.0]]}, {"text": "of coherency and a muddle of", "confidence": 0.9992863535881042, "text_region": [[151.0, 1019.0], [536.0, 1018.0], [536.0, 1046.0], [151.0, 1048.0]]}, {"text": "details. The onus is on the model", "confidence": 0.9968976974487305, "text_region": [[155.0, 1053.0], [558.0, 1053.0], [558.0, 1075.0], [155.0, 1075.0]]}, {"text": "to go through this chaotic mix to", "confidence": 0.9990480542182922, "text_region": [[151.0, 1085.0], [558.0, 1084.0], [558.0, 1112.0], [151.0, 1114.0]]}, {"text": "pick details that are essential to", "confidence": 0.9921853542327881, "text_region": [[151.0, 1118.0], [553.0, 1116.0], [553.0, 1145.0], [151.0, 1146.0]]}, {"text": "answering the query accurately. As", "confidence": 0.9991211891174316, "text_region": [[155.0, 1153.0], [593.0, 1153.0], [593.0, 1177.0], [155.0, 1177.0]]}, {"text": "you can imagine, using a simple", "confidence": 0.9981389045715332, "text_region": [[155.0, 1185.0], [557.0, 1185.0], [557.0, 1209.0], [155.0, 1209.0]]}, {"text": "prompt or a chain of thought.", "confidence": 0.9622732400894165, "text_region": [[153.0, 1216.0], [521.0, 1214.0], [521.0, 1243.0], [153.0, 1245.0]]}, {"text": "prompting method can do little to", "confidence": 0.995303750038147, "text_region": [[153.0, 1248.0], [577.0, 1244.0], [577.0, 1273.0], [153.0, 1277.0]]}, {"text": "instruct the model to pick the right", "confidence": 0.9933057427406311, "text_region": [[150.0, 1278.0], [584.0, 1280.0], [584.0, 1309.0], [150.0, 1307.0]]}, {"text": "details.", "confidence": 0.9995356798171997, "text_region": [[153.0, 1314.0], [242.0, 1314.0], [242.0, 1338.0], [153.0, 1338.0]]}, {"text": "The idea behind ThoT prompting is", "confidence": 0.9986101984977722, "text_region": [[151.0, 1375.0], [586.0, 1377.0], [586.0, 1406.0], [151.0, 1404.0]]}, {"text": "instructing the model to:", "confidence": 0.9998000860214233, "text_region": [[150.0, 1409.0], [461.0, 1411.0], [460.0, 1439.0], [150.0, 1438.0]]}, {"text": "Go step-by-step", "confidence": 0.9996640682220459, "text_region": [[193.0, 1473.0], [411.0, 1477.0], [410.0, 1506.0], [192.0, 1502.0]]}, {"text": " Summarize each step", "confidence": 0.9365086555480957, "text_region": [[160.0, 1529.0], [473.0, 1531.0], [472.0, 1560.0], [160.0, 1558.0]]}, {"text": ". Analyze each step", "confidence": 0.9494249224662781, "text_region": [[155.0, 1583.0], [428.0, 1587.0], [428.0, 1616.0], [155.0, 1612.0]]}, {"text": "Galileo", "confidence": 0.9954356551170349, "text_region": [[244.0, 1997.0], [351.0, 1997.0], [351.0, 2032.0], [244.0, 2032.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9990150332450867, "text_region": [[1149.0, 2003.0], [1336.0, 2003.0], [1336.0, 2027.0], [1149.0, 2027.0]]}], "img_idx": 0}

{"type": "figure", "bbox": [0, 0, 1485, 2104], "res": [{"text": "Chapter1 briefly introduces LLMs and RAG", "confidence": 0.972378134727478, "text_region": [[155.0, 193.0], [672.0, 193.0], [672.0, 215.0], [155.0, 215.0]]}, {"text": "Chapter 6 concludes with different methods", "confidence": 0.9954774975776672, "text_region": [[776.0, 188.0], [1328.0, 188.0], [1328.0, 217.0], [776.0, 217.0]]}, {"text": "systems. The assumption here is that", "confidence": 0.9581525325775146, "text_region": [[155.0, 224.0], [617.0, 224.0], [617.0, 245.0], [155.0, 245.0]]}, {"text": "to observe and manage your RAG system", "confidence": 0.992301344871521, "text_region": [[773.0, 221.0], [1299.0, 221.0], [1299.0, 250.0], [773.0, 250.0]]}, {"text": "you're already familiar with the basics of", "confidence": 0.9994276165962219, "text_region": [[150.0, 250.0], [661.0, 250.0], [661.0, 278.0], [150.0, 278.0]]}, {"text": "after deployment..", "confidence": 0.9689412713050842, "text_region": [[771.0, 250.0], [999.0, 250.0], [999.0, 278.0], [771.0, 278.0]]}, {"text": "generative models, how they differ from", "confidence": 0.9922631978988647, "text_region": [[150.0, 281.0], [652.0, 278.0], [652.0, 307.0], [150.0, 309.0]]}, {"text": "discriminative models, and how they work.", "confidence": 0.999556839466095, "text_region": [[152.0, 309.0], [683.0, 309.0], [683.0, 338.0], [152.0, 338.0]]}, {"text": "Chapter 7 explores ways to improve RAG", "confidence": 0.9805771708488464, "text_region": [[773.0, 309.0], [1284.0, 309.0], [1284.0, 338.0], [773.0, 338.0]]}, {"text": "performance after deployment, ensuring", "confidence": 0.999893307685852, "text_region": [[771.0, 337.0], [1286.0, 340.0], [1286.0, 370.0], [771.0, 368.0]]}, {"text": "Chapter 2 details the challenges or pain", "confidence": 0.99308842420578, "text_region": [[150.0, 366.0], [656.0, 368.0], [656.0, 399.0], [150.0, 397.0]]}, {"text": "your system is always effective..", "confidence": 0.9950208067893982, "text_region": [[773.0, 370.0], [1169.0, 370.0], [1169.0, 399.0], [773.0, 399.0]]}, {"text": "points associated with RAG systems and", "confidence": 0.9898177981376648, "text_region": [[152.0, 403.0], [661.0, 403.0], [661.0, 425.0], [152.0, 425.0]]}, {"text": "some practical tips for addressing them", "confidence": 0.980698823928833, "text_region": [[152.0, 434.0], [656.0, 434.0], [656.0, 456.0], [152.0, 456.0]]}, {"text": "We're confident that going through this", "confidence": 0.9997851848602295, "text_region": [[773.0, 430.0], [1266.0, 430.0], [1266.0, 458.0], [773.0, 458.0]]}, {"text": "comprehensive resource will better position", "confidence": 0.9963111281394958, "text_region": [[773.0, 460.0], [1324.0, 460.0], [1324.0, 489.0], [773.0, 489.0]]}, {"text": "Chapter 3 covers different prompting", "confidence": 0.9755042195320129, "text_region": [[150.0, 486.0], [621.0, 491.0], [621.0, 520.0], [150.0, 515.0]]}, {"text": "you to experiment with LLMs and RAGs and", "confidence": 0.9994770288467407, "text_region": [[771.0, 491.0], [1308.0, 489.0], [1308.0, 517.0], [771.0, 519.0]]}, {"text": "techniques that you can use to reduce", "confidence": 0.9918656349182129, "text_region": [[150.0, 519.0], [639.0, 519.0], [639.0, 548.0], [150.0, 548.0]]}, {"text": "appreciate the intricacies of such systems.", "confidence": 0.9994178414344788, "text_region": [[773.0, 519.0], [1310.0, 517.0], [1310.0, 548.0], [774.0, 550.0]]}, {"text": "hallucinations in your RAG applications.", "confidence": 0.9990030527114868, "text_region": [[150.0, 550.0], [643.0, 550.0], [643.0, 579.0], [150.0, 579.0]]}, {"text": "Some of these concepts are relatively new,", "confidence": 0.9938231706619263, "text_region": [[773.0, 550.0], [1310.0, 550.0], [1310.0, 579.0], [773.0, 579.0]]}, {"text": "and something better and more interesting", "confidence": 0.9828922152519226, "text_region": [[773.0, 581.0], [1319.0, 581.0], [1319.0, 609.0], [773.0, 609.0]]}, {"text": "Chapter 4 - consisting of many subchapters", "confidence": 0.9862934350967407, "text_region": [[152.0, 609.0], [714.0, 609.0], [714.0, 638.0], [152.0, 638.0]]}, {"text": "may emerge tomorrow. That said, the topics", "confidence": 0.9956629872322083, "text_region": [[773.0, 611.0], [1328.0, 611.0], [1328.0, 633.0], [773.0, 633.0]]}, {"text": "- explores chunking for RAGs, discusses", "confidence": 0.9824122786521912, "text_region": [[157.0, 640.0], [650.0, 640.0], [650.0, 668.0], [157.0, 668.0]]}, {"text": "we've covered in the ebook are structured to", "confidence": 0.9861642718315125, "text_region": [[776.0, 638.0], [1330.0, 640.0], [1330.0, 668.0], [776.0, 666.0]]}, {"text": "vector embeddings and re-ranking", "confidence": 0.9998307228088379, "text_region": [[150.0, 671.0], [594.0, 671.0], [594.0, 699.0], [150.0, 699.0]]}, {"text": "build a foundation-a gentle footing-upon", "confidence": 0.9888240694999695, "text_region": [[776.0, 671.0], [1315.0, 671.0], [1315.0, 699.0], [776.0, 699.0]]}, {"text": "techniques to improve retrieval, and", "confidence": 0.9743055701255798, "text_region": [[152.0, 704.0], [603.0, 704.0], [603.0, 725.0], [152.0, 725.0]]}, {"text": "which you can confidently work towards", "confidence": 0.9760937690734863, "text_region": [[778.0, 704.0], [1277.0, 704.0], [1277.0, 725.0], [778.0, 725.0]]}, {"text": "provides tips on choosing the best vector", "confidence": 0.9891489744186401, "text_region": [[150.0, 730.0], [667.0, 730.0], [667.0, 758.0], [150.0, 758.0]]}, {"text": "building enterprise-level RAG systems. The", "confidence": 0.9988625645637512, "text_region": [[771.0, 728.0], [1306.0, 728.0], [1306.0, 756.0], [771.0, 756.0]]}, {"text": "databases for your RAG system. In the", "confidence": 0.9895598888397217, "text_region": [[152.0, 761.0], [630.0, 761.0], [630.0, 789.0], [152.0, 789.0]]}, {"text": "concepts and ideas that you'll carry with", "confidence": 0.9952147006988525, "text_region": [[773.0, 761.0], [1284.0, 761.0], [1284.0, 789.0], [773.0, 789.0]]}, {"text": "end, it offers a practical guide to starting", "confidence": 0.9887321591377258, "text_region": [[150.0, 787.0], [663.0, 791.0], [663.0, 822.0], [150.0, 817.0]]}, {"text": "you from here will remain evergreen. During", "confidence": 0.964935302734375, "text_region": [[773.0, 791.0], [1321.0, 791.0], [1321.0, 820.0], [773.0, 820.0]]}, {"text": "your journey in building an enterprise-", "confidence": 0.9986763000488281, "text_region": [[152.0, 820.0], [623.0, 820.0], [623.0, 848.0], [152.0, 848.0]]}, {"text": "this exercise, you'll also explore different", "confidence": 0.9982051849365234, "text_region": [[773.0, 820.0], [1277.0, 820.0], [1277.0, 848.0], [773.0, 848.0]]}, {"text": "RAG system through architectural", "confidence": 0.9994508028030396, "text_region": [[152.0, 850.0], [577.0, 850.0], [577.0, 879.0], [152.0, 879.0]]}, {"text": "ways in which the Al systems you build are", "confidence": 0.9799928069114685, "text_region": [[773.0, 850.0], [1308.0, 850.0], [1308.0, 879.0], [773.0, 879.0]]}, {"text": "considerations.", "confidence": 0.9894039630889893, "text_region": [[150.0, 881.0], [345.0, 881.0], [345.0, 910.0], [150.0, 910.0]]}, {"text": "safe, transparent, and secure-the linchpin", "confidence": 0.9743291735649109, "text_region": [[776.0, 883.0], [1308.0, 883.0], [1308.0, 905.0], [776.0, 905.0]]}, {"text": "of a good business-and be someone who", "confidence": 0.9792699217796326, "text_region": [[771.0, 910.0], [1306.0, 910.0], [1306.0, 938.0], [771.0, 938.0]]}, {"text": "Chapter 5 prepares you for productionizing", "confidence": 0.9821642637252808, "text_region": [[152.0, 940.0], [692.0, 940.0], [692.0, 969.0], [152.0, 969.0]]}, {"text": "customers can trust.", "confidence": 0.9939141273498535, "text_region": [[771.0, 940.0], [1032.0, 940.0], [1032.0, 969.0], [771.0, 969.0]]}, {"text": "your RAG system through a detailed", "confidence": 0.9994954466819763, "text_region": [[150.0, 971.0], [608.0, 971.0], [608.0, 999.0], [150.0, 999.0]]}, {"text": "walkthrough of 8 test case scenarios.", "confidence": 0.9956020712852478, "text_region": [[150.0, 1002.0], [614.0, 1002.0], [614.0, 1030.0], [150.0, 1030.0]]}, {"text": "Written by Pratik Bhavsar", "confidence": 0.996703565120697, "text_region": [[975.0, 1784.0], [1348.0, 1784.0], [1348.0, 1813.0], [975.0, 1813.0]]}, {"text": "Galileo", "confidence": 0.9959842562675476, "text_region": [[248.0, 1997.0], [351.0, 1997.0], [351.0, 2029.0], [248.0, 2029.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9987513422966003, "text_region": [[1145.0, 2001.0], [1337.0, 2001.0], [1337.0, 2029.0], [1145.0, 2029.0]]}], "img_idx": 0}

{"type": "figure", "bbox": [108, 329, 1458, 2104], "res": [{"text": "1", "confidence": 0.9998252987861633, "text_region": [[207.0, 418.0], [224.0, 418.0], [224.0, 440.0], [207.0, 440.0]]}, {"text": "Introduction to LLMs and RAGs", "confidence": 0.9982144832611084, "text_region": [[290.0, 418.0], [733.0, 418.0], [733.0, 444.0], [290.0, 444.0]]}, {"text": "5", "confidence": 0.9998892545700073, "text_region": [[1262.0, 414.0], [1286.0, 414.0], [1286.0, 444.0], [1262.0, 444.0]]}, {"text": "2", "confidence": 0.9998188614845276, "text_region": [[202.0, 516.0], [227.0, 516.0], [227.0, 545.0], [202.0, 545.0]]}, {"text": "Challenges Associated With Building RAG Systems.", "confidence": 0.9892334342002869, "text_region": [[288.0, 516.0], [1036.0, 516.0], [1036.0, 547.0], [288.0, 547.0]]}, {"text": "14", "confidence": 0.9995754957199097, "text_region": [[1253.0, 516.0], [1291.0, 516.0], [1291.0, 545.0], [1253.0, 545.0]]}, {"text": "3", "confidence": 0.999866247177124, "text_region": [[198.0, 616.0], [229.0, 616.0], [229.0, 649.0], [198.0, 649.0]]}, {"text": "Reduce Hallucinations Through Prompting Techniques.", "confidence": 0.9923955202102661, "text_region": [[284.0, 616.0], [1097.0, 617.0], [1097.0, 651.0], [284.0, 649.0]]}, {"text": "20", "confidence": 0.9995554089546204, "text_region": [[1251.0, 617.0], [1295.0, 617.0], [1295.0, 649.0], [1251.0, 649.0]]}, {"text": "4.1", "confidence": 0.9997753500938416, "text_region": [[194.0, 717.0], [238.0, 717.0], [238.0, 749.0], [194.0, 749.0]]}, {"text": "Advanced Chunking Techniques.", "confidence": 0.9834288954734802, "text_region": [[284.0, 717.0], [772.0, 719.0], [772.0, 751.0], [284.0, 749.0]]}, {"text": "40", "confidence": 0.9996809959411621, "text_region": [[1253.0, 719.0], [1295.0, 719.0], [1295.0, 749.0], [1253.0, 749.0]]}, {"text": "4.2", "confidence": 0.999821662902832, "text_region": [[189.0, 817.0], [244.0, 817.0], [244.0, 852.0], [189.0, 852.0]]}, {"text": "How to Select an Embedding Model", "confidence": 0.9905438423156738, "text_region": [[286.0, 821.0], [816.0, 821.0], [816.0, 852.0], [286.0, 852.0]]}, {"text": "61", "confidence": 0.9997247457504272, "text_region": [[1256.0, 819.0], [1293.0, 819.0], [1293.0, 852.0], [1256.0, 852.0]]}, {"text": "4.3", "confidence": 0.9999414086341858, "text_region": [[191.0, 921.0], [242.0, 921.0], [242.0, 950.0], [191.0, 950.0]]}, {"text": "Choosing the Perfect Vector Database.", "confidence": 0.9797829389572144, "text_region": [[288.0, 921.0], [862.0, 921.0], [862.0, 952.0], [288.0, 952.0]]}, {"text": "82", "confidence": 0.999957263469696, "text_region": [[1251.0, 921.0], [1295.0, 921.0], [1295.0, 952.0], [1251.0, 952.0]]}, {"text": "4.4", "confidence": 0.9999091625213623, "text_region": [[189.0, 1021.0], [244.0, 1021.0], [244.0, 1056.0], [189.0, 1056.0]]}, {"text": "How to Select a Reranking Model.", "confidence": 0.9849430322647095, "text_region": [[282.0, 1022.0], [774.0, 1020.0], [774.0, 1052.0], [282.0, 1054.0]]}, {"text": "96", "confidence": 0.9998041391372681, "text_region": [[1251.0, 1022.0], [1295.0, 1022.0], [1295.0, 1052.0], [1251.0, 1052.0]]}, {"text": "4.5", "confidence": 0.9999120831489563, "text_region": [[187.0, 1120.0], [244.0, 1120.0], [244.0, 1155.0], [187.0, 1155.0]]}, {"text": "Steps to Build an Enterprise RAG System.", "confidence": 0.991751492023468, "text_region": [[284.0, 1122.0], [882.0, 1126.0], [882.0, 1157.0], [284.0, 1154.0]]}, {"text": "118", "confidence": 0.9947308897972107, "text_region": [[1249.0, 1124.0], [1295.0, 1124.0], [1295.0, 1155.0], [1249.0, 1155.0]]}, {"text": "5", "confidence": 0.9998488426208496, "text_region": [[203.0, 1224.0], [229.0, 1224.0], [229.0, 1255.0], [203.0, 1255.0]]}, {"text": "8 Scenarios To Evaluate Before Production.", "confidence": 0.9911187291145325, "text_region": [[288.0, 1228.0], [915.0, 1228.0], [915.0, 1253.0], [288.0, 1253.0]]}, {"text": "138", "confidence": 0.9998912811279297, "text_region": [[1243.0, 1222.0], [1300.0, 1222.0], [1300.0, 1257.0], [1243.0, 1257.0]]}, {"text": "6", "confidence": 0.9993263483047485, "text_region": [[200.0, 1324.0], [231.0, 1324.0], [231.0, 1357.0], [200.0, 1357.0]]}, {"text": "Monitoring & Optimizing Your RAG Systems", "confidence": 0.9872902631759644, "text_region": [[286.0, 1322.0], [922.0, 1324.0], [922.0, 1361.0], [286.0, 1359.0]]}, {"text": "156", "confidence": 0.9998836517333984, "text_region": [[1245.0, 1326.0], [1300.0, 1326.0], [1300.0, 1355.0], [1245.0, 1355.0]]}, {"text": "7", "confidence": 0.9997246861457825, "text_region": [[202.0, 1427.0], [227.0, 1427.0], [227.0, 1457.0], [202.0, 1457.0]]}, {"text": "Improve RAG Performance With 4 Powerful RAG Metrics", "confidence": 0.9934349656105042, "text_region": [[288.0, 1431.0], [1104.0, 1431.0], [1104.0, 1457.0], [288.0, 1457.0]]}, {"text": "172", "confidence": 0.9999457001686096, "text_region": [[1245.0, 1425.0], [1298.0, 1425.0], [1298.0, 1461.0], [1245.0, 1461.0]]}, {"text": "8", "confidence": 0.9996073842048645, "text_region": [[200.0, 1527.0], [231.0, 1527.0], [231.0, 1560.0], [200.0, 1560.0]]}, {"text": "Conclusion", "confidence": 0.9994602203369141, "text_region": [[286.0, 1529.0], [457.0, 1529.0], [457.0, 1560.0], [286.0, 1560.0]]}, {"text": "194", "confidence": 0.9999399185180664, "text_region": [[1243.0, 1525.0], [1302.0, 1525.0], [1302.0, 1560.0], [1243.0, 1560.0]]}, {"text": "9", "confidence": 0.989382803440094, "text_region": [[203.0, 1629.0], [229.0, 1629.0], [229.0, 1658.0], [203.0, 1658.0]]}, {"text": "GLOSSARY", "confidence": 0.9989926218986511, "text_region": [[284.0, 1629.0], [440.0, 1629.0], [440.0, 1660.0], [284.0, 1660.0]]}, {"text": "196", "confidence": 0.9998913407325745, "text_region": [[1242.0, 1622.0], [1303.0, 1628.0], [1300.0, 1663.0], [1239.0, 1658.0]]}, {"text": "Galileo", "confidence": 0.9922510981559753, "text_region": [[241.0, 1991.0], [352.0, 1995.0], [351.0, 2034.0], [240.0, 2030.0]]}, {"text": "R", "confidence": 0.5968613624572754, "text_region": [[158.0, 2013.0], [214.0, 2013.0], [214.0, 2043.0], [158.0, 2043.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9978320002555847, "text_region": [[1146.0, 2004.0], [1338.0, 2000.0], [1339.0, 2026.0], [1147.0, 2030.0]]}], "img_idx": 0}

{"type": "figure", "bbox": [0, 0, 1488, 2104], "res": [{"text": "01", "confidence": 0.9110136032104492, "text_region": [[148.0, 206.0], [261.0, 206.0], [261.0, 298.0], [148.0, 298.0]]}, {"text": "INTRODUCTION TO LLMS AND RAGS", "confidence": 0.9561594128608704, "text_region": [[153.0, 333.0], [1174.0, 333.0], [1174.0, 377.0], [153.0, 377.0]]}, {"text": "The introduction of generative models,", "confidence": 0.9934642314910889, "text_region": [[155.0, 476.0], [633.0, 476.0], [633.0, 504.0], [155.0, 504.0]]}, {"text": "Then, OpenAl came up with Generative Pre", "confidence": 0.9820030331611633, "text_region": [[775.0, 476.0], [1311.0, 476.0], [1311.0, 504.0], [775.0, 504.0]]}, {"text": "that is, the use of the generator and the", "confidence": 0.9992899894714355, "text_region": [[148.0, 508.0], [649.0, 511.0], [649.0, 541.0], [148.0, 539.0]]}, {"text": "trained Transformers (GPTs) models that", "confidence": 0.993117094039917, "text_region": [[773.0, 511.0], [1289.0, 511.0], [1289.0, 539.0], [773.0, 539.0]]}, {"text": " discriminator model competing against one", "confidence": 0.9825835227966309, "text_region": [[148.0, 543.0], [709.0, 546.0], [708.0, 576.0], [148.0, 574.0]]}, {"text": "used unsupervised learning (pre-trained", "confidence": 0.9837315082550049, "text_region": [[775.0, 550.0], [1284.0, 550.0], [1284.0, 572.0], [775.0, 572.0]]}, {"text": "another, became the bedrock upon which", "confidence": 0.9854938983917236, "text_region": [[153.0, 583.0], [675.0, 583.0], [675.0, 605.0], [153.0, 605.0]]}, {"text": "on vast amounts of text) and then fine-", "confidence": 0.9756234288215637, "text_region": [[773.0, 581.0], [1267.0, 581.0], [1267.0, 609.0], [773.0, 609.0]]}, {"text": "foundation models were built. Then, the", "confidence": 0.9882157444953918, "text_region": [[151.0, 616.0], [647.0, 616.0], [647.0, 644.0], [151.0, 644.0]]}, {"text": "tuned for specific tasks based on need..", "confidence": 0.9668553471565247, "text_region": [[773.0, 618.0], [1262.0, 618.0], [1262.0, 640.0], [773.0, 640.0]]}, {"text": "introduction of the attention mechanism", "confidence": 0.9914380311965942, "text_region": [[148.0, 649.0], [662.0, 651.0], [662.0, 679.0], [148.0, 677.0]]}, {"text": "Its successor models grew capabilities.", "confidence": 0.985130786895752, "text_region": [[771.0, 651.0], [1264.0, 651.0], [1264.0, 679.0], [771.0, 679.0]]}, {"text": "(in the phenomenal paper \"Attention Is All", "confidence": 0.9914321899414062, "text_region": [[153.0, 686.0], [678.0, 686.0], [678.0, 714.0], [153.0, 714.0]]}, {"text": "With GPT-2, you could perform translation,", "confidence": 0.98786860704422, "text_region": [[773.0, 686.0], [1300.0, 686.0], [1300.0, 714.0], [773.0, 714.0]]}, {"text": "You Need\") and transformers thereafter", "confidence": 0.9769371151924133, "text_region": [[153.0, 721.0], [651.0, 721.0], [651.0, 750.0], [153.0, 750.0]]}, {"text": " summarization, and even rudimentary", "confidence": 0.9845821857452393, "text_region": [[771.0, 719.0], [1256.0, 721.0], [1255.0, 752.0], [771.0, 750.0]]}, {"text": "marked the departure from recurrent", "confidence": 0.9892269968986511, "text_region": [[153.0, 756.0], [622.0, 756.0], [622.0, 785.0], [153.0, 785.0]]}, {"text": "conversation. With GPT-3, having 175 billion", "confidence": 0.9991706609725952, "text_region": [[773.0, 756.0], [1313.0, 756.0], [1313.0, 785.0], [773.0, 785.0]]}, {"text": "neural networks (RNNs) or long short-term", "confidence": 0.9870058298110962, "text_region": [[151.0, 791.0], [682.0, 791.0], [682.0, 820.0], [151.0, 820.0]]}, {"text": "parameters and therefore capable of", "confidence": 0.9998091459274292, "text_region": [[771.0, 791.0], [1247.0, 789.0], [1247.0, 820.0], [771.0, 822.0]]}, {"text": "memory networks (LsTMs). while these", "confidence": 0.9796183109283447, "text_region": [[151.0, 826.0], [640.0, 826.0], [640.0, 855.0], [151.0, 855.0]]}, {"text": "capturing complex relationships between", "confidence": 0.9911178946495056, "text_region": [[773.0, 828.0], [1295.0, 828.0], [1295.0, 857.0], [773.0, 857.0]]}, {"text": "were processing data sequentially,the", "confidence": 0.9618962407112122, "text_region": [[151.0, 861.0], [638.0, 861.0], [638.0, 890.0], [151.0, 890.0]]}, {"text": "elements, it could generate creative content,", "confidence": 0.9918373823165894, "text_region": [[771.0, 861.0], [1333.0, 861.0], [1333.0, 890.0], [771.0, 890.0]]}, {"text": "newer methods could learn contextual", "confidence": 0.9812855124473572, "text_region": [[151.0, 896.0], [638.0, 896.0], [638.0, 925.0], [151.0, 925.0]]}, {"text": "solve complex problems, and provide", "confidence": 0.9782295227050781, "text_region": [[773.0, 896.0], [1247.0, 896.0], [1247.0, 925.0], [773.0, 925.0]]}, {"text": "relationships between different elements in", "confidence": 0.9829092025756836, "text_region": [[151.0, 931.0], [695.0, 931.0], [695.0, 960.0], [151.0, 960.0]]}, {"text": "explanations.The introduction of GPT-40", "confidence": 0.9700793623924255, "text_region": [[771.0, 931.0], [1284.0, 929.0], [1284.0, 958.0], [771.0, 960.0]]}, {"text": "the sequence.The progress in the field since", "confidence": 0.9449604153633118, "text_region": [[148.0, 967.0], [706.0, 967.0], [706.0, 995.0], [148.0, 995.0]]}, {"text": "much more refined with few-shot and", "confidence": 0.9682181477546692, "text_region": [[768.0, 967.0], [1251.0, 967.0], [1251.0, 995.0], [768.0, 995.0]]}, {"text": "then has been groundbreaking,building", "confidence": 0.9572523236274719, "text_region": [[146.0, 997.0], [658.0, 1002.0], [657.0, 1032.0], [146.0, 1028.0]]}, {"text": "zero-shot learning capabilities,has been", "confidence": 0.9627538919448853, "text_region": [[773.0, 1002.0], [1284.0, 1002.0], [1284.0, 1030.0], [773.0, 1030.0]]}, {"text": "atop transformers.", "confidence": 0.9686293005943298, "text_region": [[153.0, 1037.0], [385.0, 1037.0], [385.0, 1065.0], [153.0, 1065.0]]}, {"text": "a milepost in the space with additional", "confidence": 0.9643598794937134, "text_region": [[773.0, 1037.0], [1271.0, 1037.0], [1271.0, 1065.0], [773.0, 1065.0]]}, {"text": "capabilities i.e., the ability to process image", "confidence": 0.9284771680831909, "text_region": [[775.0, 1072.0], [1331.0, 1072.0], [1331.0, 1100.0], [775.0, 1100.0]]}, {"text": "sound,and text) and the ability to let users", "confidence": 0.9484434127807617, "text_region": [[773.0, 1107.0], [1311.0, 1107.0], [1311.0, 1135.0], [773.0, 1135.0]]}, {"text": "customize their style,tone,and tasks.", "confidence": 0.9593833684921265, "text_region": [[773.0, 1142.0], [1238.0, 1142.0], [1238.0, 1170.0], [773.0, 1170.0]]}, {"text": "Galileo", "confidence": 0.9965332746505737, "text_region": [[248.0, 1997.0], [352.0, 1997.0], [352.0, 2029.0], [248.0, 2029.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9906944036483765, "text_region": [[1145.0, 2001.0], [1340.0, 2001.0], [1340.0, 2029.0], [1145.0, 2029.0]]}], "img_idx": 0}

{"type": "text", "bbox": [777, 931, 1327, 1221], "res": [{"text": "In the second phase, there's supervised", "confidence": 0.9567227363586426, "text_region": [[779.0, 935.0], [1271.0, 936.0], [1271.0, 957.0], [779.0, 956.0]]}, {"text": "learning, where the model benefits from", "confidence": 0.9851050972938538, "text_region": [[779.0, 967.0], [1273.0, 965.0], [1273.0, 988.0], [779.0, 990.0]]}, {"text": "being trained with clear objectives, such as", "confidence": 0.9793820977210999, "text_region": [[780.0, 998.0], [1313.0, 999.0], [1313.0, 1023.0], [780.0, 1022.0]]}, {"text": "anguage translation or text classification.", "confidence": 0.9997318983078003, "text_region": [[780.0, 1033.0], [1298.0, 1031.0], [1298.0, 1054.0], [780.0, 1056.0]]}, {"text": "After having adjusted its weights, the model", "confidence": 0.9955154657363892, "text_region": [[781.0, 1065.0], [1322.0, 1065.0], [1322.0, 1088.0], [781.0, 1088.0]]}, {"text": "s now aligned with a user's end goal or.", "confidence": 0.9733282327651978, "text_region": [[780.0, 1097.0], [1266.0, 1097.0], [1266.0, 1120.0], [780.0, 1120.0]]}, {"text": "ntention. Now, when you ask it to classify.", "confidence": 0.9837851524353027, "text_region": [[780.0, 1130.0], [1286.0, 1130.0], [1286.0, 1154.0], [780.0, 1154.0]]}, {"text": " set of words by their sentiment, it'll do so", "confidence": 0.9959152936935425, "text_region": [[780.0, 1162.0], [1303.0, 1162.0], [1303.0, 1185.0], [780.0, 1185.0]]}, {"text": "perfectly!", "confidence": 0.9985550045967102, "text_region": [[779.0, 1193.0], [893.0, 1193.0], [893.0, 1217.0], [779.0, 1217.0]]}], "img_idx": 0}
{"type": "text", "bbox": [778, 1252, 1489, 2105], "res": [{"text": "In the third stage, the model is further", "confidence": 0.9867030382156372, "text_region": [[780.0, 1260.0], [1248.0, 1260.0], [1248.0, 1283.0], [780.0, 1283.0]]}, {"text": "mproved by supervised instruction fine-", "confidence": 0.9994001388549805, "text_region": [[781.0, 1292.0], [1279.0, 1292.0], [1279.0, 1316.0], [781.0, 1316.0]]}, {"text": "uning. This is possible by training the", "confidence": 0.9902579188346863, "text_region": [[781.0, 1325.0], [1241.0, 1325.0], [1241.0, 1349.0], [781.0, 1349.0]]}, {"text": "nodel on specific Iabeled datasets where.", "confidence": 0.9752591848373413, "text_region": [[781.0, 1357.0], [1298.0, 1357.0], [1298.0, 1379.0], [781.0, 1379.0]]}, {"text": "he model will update its weights to further", "confidence": 0.9974472522735596, "text_region": [[781.0, 1389.0], [1306.0, 1389.0], [1306.0, 1413.0], [781.0, 1413.0]]}, {"text": "educe the errors in its predictions/tasks", "confidence": 0.9998624920845032, "text_region": [[781.0, 1422.0], [1279.0, 1422.0], [1279.0, 1445.0], [781.0, 1445.0]]}, {"text": "After the model has been fine-tuned to", "confidence": 0.9991579651832581, "text_region": [[780.0, 1452.0], [1263.0, 1453.0], [1263.0, 1476.0], [780.0, 1475.0]]}, {"text": " specific domain, to refine the model's", "confidence": 0.9919653534889221, "text_region": [[781.0, 1487.0], [1265.0, 1485.0], [1265.0, 1508.0], [781.0, 1510.0]]}, {"text": "output further, we can use a technique", "confidence": 0.9677531719207764, "text_region": [[782.0, 1520.0], [1258.0, 1520.0], [1258.0, 1542.0], [782.0, 1542.0]]}, {"text": "called Reinforcement Learning from Human.", "confidence": 0.9801239371299744, "text_region": [[780.0, 1550.0], [1321.0, 1552.0], [1321.0, 1575.0], [780.0, 1573.0]]}, {"text": "Feedback (RLHF). Based on how we rate", "confidence": 0.9616471529006958, "text_region": [[781.0, 1583.0], [1271.0, 1583.0], [1271.0, 1606.0], [781.0, 1606.0]]}, {"text": "the quality of the model output or ask it to", "confidence": 0.9860374331474304, "text_region": [[781.0, 1616.0], [1298.0, 1616.0], [1298.0, 1640.0], [781.0, 1640.0]]}, {"text": "modify the output, the model keeps trying", "confidence": 0.9867334365844727, "text_region": [[779.0, 1647.0], [1297.0, 1649.0], [1297.0, 1676.0], [779.0, 1674.0]]}, {"text": "o make its output better to match what.", "confidence": 0.9817714095115662, "text_region": [[781.0, 1682.0], [1277.0, 1681.0], [1277.0, 1702.0], [781.0, 1703.0]]}, {"text": "we need, somewhat like a reward system.", "confidence": 0.9771623611450195, "text_region": [[780.0, 1714.0], [1294.0, 1715.0], [1294.0, 1738.0], [780.0, 1737.0]]}, {"text": "f you use ChatGPT, Gemini, or any other", "confidence": 0.9894366264343262, "text_region": [[781.0, 1747.0], [1273.0, 1746.0], [1273.0, 1769.0], [781.0, 1770.0]]}, {"text": "Al chatbot, you'll sometimes be prompted", "confidence": 0.9982703328132629, "text_region": [[781.0, 1780.0], [1299.0, 1780.0], [1299.0, 1803.0], [781.0, 1803.0]]}, {"text": "o select between different generated", "confidence": 0.9991474151611328, "text_region": [[781.0, 1811.0], [1248.0, 1811.0], [1248.0, 1834.0], [781.0, 1834.0]]}, {"text": "responses or asked to rate a response after.", "confidence": 0.9796846508979797, "text_region": [[780.0, 1845.0], [1318.0, 1843.0], [1318.0, 1866.0], [780.0, 1868.0]]}, {"text": "t has been generated-a classic example", "confidence": 0.9895206093788147, "text_region": [[781.0, 1877.0], [1298.0, 1877.0], [1298.0, 1900.0], [781.0, 1900.0]]}, {"text": "of an interactive feedback mechanism in", "confidence": 0.9636027216911316, "text_region": [[782.0, 1911.0], [1288.0, 1911.0], [1288.0, 1930.0], [782.0, 1930.0]]}, {"text": "action.", "confidence": 0.9995657205581665, "text_region": [[778.0, 1941.0], [862.0, 1941.0], [862.0, 1965.0], [778.0, 1965.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9944215416908264, "text_region": [[1147.0, 2005.0], [1334.0, 2004.0], [1335.0, 2025.0], [1147.0, 2026.0]]}], "img_idx": 0}
{"type": "text", "bbox": [154, 1352, 712, 1741], "res": [{"text": "LLMs have been trained on a large corpus of", "confidence": 0.9667953848838806, "text_region": [[157.0, 1357.0], [701.0, 1359.0], [701.0, 1379.0], [157.0, 1377.0]]}, {"text": "ext data. Say, books, articles, conversations", "confidence": 0.9810028672218323, "text_region": [[158.0, 1392.0], [701.0, 1392.0], [701.0, 1412.0], [158.0, 1412.0]]}, {"text": "and more. And the total size of the training", "confidence": 0.9912851452827454, "text_region": [[156.0, 1420.0], [681.0, 1422.0], [681.0, 1446.0], [156.0, 1444.0]]}, {"text": "data runs into petabytes. In the first stage,", "confidence": 0.9997787475585938, "text_region": [[156.0, 1452.0], [677.0, 1455.0], [677.0, 1480.0], [156.0, 1477.0]]}, {"text": "there's unsupervised learning, where it.", "confidence": 0.9769344329833984, "text_region": [[157.0, 1487.0], [632.0, 1488.0], [632.0, 1509.0], [157.0, 1508.0]]}, {"text": "earns to identify patterns and relationships.", "confidence": 0.985869824886322, "text_region": [[157.0, 1520.0], [694.0, 1520.0], [694.0, 1543.0], [157.0, 1543.0]]}, {"text": "n the data it's being fed without any aid", "confidence": 0.9880667924880981, "text_region": [[157.0, 1552.0], [655.0, 1552.0], [655.0, 1575.0], [157.0, 1575.0]]}, {"text": "from Iabels. As of the first stage, there's no.", "confidence": 0.9762842059135437, "text_region": [[157.0, 1583.0], [685.0, 1585.0], [685.0, 1608.0], [157.0, 1606.0]]}, {"text": "alignment-i.e., the model doesn't output", "confidence": 0.9878913760185242, "text_region": [[158.0, 1617.0], [664.0, 1617.0], [664.0, 1641.0], [158.0, 1641.0]]}, {"text": "something you want it to. So when you ask,.", "confidence": 0.9868150949478149, "text_region": [[158.0, 1651.0], [686.0, 1651.0], [686.0, 1674.0], [158.0, 1674.0]]}, {"text": "'Hey, what's up?\" it'll probably reply with a", "confidence": 0.9970423579216003, "text_region": [[158.0, 1680.0], [674.0, 1681.0], [674.0, 1706.0], [158.0, 1705.0]]}, {"text": "'What's up, with you?\"..", "confidence": 0.9739548563957214, "text_region": [[157.0, 1712.0], [430.0, 1713.0], [430.0, 1737.0], [157.0, 1736.0]]}], "img_idx": 0}
{"type": "text", "bbox": [152, 930, 721, 1318], "res": [{"text": "Before we take a quick look at what LLMs are", "confidence": 0.9818783402442932, "text_region": [[156.0, 936.0], [708.0, 936.0], [708.0, 956.0], [156.0, 956.0]]}, {"text": "we'll quickly revisit the concept of foundation", "confidence": 0.9950781464576721, "text_region": [[155.0, 966.0], [712.0, 966.0], [712.0, 990.0], [155.0, 990.0]]}, {"text": "models. Foundation models are large-scale", "confidence": 0.9872359037399292, "text_region": [[156.0, 1000.0], [699.0, 1000.0], [699.0, 1023.0], [156.0, 1023.0]]}, {"text": "neural networks trained on vast amounts of", "confidence": 0.9869457483291626, "text_region": [[155.0, 1032.0], [697.0, 1031.0], [697.0, 1052.0], [155.0, 1053.0]]}, {"text": "data. These then serve as a foundation for", "confidence": 0.9854151606559753, "text_region": [[156.0, 1065.0], [680.0, 1065.0], [680.0, 1086.0], [156.0, 1086.0]]}, {"text": "numerous tasks and applications. As we saw", "confidence": 0.9876217842102051, "text_region": [[155.0, 1097.0], [711.0, 1098.0], [711.0, 1119.0], [155.0, 1118.0]]}, {"text": "above, GPT-3 is an example of a foundation", "confidence": 0.9951783418655396, "text_region": [[155.0, 1130.0], [699.0, 1130.0], [699.0, 1153.0], [155.0, 1153.0]]}, {"text": "model for natural language processing.", "confidence": 0.975573718547821, "text_region": [[154.0, 1160.0], [642.0, 1162.0], [642.0, 1187.0], [154.0, 1185.0]]}, {"text": "(NLP) tasks. With foundation models, you.", "confidence": 0.9741801023483276, "text_region": [[157.0, 1192.0], [660.0, 1194.0], [660.0, 1218.0], [157.0, 1216.0]]}, {"text": "no longer need to train a model whenever", "confidence": 0.9794706106185913, "text_region": [[155.0, 1227.0], [678.0, 1227.0], [678.0, 1250.0], [155.0, 1250.0]]}, {"text": "you have a new task. You'll o cessing, and.", "confidence": 0.9897121787071228, "text_region": [[155.0, 1259.0], [685.0, 1259.0], [685.0, 1284.0], [155.0, 1284.0]]}, {"text": "generating human-like text..", "confidence": 0.9886391758918762, "text_region": [[154.0, 1291.0], [501.0, 1290.0], [501.0, 1314.0], [154.0, 1315.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [119, 0, 723, 2105], "res": [{"text": "F", "confidence": 0.15893803536891937, "text_region": [[239.0, 152.0], [323.0, 145.0], [333.0, 273.0], [249.0, 280.0]]}, {"text": "", "confidence": 0.0, "text_region": [[278.0, 252.0], [310.0, 252.0], [310.0, 285.0], [278.0, 285.0]]}, {"text": "R", "confidence": 0.17123858630657196, "text_region": [[253.0, 265.0], [356.0, 265.0], [356.0, 390.0], [253.0, 390.0]]}, {"text": "L", "confidence": 0.33663031458854675, "text_region": [[677.0, 452.0], [713.0, 452.0], [713.0, 476.0], [677.0, 476.0]]}, {"text": "WHAT ARE LLMS, AND", "confidence": 0.9794082641601562, "text_region": [[157.0, 794.0], [717.0, 794.0], [717.0, 838.0], [157.0, 838.0]]}, {"text": "Before we take a quick look at what LLMs are,.", "confidence": 0.9774458408355713, "text_region": [[148.0, 930.0], [710.0, 932.0], [710.0, 960.0], [148.0, 958.0]]}, {"text": "we'll quickly revisit the concept of foundation", "confidence": 0.979350745677948, "text_region": [[153.0, 967.0], [713.0, 967.0], [713.0, 989.0], [153.0, 989.0]]}, {"text": "models. Foundation models are large-scale.", "confidence": 0.9846787452697754, "text_region": [[150.0, 998.0], [704.0, 998.0], [704.0, 1026.0], [150.0, 1026.0]]}, {"text": "neural networks trained on vast amounts of", "confidence": 0.989800751209259, "text_region": [[150.0, 1028.0], [700.0, 1028.0], [700.0, 1057.0], [150.0, 1057.0]]}, {"text": "data. These then serve as a foundation for", "confidence": 0.9972435832023621, "text_region": [[153.0, 1061.0], [683.0, 1061.0], [683.0, 1090.0], [153.0, 1090.0]]}, {"text": "numerous tasks and applications. As we saw.", "confidence": 0.9902470707893372, "text_region": [[150.0, 1094.0], [715.0, 1094.0], [715.0, 1123.0], [150.0, 1123.0]]}, {"text": "above, GPT-3 is an example of a foundation.", "confidence": 0.9625651240348816, "text_region": [[153.0, 1125.0], [700.0, 1125.0], [700.0, 1153.0], [153.0, 1153.0]]}, {"text": "model for natural language processing", "confidence": 0.9925985336303711, "text_region": [[151.0, 1158.0], [643.0, 1160.0], [643.0, 1188.0], [150.0, 1186.0]]}, {"text": "(NLP) tasks. With foundation models, you", "confidence": 0.9854081869125366, "text_region": [[151.0, 1188.0], [660.0, 1191.0], [660.0, 1221.0], [150.0, 1219.0]]}, {"text": "no longer need to train a model whenever", "confidence": 0.9876257181167603, "text_region": [[150.0, 1224.0], [679.0, 1224.0], [679.0, 1252.0], [150.0, 1252.0]]}, {"text": "you have a new task. You'll o cessing, and", "confidence": 0.9979448914527893, "text_region": [[151.0, 1254.0], [687.0, 1256.0], [687.0, 1287.0], [150.0, 1285.0]]}, {"text": "generating human-like text.", "confidence": 0.9919933080673218, "text_region": [[150.0, 1289.0], [505.0, 1287.0], [505.0, 1318.0], [151.0, 1320.0]]}, {"text": "LLMs have been trained on a large corpus of", "confidence": 0.9884493350982666, "text_region": [[148.0, 1351.0], [706.0, 1353.0], [706.0, 1384.0], [148.0, 1381.0]]}, {"text": "text data. Say, books, articles, conversations,.", "confidence": 0.9825407862663269, "text_region": [[148.0, 1386.0], [706.0, 1388.0], [706.0, 1417.0], [148.0, 1414.0]]}, {"text": "and more. And the total size of the training", "confidence": 0.9846006035804749, "text_region": [[148.0, 1414.0], [683.0, 1419.0], [683.0, 1449.0], [148.0, 1445.0]]}, {"text": "data runs into petabytes. In the first stage,", "confidence": 0.9933245182037354, "text_region": [[151.0, 1449.0], [681.0, 1452.0], [681.0, 1482.0], [150.0, 1480.0]]}, {"text": "there's unsupervised learning, where it", "confidence": 0.9828585982322693, "text_region": [[150.0, 1484.0], [639.0, 1484.0], [639.0, 1513.0], [150.0, 1513.0]]}, {"text": "learns to identify patterns and relationships", "confidence": 0.9984027147293091, "text_region": [[150.0, 1515.0], [696.0, 1515.0], [696.0, 1544.0], [150.0, 1544.0]]}, {"text": "in the data it's being fed without any aid", "confidence": 0.9937846660614014, "text_region": [[150.0, 1550.0], [656.0, 1550.0], [656.0, 1579.0], [150.0, 1579.0]]}, {"text": "from labels. As of the first stage, there's no", "confidence": 0.9976969361305237, "text_region": [[148.0, 1579.0], [689.0, 1581.0], [689.0, 1612.0], [148.0, 1609.0]]}, {"text": "alignment--i.e., the model doesn't output", "confidence": 0.9773430228233337, "text_region": [[153.0, 1614.0], [666.0, 1614.0], [666.0, 1642.0], [153.0, 1642.0]]}, {"text": "something you want it to. So when you ask,", "confidence": 0.9864370226860046, "text_region": [[150.0, 1647.0], [687.0, 1647.0], [687.0, 1675.0], [150.0, 1675.0]]}, {"text": "\"Hey, what's up?\" it'll probably reply with a", "confidence": 0.9762726426124573, "text_region": [[153.0, 1680.0], [677.0, 1680.0], [677.0, 1708.0], [153.0, 1708.0]]}, {"text": "\"What's up, with you?\"", "confidence": 0.9443662762641907, "text_region": [[151.0, 1708.0], [432.0, 1710.0], [431.0, 1741.0], [150.0, 1739.0]]}, {"text": "Galileo", "confidence": 0.9971453547477722, "text_region": [[245.0, 1998.0], [352.0, 1998.0], [352.0, 2033.0], [245.0, 2033.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [49, 0, 1438, 2085], "res": [{"text": "A", "confidence": 0.2895187437534332, "text_region": [[659.0, 319.0], [804.0, 319.0], [804.0, 454.0], [659.0, 454.0]]}, {"text": "J", "confidence": 0.0892176702618599, "text_region": [[681.0, 454.0], [776.0, 454.0], [776.0, 478.0], [681.0, 478.0]]}, {"text": "WHAT ARE LLMS, AND HOW DO THEY WORK?", "confidence": 0.9671030044555664, "text_region": [[158.0, 793.0], [1349.0, 793.0], [1349.0, 836.0], [158.0, 836.0]]}, {"text": "Before we take a quick look at what LLMs are,.", "confidence": 0.9873844385147095, "text_region": [[151.0, 932.0], [711.0, 932.0], [711.0, 960.0], [151.0, 960.0]]}, {"text": "In the second phase, there's supervised", "confidence": 0.9927729964256287, "text_region": [[774.0, 932.0], [1275.0, 932.0], [1275.0, 960.0], [774.0, 960.0]]}, {"text": "we'll quickly revisit the concept of foundation", "confidence": 0.9896479845046997, "text_region": [[151.0, 964.0], [713.0, 964.0], [713.0, 993.0], [151.0, 993.0]]}, {"text": "learning, where the model benefits from", "confidence": 0.9959805607795715, "text_region": [[776.0, 964.0], [1277.0, 964.0], [1277.0, 993.0], [776.0, 993.0]]}, {"text": "models. Foundation models are large-scale", "confidence": 0.9981359839439392, "text_region": [[151.0, 997.0], [700.0, 997.0], [700.0, 1025.0], [151.0, 1025.0]]}, {"text": "being trained with clear objectives, such as", "confidence": 0.9997804164886475, "text_region": [[776.0, 997.0], [1316.0, 997.0], [1316.0, 1025.0], [776.0, 1025.0]]}, {"text": "neural networks trained on vast amounts of", "confidence": 0.999780535697937, "text_region": [[151.0, 1029.0], [700.0, 1029.0], [700.0, 1058.0], [151.0, 1058.0]]}, {"text": "Ianguage translation or text classification.", "confidence": 0.9926105737686157, "text_region": [[776.0, 1029.0], [1299.0, 1029.0], [1299.0, 1058.0], [776.0, 1058.0]]}, {"text": "data. These then serve as a foundation for.", "confidence": 0.9894945025444031, "text_region": [[153.0, 1064.0], [678.0, 1064.0], [678.0, 1086.0], [153.0, 1086.0]]}, {"text": "After having adjusted its weights, the model", "confidence": 0.9987970590591431, "text_region": [[776.0, 1062.0], [1325.0, 1062.0], [1325.0, 1090.0], [776.0, 1090.0]]}, {"text": "numerous tasks and applications. As we saw.", "confidence": 0.9770892858505249, "text_region": [[151.0, 1095.0], [713.0, 1095.0], [713.0, 1123.0], [151.0, 1123.0]]}, {"text": "is now aligned with a user's end goal or", "confidence": 0.9998642206192017, "text_region": [[774.0, 1095.0], [1269.0, 1095.0], [1269.0, 1123.0], [774.0, 1123.0]]}, {"text": "above, GPT-3 is an example of a foundation", "confidence": 0.995299220085144, "text_region": [[151.0, 1127.0], [700.0, 1127.0], [700.0, 1155.0], [151.0, 1155.0]]}, {"text": "intention. Now, when you ask it to classify", "confidence": 0.9815698862075806, "text_region": [[774.0, 1127.0], [1286.0, 1127.0], [1286.0, 1155.0], [774.0, 1155.0]]}, {"text": "model for natural language processing", "confidence": 0.9960400462150574, "text_region": [[151.0, 1155.0], [644.0, 1158.0], [644.0, 1188.0], [151.0, 1186.0]]}, {"text": "a set of words by their sentiment, it'll do so", "confidence": 0.9989480376243591, "text_region": [[774.0, 1160.0], [1303.0, 1160.0], [1303.0, 1188.0], [774.0, 1188.0]]}, {"text": "(NLP) tasks. With foundation models, you", "confidence": 0.9902859926223755, "text_region": [[151.0, 1188.0], [661.0, 1190.0], [661.0, 1221.0], [151.0, 1218.0]]}, {"text": "perfectly!", "confidence": 0.9998839497566223, "text_region": [[774.0, 1192.0], [893.0, 1192.0], [893.0, 1216.0], [774.0, 1216.0]]}, {"text": "no longer need to train a model whenever", "confidence": 0.9862494468688965, "text_region": [[151.0, 1225.0], [676.0, 1225.0], [676.0, 1253.0], [151.0, 1253.0]]}, {"text": "you have a new task. You'll o cessing, and", "confidence": 0.996964693069458, "text_region": [[151.0, 1258.0], [687.0, 1258.0], [687.0, 1286.0], [151.0, 1286.0]]}, {"text": "In the third stage, the model is further", "confidence": 0.9989919662475586, "text_region": [[774.0, 1258.0], [1254.0, 1258.0], [1254.0, 1286.0], [774.0, 1286.0]]}, {"text": "generating human-like text..", "confidence": 0.9881870150566101, "text_region": [[151.0, 1290.0], [505.0, 1290.0], [505.0, 1318.0], [151.0, 1318.0]]}, {"text": "improved by supervised instruction fine-", "confidence": 0.9992833137512207, "text_region": [[776.0, 1290.0], [1275.0, 1290.0], [1275.0, 1318.0], [776.0, 1318.0]]}, {"text": "tuning. This is possible by training the", "confidence": 0.9913023114204407, "text_region": [[772.0, 1320.0], [1241.0, 1320.0], [1241.0, 1349.0], [772.0, 1349.0]]}, {"text": "LLMs have been trained on a large corpus of", "confidence": 0.9951404333114624, "text_region": [[151.0, 1355.0], [704.0, 1355.0], [704.0, 1383.0], [151.0, 1383.0]]}, {"text": "model on specific labeled datasets where", "confidence": 0.9771648645401001, "text_region": [[776.0, 1355.0], [1299.0, 1355.0], [1299.0, 1383.0], [776.0, 1383.0]]}, {"text": "text data. Say, books, articles, conversations", "confidence": 0.992807149887085, "text_region": [[151.0, 1388.0], [704.0, 1388.0], [704.0, 1416.0], [151.0, 1416.0]]}, {"text": "the model will update its weights to further", "confidence": 0.9961829781532288, "text_region": [[774.0, 1388.0], [1308.0, 1388.0], [1308.0, 1416.0], [774.0, 1416.0]]}, {"text": "and more. And the total size of the training", "confidence": 0.9806997776031494, "text_region": [[153.0, 1420.0], [683.0, 1420.0], [683.0, 1449.0], [153.0, 1449.0]]}, {"text": "reduce the errors in its predictions/tasks.", "confidence": 0.9907353520393372, "text_region": [[776.0, 1418.0], [1284.0, 1418.0], [1284.0, 1446.0], [776.0, 1446.0]]}, {"text": "data runs into petabytes. In the first stage,", "confidence": 0.9895792603492737, "text_region": [[151.0, 1449.0], [678.0, 1453.0], [678.0, 1483.0], [151.0, 1479.0]]}, {"text": "After the model has been fine-tuned to.", "confidence": 0.9924247860908508, "text_region": [[778.0, 1455.0], [1264.0, 1455.0], [1264.0, 1477.0], [778.0, 1477.0]]}, {"text": "there's unsupervised learning, where it", "confidence": 0.9984426498413086, "text_region": [[151.0, 1486.0], [635.0, 1486.0], [635.0, 1514.0], [151.0, 1514.0]]}, {"text": "a specific domain, to refine the model's.", "confidence": 0.9851818680763245, "text_region": [[774.0, 1486.0], [1264.0, 1486.0], [1264.0, 1507.0], [774.0, 1507.0]]}, {"text": "learns to identify patterns and relationships", "confidence": 0.9984708428382874, "text_region": [[151.0, 1518.0], [698.0, 1518.0], [698.0, 1546.0], [151.0, 1546.0]]}, {"text": "output further, we can use a technique", "confidence": 0.9995613098144531, "text_region": [[774.0, 1518.0], [1260.0, 1518.0], [1260.0, 1546.0], [774.0, 1546.0]]}, {"text": "in the data it's being fed without any aid", "confidence": 0.9850106835365295, "text_region": [[151.0, 1549.0], [657.0, 1549.0], [657.0, 1577.0], [151.0, 1577.0]]}, {"text": "called Reinforcement Learning from Human", "confidence": 0.9844917058944702, "text_region": [[774.0, 1549.0], [1321.0, 1549.0], [1321.0, 1577.0], [774.0, 1577.0]]}, {"text": "from labels. As of the first stage, there's no", "confidence": 0.9985236525535583, "text_region": [[149.0, 1579.0], [687.0, 1581.0], [687.0, 1612.0], [149.0, 1609.0]]}, {"text": "Feedback (RLHF). Based on how we rate", "confidence": 0.9879689812660217, "text_region": [[776.0, 1581.0], [1273.0, 1581.0], [1273.0, 1609.0], [776.0, 1609.0]]}, {"text": "alignment-i.e., the model doesn't output", "confidence": 0.984778106212616, "text_region": [[151.0, 1614.0], [668.0, 1614.0], [668.0, 1642.0], [151.0, 1642.0]]}, {"text": "the quality of the model output or ask it to", "confidence": 0.9866085648536682, "text_region": [[774.0, 1614.0], [1301.0, 1614.0], [1301.0, 1642.0], [774.0, 1642.0]]}, {"text": "something you want it to. So when you ask,", "confidence": 0.9974857568740845, "text_region": [[151.0, 1648.0], [687.0, 1648.0], [687.0, 1677.0], [151.0, 1677.0]]}, {"text": "modify the output, the model keeps trying", "confidence": 0.999755322933197, "text_region": [[774.0, 1646.0], [1299.0, 1648.0], [1299.0, 1677.0], [774.0, 1674.0]]}, {"text": "\"Hey, what's up?\" it'll probably reply with a", "confidence": 0.9881440997123718, "text_region": [[151.0, 1677.0], [676.0, 1679.0], [676.0, 1709.0], [151.0, 1707.0]]}, {"text": "to make its output better to match what", "confidence": 0.987163245677948, "text_region": [[774.0, 1679.0], [1280.0, 1679.0], [1280.0, 1707.0], [774.0, 1707.0]]}, {"text": "\"What's up, with you?\".", "confidence": 0.9683104157447815, "text_region": [[149.0, 1709.0], [433.0, 1712.0], [433.0, 1742.0], [149.0, 1740.0]]}, {"text": "we need, somewhat like a reward system.", "confidence": 0.9974648952484131, "text_region": [[776.0, 1711.0], [1295.0, 1711.0], [1295.0, 1740.0], [776.0, 1740.0]]}, {"text": "If you use ChatGPT, Gemini, or any other", "confidence": 0.9912856817245483, "text_region": [[776.0, 1744.0], [1277.0, 1744.0], [1277.0, 1772.0], [776.0, 1772.0]]}, {"text": "Al chatbot, you'll sometimes be prompted", "confidence": 0.9981808662414551, "text_region": [[776.0, 1777.0], [1301.0, 1777.0], [1301.0, 1805.0], [776.0, 1805.0]]}, {"text": "to select between different generated", "confidence": 0.9996729493141174, "text_region": [[774.0, 1809.0], [1249.0, 1809.0], [1249.0, 1837.0], [774.0, 1837.0]]}, {"text": "responses or asked to rate a response after", "confidence": 0.9908594489097595, "text_region": [[776.0, 1842.0], [1319.0, 1842.0], [1319.0, 1870.0], [776.0, 1870.0]]}, {"text": "it has been generated-a classic example", "confidence": 0.9879242181777954, "text_region": [[774.0, 1874.0], [1301.0, 1874.0], [1301.0, 1903.0], [774.0, 1903.0]]}, {"text": "of an interactive feedback mechanism in", "confidence": 0.9988747835159302, "text_region": [[774.0, 1907.0], [1293.0, 1907.0], [1293.0, 1935.0], [774.0, 1935.0]]}, {"text": "action.", "confidence": 0.9998798370361328, "text_region": [[774.0, 1942.0], [861.0, 1942.0], [861.0, 1966.0], [774.0, 1966.0]]}, {"text": "Galileo", "confidence": 0.9922691583633423, "text_region": [[244.0, 1998.0], [349.0, 1998.0], [349.0, 2031.0], [244.0, 2031.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9688573479652405, "text_region": [[1145.0, 2000.0], [1338.0, 2000.0], [1338.0, 2029.0], [1145.0, 2029.0]]}], "img_idx": 0}

{"type": "text", "bbox": [775, 391, 1331, 787], "res": [{"text": "become more amplified with deteriorating", "confidence": 0.9997867345809937, "text_region": [[777.0, 398.0], [1304.0, 400.0], [1304.0, 425.0], [777.0, 423.0]]}, {"text": "data quality. Another reason why an LLM", "confidence": 0.9842677712440491, "text_region": [[780.0, 435.0], [1278.0, 435.0], [1278.0, 456.0], [780.0, 456.0]]}, {"text": "may output erroneous results is due to the", "confidence": 0.9826922416687012, "text_region": [[780.0, 467.0], [1303.0, 467.0], [1303.0, 488.0], [780.0, 488.0]]}, {"text": "Iack of context in a user's prompt. Without", "confidence": 0.9859243631362915, "text_region": [[779.0, 498.0], [1298.0, 499.0], [1298.0, 521.0], [779.0, 520.0]]}, {"text": "proper context, the LLM doesn't \"actually", "confidence": 0.9780905842781067, "text_region": [[779.0, 531.0], [1276.0, 531.0], [1276.0, 555.0], [779.0, 555.0]]}, {"text": "know\" what you expect from it. For example,", "confidence": 0.994714617729187, "text_region": [[779.0, 564.0], [1319.0, 564.0], [1319.0, 588.0], [779.0, 588.0]]}, {"text": "f you prompt \"What's the capital?\" and", "confidence": 0.9865153431892395, "text_region": [[779.0, 596.0], [1266.0, 596.0], [1266.0, 620.0], [779.0, 620.0]]}, {"text": "do not specify the country, then the model", "confidence": 0.9957863688468933, "text_region": [[778.0, 629.0], [1305.0, 629.0], [1305.0, 653.0], [778.0, 653.0]]}, {"text": "has no way of knowing what you're looking", "confidence": 0.9887944459915161, "text_region": [[777.0, 660.0], [1308.0, 661.0], [1307.0, 686.0], [777.0, 685.0]]}, {"text": "for. Without context, the LLM is bound to", "confidence": 0.985406756401062, "text_region": [[779.0, 695.0], [1265.0, 695.0], [1265.0, 716.0], [779.0, 716.0]]}, {"text": "generate results that won't align with what", "confidence": 0.9998270869255066, "text_region": [[777.0, 725.0], [1308.0, 724.0], [1309.0, 749.0], [777.0, 750.0]]}, {"text": "you're looking for. (See Fig 1.1).", "confidence": 0.9875074028968811, "text_region": [[777.0, 757.0], [1136.0, 756.0], [1136.0, 781.0], [777.0, 782.0]]}], "img_idx": 0}
{"type": "text", "bbox": [152, 392, 721, 819], "res": [{"text": "Firstly, you'll see how the word.", "confidence": 0.990166962146759, "text_region": [[155.0, 399.0], [526.0, 398.0], [526.0, 423.0], [155.0, 424.0]]}, {"text": "'hallucinations\" is practically everywhere", "confidence": 0.9871670007705688, "text_region": [[155.0, 431.0], [663.0, 433.0], [663.0, 458.0], [155.0, 456.0]]}, {"text": "there's a mention of LLMs. Also better termed", "confidence": 0.9664127826690674, "text_region": [[155.0, 465.0], [709.0, 466.0], [709.0, 486.0], [155.0, 485.0]]}, {"text": "as \"confabulations\". This is the model.", "confidence": 0.973713219165802, "text_region": [[156.0, 499.0], [617.0, 499.0], [617.0, 519.0], [156.0, 519.0]]}, {"text": "throwing plausible but incorrect or entirely", "confidence": 0.9887906908988953, "text_region": [[154.0, 528.0], [680.0, 531.0], [679.0, 555.0], [154.0, 553.0]]}, {"text": "fabricated answers at you, meaning you", "confidence": 0.9917753338813782, "text_region": [[154.0, 562.0], [658.0, 564.0], [658.0, 588.0], [154.0, 586.0]]}, {"text": "should always double-check what the", "confidence": 0.9914736151695251, "text_region": [[155.0, 596.0], [629.0, 595.0], [629.0, 617.0], [155.0, 618.0]]}, {"text": "LLM outputs. There are, of course, several", "confidence": 0.9911122918128967, "text_region": [[156.0, 630.0], [658.0, 630.0], [658.0, 651.0], [156.0, 651.0]]}, {"text": "reasons why this happens. Primarily, LLMs", "confidence": 0.9995149970054626, "text_region": [[155.0, 661.0], [667.0, 661.0], [667.0, 685.0], [155.0, 685.0]]}, {"text": "Iack \"common sense,\" i.e., they're not.", "confidence": 0.9717741012573242, "text_region": [[155.0, 694.0], [613.0, 695.0], [613.0, 716.0], [155.0, 715.0]]}, {"text": "primarily reasoning machines.Remember", "confidence": 0.9848691821098328, "text_region": [[156.0, 727.0], [678.0, 726.0], [678.0, 747.0], [156.0, 748.0]]}, {"text": "that they're trained to predict the word that's", "confidence": 0.9982510209083557, "text_region": [[155.0, 759.0], [710.0, 758.0], [710.0, 780.0], [155.0, 781.0]]}, {"text": "most likely to occur next. The problem may", "confidence": 0.9778175354003906, "text_region": [[156.0, 790.0], [685.0, 792.0], [685.0, 814.0], [156.0, 812.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [12, 429, 1415, 2104], "res": [{"text": "\"hallucinations\" is practically everywhere", "confidence": 0.9992657899856567, "text_region": [[152.0, 431.0], [664.0, 433.0], [664.0, 457.0], [152.0, 455.0]]}, {"text": "data quality. Another reason why an LLM", "confidence": 0.9971728324890137, "text_region": [[777.0, 434.0], [1278.0, 434.0], [1278.0, 457.0], [777.0, 457.0]]}, {"text": "there's a mention of LLMs. Also better termed.", "confidence": 0.9920552372932434, "text_region": [[151.0, 462.0], [710.0, 464.0], [710.0, 488.0], [151.0, 487.0]]}, {"text": "may output erroneous results is due to the", "confidence": 0.989331841468811, "text_region": [[775.0, 466.0], [1305.0, 466.0], [1305.0, 490.0], [775.0, 490.0]]}, {"text": "as \"confabulations\". This is the model", "confidence": 0.9990337491035461, "text_region": [[151.0, 497.0], [619.0, 495.0], [619.0, 520.0], [151.0, 522.0]]}, {"text": "lack of context in a user's prompt. Without", "confidence": 0.9811716079711914, "text_region": [[771.0, 495.0], [1299.0, 494.0], [1299.0, 523.0], [771.0, 525.0]]}, {"text": "throwing plausible but incorrect or entirely", "confidence": 0.9990732073783875, "text_region": [[152.0, 530.0], [678.0, 530.0], [678.0, 555.0], [152.0, 555.0]]}, {"text": "proper context, the LLM doesn't \"actually", "confidence": 0.9913824200630188, "text_region": [[777.0, 530.0], [1276.0, 530.0], [1276.0, 555.0], [777.0, 555.0]]}, {"text": "fabricated answers at you, meaning you", "confidence": 0.9995231628417969, "text_region": [[149.0, 558.0], [659.0, 562.0], [659.0, 591.0], [149.0, 588.0]]}, {"text": "know\" what you expect from it. For example.", "confidence": 0.9852805733680725, "text_region": [[777.0, 563.0], [1319.0, 563.0], [1319.0, 588.0], [777.0, 588.0]]}, {"text": "should always double-check what the", "confidence": 0.9976293444633484, "text_region": [[152.0, 597.0], [629.0, 597.0], [629.0, 619.0], [152.0, 619.0]]}, {"text": "if you prompt \"what's the capital?\" and", "confidence": 0.9837852716445923, "text_region": [[777.0, 595.0], [1264.0, 595.0], [1264.0, 619.0], [777.0, 619.0]]}, {"text": "LLM outputs. There are, of course, several", "confidence": 0.9888116717338562, "text_region": [[152.0, 628.0], [659.0, 628.0], [659.0, 652.0], [152.0, 652.0]]}, {"text": "do not specify the country, then the model", "confidence": 0.9870624542236328, "text_region": [[777.0, 628.0], [1305.0, 628.0], [1305.0, 652.0], [777.0, 652.0]]}, {"text": "reasons why this happens. Primarily, LLMs", "confidence": 0.9864278435707092, "text_region": [[151.0, 659.0], [664.0, 659.0], [664.0, 684.0], [151.0, 684.0]]}, {"text": "has no way of knowing what you're looking", "confidence": 0.9933373332023621, "text_region": [[775.0, 661.0], [1308.0, 661.0], [1308.0, 685.0], [775.0, 685.0]]}, {"text": "Iack \"common sense,\" i.e., they're not", "confidence": 0.9804831147193909, "text_region": [[152.0, 691.0], [614.0, 691.0], [614.0, 715.0], [152.0, 715.0]]}, {"text": "for. Without context, the LLM is bound to", "confidence": 0.9750391244888306, "text_region": [[775.0, 692.0], [1264.0, 692.0], [1264.0, 717.0], [775.0, 717.0]]}, {"text": "primarily reasoning machines. Remember", "confidence": 0.9998039603233337, "text_region": [[154.0, 726.0], [678.0, 726.0], [678.0, 750.0], [154.0, 750.0]]}, {"text": "generate results that won't align with what.", "confidence": 0.9949805736541748, "text_region": [[773.0, 724.0], [1310.0, 720.0], [1310.0, 750.0], [773.0, 754.0]]}, {"text": "that they're trained to predict the word that's.", "confidence": 0.9888591170310974, "text_region": [[152.0, 759.0], [712.0, 759.0], [712.0, 783.0], [152.0, 783.0]]}, {"text": "you're looking for. (See Fig 1.1)", "confidence": 0.9963815808296204, "text_region": [[773.0, 755.0], [1140.0, 755.0], [1140.0, 785.0], [773.0, 785.0]]}, {"text": "most likely to occur next. The problem may.", "confidence": 0.9836171865463257, "text_region": [[151.0, 787.0], [687.0, 788.0], [687.0, 818.0], [151.0, 816.0]]}, {"text": "23:56", "confidence": 0.997724711894989, "text_region": [[826.0, 987.0], [870.0, 987.0], [870.0, 1014.0], [826.0, 1014.0]]}, {"text": "", "confidence": 0.0, "text_region": [[1043.0, 987.0], [1127.0, 987.0], [1127.0, 1012.0], [1043.0, 1012.0]]}, {"text": "User Input", "confidence": 0.9953103065490723, "text_region": [[912.0, 1083.0], [984.0, 1087.0], [983.0, 1106.0], [911.0, 1102.0]]}, {"text": "HI THERE!", "confidence": 0.9828470945358276, "text_region": [[450.0, 1096.0], [587.0, 1096.0], [587.0, 1136.0], [450.0, 1136.0]]}, {"text": "Can you", "confidence": 0.989838719367981, "text_region": [[915.0, 1108.0], [998.0, 1108.0], [998.0, 1127.0], [915.0, 1127.0]]}, {"text": "recommend a", "confidence": 0.9894174337387085, "text_region": [[913.0, 1129.0], [1059.0, 1129.0], [1059.0, 1151.0], [913.0, 1151.0]]}, {"text": "delicious recipe", "confidence": 0.9947915077209473, "text_region": [[912.0, 1149.0], [1070.0, 1153.0], [1069.0, 1176.0], [911.0, 1172.0]]}, {"text": "for dinner?", "confidence": 0.9703830480575562, "text_region": [[913.0, 1178.0], [1020.0, 1178.0], [1020.0, 1197.0], [913.0, 1197.0]]}, {"text": "LLM Response", "confidence": 0.9257643222808838, "text_region": [[845.0, 1263.0], [940.0, 1263.0], [940.0, 1282.0], [845.0, 1282.0]]}, {"text": "Yes, here is a", "confidence": 0.9872341752052307, "text_region": [[850.0, 1289.0], [978.0, 1289.0], [978.0, 1308.0], [850.0, 1308.0]]}, {"text": "delicious recipe for", "confidence": 0.9980825185775757, "text_region": [[850.0, 1312.0], [1034.0, 1312.0], [1034.0, 1335.0], [850.0, 1335.0]]}, {"text": "lunch. So how", "confidence": 0.9633297324180603, "text_region": [[850.0, 1334.0], [985.0, 1336.0], [985.0, 1356.0], [850.0, 1354.0]]}, {"text": "about fried", "confidence": 0.9594370126724243, "text_region": [[852.0, 1361.0], [961.0, 1361.0], [961.0, 1380.0], [852.0, 1380.0]]}, {"text": "chicken with", "confidence": 0.9812278747558594, "text_region": [[850.0, 1383.0], [973.0, 1383.0], [973.0, 1403.0], [850.0, 1403.0]]}, {"text": "mashed potatoes?", "confidence": 0.9978935122489929, "text_region": [[849.0, 1406.0], [1036.0, 1406.0], [1036.0, 1429.0], [849.0, 1429.0]]}, {"text": "In addition,", "confidence": 0.9701046347618103, "text_region": [[850.0, 1431.0], [959.0, 1431.0], [959.0, 1450.0], [850.0, 1450.0]]}, {"text": "tomatoes are also", "confidence": 0.971239447593689, "text_region": [[850.0, 1453.0], [1029.0, 1453.0], [1029.0, 1471.0], [850.0, 1471.0]]}, {"text": "an excellent", "confidence": 0.9628067016601562, "text_region": [[852.0, 1478.0], [970.0, 1478.0], [970.0, 1497.0], [852.0, 1497.0]]}, {"text": "pairing for this", "confidence": 0.9997807741165161, "text_region": [[849.0, 1500.0], [994.0, 1500.0], [994.0, 1523.0], [849.0, 1523.0]]}, {"text": "000", "confidence": 0.957707941532135, "text_region": [[578.0, 1516.0], [626.0, 1516.0], [626.0, 1535.0], [578.0, 1535.0]]}, {"text": "dish as they are", "confidence": 0.9988924264907837, "text_region": [[849.0, 1523.0], [1008.0, 1523.0], [1008.0, 1546.0], [849.0, 1546.0]]}, {"text": "rich in calcium.", "confidence": 0.9715620875358582, "text_region": [[849.0, 1546.0], [1001.0, 1546.0], [1001.0, 1568.0], [849.0, 1568.0]]}, {"text": "Enjoy this steak!", "confidence": 0.9995562434196472, "text_region": [[849.0, 1570.0], [1006.0, 1570.0], [1006.0, 1593.0], [849.0, 1593.0]]}, {"text": "Hallucination Explanation", "confidence": 0.9997190833091736, "text_region": [[577.0, 1732.0], [910.0, 1732.0], [910.0, 1757.0], [577.0, 1757.0]]}, {"text": "Input-Conflicting Hallucination: : Context-Conflicting Hallucination: : Fact-Conflicting Hallucination:", "confidence": 0.9754900336265564, "text_region": [[180.0, 1783.0], [1317.0, 1783.0], [1317.0, 1807.0], [180.0, 1807.0]]}, {"text": "the user wants a recipe for", "confidence": 0.9996190071105957, "text_region": [[179.0, 1813.0], [482.0, 1813.0], [482.0, 1835.0], [179.0, 1835.0]]}, {"text": "steak has not been mentioned in", "confidence": 0.9998117685317993, "text_region": [[561.0, 1813.0], [940.0, 1813.0], [940.0, 1835.0], [561.0, 1835.0]]}, {"text": ": tomatoes are not rich in", "confidence": 0.9930508732795715, "text_region": [[954.0, 1813.0], [1247.0, 1813.0], [1247.0, 1835.0], [954.0, 1835.0]]}, {"text": "dinner while LLM provide one", "confidence": 0.9945011734962463, "text_region": [[179.0, 1837.0], [503.0, 1841.0], [503.0, 1863.0], [179.0, 1860.0]]}, {"text": "the preceding context.", "confidence": 0.9995603561401367, "text_region": [[561.0, 1841.0], [815.0, 1841.0], [815.0, 1863.0], [561.0, 1863.0]]}, {"text": "calcium in fact.", "confidence": 0.9932486414909363, "text_region": [[970.0, 1837.0], [1149.0, 1839.0], [1148.0, 1863.0], [969.0, 1861.0]]}, {"text": "for lunch.", "confidence": 0.9974225163459778, "text_region": [[179.0, 1867.0], [286.0, 1867.0], [286.0, 1891.0], [179.0, 1891.0]]}, {"text": "Fig 1.1: Example of LLM hallucination on ChatGPT.", "confidence": 0.9747456908226013, "text_region": [[473.0, 1930.0], [1013.0, 1928.0], [1013.0, 1952.0], [473.0, 1954.0]]}, {"text": "Galileo", "confidence": 0.9797354340553284, "text_region": [[245.0, 1990.0], [354.0, 1995.0], [353.0, 2033.0], [243.0, 2029.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9991854429244995, "text_region": [[1147.0, 2005.0], [1336.0, 2005.0], [1336.0, 2027.0], [1147.0, 2027.0]]}], "img_idx": 0}

{"type": "text", "bbox": [152, 461, 711, 1018], "res": [{"text": "Second, LLMs have a knowledge cut-off", "confidence": 0.9918603897094727, "text_region": [[156.0, 470.0], [644.0, 470.0], [644.0, 494.0], [156.0, 494.0]]}, {"text": "date. This is the date up to which the model.", "confidence": 0.9980305433273315, "text_region": [[155.0, 502.0], [696.0, 502.0], [696.0, 526.0], [155.0, 526.0]]}, {"text": "was trained. If you were to ask this type of", "confidence": 0.9990903735160828, "text_region": [[155.0, 536.0], [673.0, 536.0], [673.0, 559.0], [155.0, 559.0]]}, {"text": "system, \"Who won the Premier League last.", "confidence": 0.9767980575561523, "text_region": [[156.0, 567.0], [681.0, 566.0], [681.0, 591.0], [156.0, 592.0]]}, {"text": "week?\" and its knowledge cut-off date is.", "confidence": 0.9834546446800232, "text_region": [[155.0, 600.0], [659.0, 600.0], [659.0, 624.0], [155.0, 624.0]]}, {"text": "2022, then it wouldn't have any idea. So, it.", "confidence": 0.9938908815383911, "text_region": [[156.0, 632.0], [669.0, 633.0], [669.0, 655.0], [156.0, 653.0]]}, {"text": "may return an error message saying, \"My", "confidence": 0.9872613549232483, "text_region": [[155.0, 665.0], [666.0, 667.0], [666.0, 690.0], [155.0, 688.0]]}, {"text": "training only includes knowledge up until", "confidence": 0.991521418094635, "text_region": [[154.0, 696.0], [667.0, 698.0], [667.0, 722.0], [154.0, 721.0]]}, {"text": "January 2022, and I don't have access", "confidence": 0.9843829274177551, "text_region": [[155.0, 730.0], [635.0, 729.0], [635.0, 753.0], [155.0, 754.0]]}, {"text": "to real-time data.\" What's happening is", "confidence": 0.9852808713912964, "text_region": [[155.0, 763.0], [646.0, 763.0], [646.0, 787.0], [155.0, 787.0]]}, {"text": "the model is trying to access its static", "confidence": 0.9990704655647278, "text_region": [[155.0, 796.0], [623.0, 796.0], [623.0, 819.0], [155.0, 819.0]]}, {"text": "knowledge base for the answer, but it hasn't.", "confidence": 0.9778394103050232, "text_region": [[155.0, 828.0], [703.0, 828.0], [703.0, 851.0], [155.0, 851.0]]}, {"text": "found the answer there. There's no way that.", "confidence": 0.9958900809288025, "text_region": [[155.0, 860.0], [698.0, 861.0], [698.0, 883.0], [155.0, 882.0]]}, {"text": "a model can be re-trained over and over", "confidence": 0.9408321976661682, "text_region": [[157.0, 895.0], [663.0, 895.0], [663.0, 913.0], [157.0, 913.0]]}, {"text": "again every time there's new information,", "confidence": 0.99241042137146, "text_region": [[156.0, 926.0], [670.0, 926.0], [670.0, 949.0], [156.0, 949.0]]}, {"text": "which will bring us to the core topic of this", "confidence": 0.9920676946640015, "text_region": [[155.0, 958.0], [673.0, 958.0], [673.0, 981.0], [155.0, 981.0]]}, {"text": "ebook: RAGs.", "confidence": 0.9994701743125916, "text_region": [[153.0, 987.0], [311.0, 989.0], [311.0, 1014.0], [153.0, 1012.0]]}], "img_idx": 0}
{"type": "text", "bbox": [461, 1795, 1027, 1826], "res": [{"text": "Fig 1.2: Personal information showing in LLM outpui", "confidence": 0.9701246619224548, "text_region": [[465.0, 1802.0], [1022.0, 1802.0], [1022.0, 1821.0], [465.0, 1821.0]]}], "img_idx": 0}
{"type": "text", "bbox": [153, 1048, 697, 1147], "res": [{"text": "Third is the problem that's widely prevailing", "confidence": 0.9838018417358398, "text_region": [[155.0, 1053.0], [691.0, 1056.0], [691.0, 1080.0], [155.0, 1077.0]]}, {"text": "with the use of LLMs: bias, misinformation,", "confidence": 0.9968047738075256, "text_region": [[155.0, 1087.0], [668.0, 1088.0], [668.0, 1110.0], [155.0, 1109.0]]}, {"text": "and lack of transparency.", "confidence": 0.970815896987915, "text_region": [[154.0, 1117.0], [472.0, 1121.0], [472.0, 1145.0], [154.0, 1141.0]]}], "img_idx": 0}
{"type": "text", "bbox": [775, 462, 1340, 1117], "res": [{"text": "Due to inherent bias in the training", "confidence": 0.9959084987640381, "text_region": [[777.0, 468.0], [1205.0, 470.0], [1205.0, 495.0], [777.0, 493.0]]}, {"text": "dataset, LLMs may end up amplifying", "confidence": 0.9783458113670349, "text_region": [[777.0, 500.0], [1237.0, 504.0], [1237.0, 529.0], [777.0, 524.0]]}, {"text": "and perpetuating existing biases across", "confidence": 0.9878438115119934, "text_region": [[778.0, 535.0], [1276.0, 537.0], [1276.0, 561.0], [778.0, 559.0]]}, {"text": "different dimensions like gender, race,", "confidence": 0.9979104995727539, "text_region": [[777.0, 566.0], [1249.0, 567.0], [1249.0, 592.0], [777.0, 591.0]]}, {"text": "ethnicity, class, color, and others. Lack of", "confidence": 0.9731363654136658, "text_region": [[780.0, 602.0], [1279.0, 602.0], [1279.0, 623.0], [780.0, 623.0]]}, {"text": "transparency and explainability means.", "confidence": 0.9826374053955078, "text_region": [[778.0, 634.0], [1265.0, 634.0], [1265.0, 657.0], [778.0, 657.0]]}, {"text": "there's no way of tracing back the output", "confidence": 0.9982178211212158, "text_region": [[778.0, 665.0], [1288.0, 666.0], [1288.0, 689.0], [778.0, 688.0]]}, {"text": "to the input data, which may have led to", "confidence": 0.9916702508926392, "text_region": [[779.0, 699.0], [1278.0, 699.0], [1278.0, 720.0], [779.0, 720.0]]}, {"text": "bias in its output. Finally, there's the issue..", "confidence": 0.9802867770195007, "text_region": [[779.0, 731.0], [1284.0, 731.0], [1284.0, 755.0], [779.0, 755.0]]}, {"text": "of violation of privacy. This happens when", "confidence": 0.9969398975372314, "text_region": [[779.0, 763.0], [1295.0, 763.0], [1295.0, 786.0], [779.0, 786.0]]}, {"text": "the LLM outputs confidential information in", "confidence": 0.9824701547622681, "text_region": [[779.0, 797.0], [1303.0, 797.0], [1303.0, 817.0], [779.0, 817.0]]}, {"text": "its output. This is most likely because it has", "confidence": 0.9825639128684998, "text_region": [[779.0, 829.0], [1307.0, 829.0], [1307.0, 850.0], [779.0, 850.0]]}, {"text": "been trained on very large amounts of data.", "confidence": 0.9858078360557556, "text_region": [[778.0, 861.0], [1325.0, 861.0], [1325.0, 885.0], [778.0, 885.0]]}, {"text": "and there's a high possibility that a lot of this", "confidence": 0.9820322394371033, "text_region": [[778.0, 893.0], [1331.0, 893.0], [1331.0, 916.0], [778.0, 916.0]]}, {"text": "data has personal information like name,", "confidence": 0.977368175983429, "text_region": [[778.0, 926.0], [1289.0, 926.0], [1289.0, 949.0], [778.0, 949.0]]}, {"text": "address, phone number, etc. The LLM ends", "confidence": 0.985622763633728, "text_region": [[779.0, 958.0], [1301.0, 957.0], [1301.0, 979.0], [779.0, 980.0]]}, {"text": "up regurgitating snippets of this training", "confidence": 0.9901721477508545, "text_region": [[779.0, 991.0], [1276.0, 991.0], [1276.0, 1016.0], [779.0, 1016.0]]}, {"text": "data in its output. Fig 1.2 shows how personal", "confidence": 0.9949387907981873, "text_region": [[779.0, 1023.0], [1331.0, 1023.0], [1331.0, 1046.0], [779.0, 1046.0]]}, {"text": "information can end up surfacing in an LLM's", "confidence": 0.9918959140777588, "text_region": [[777.0, 1054.0], [1330.0, 1056.0], [1330.0, 1080.0], [777.0, 1078.0]]}, {"text": "output.", "confidence": 0.9869429469108582, "text_region": [[776.0, 1087.0], [864.0, 1087.0], [864.0, 1113.0], [776.0, 1113.0]]}], "img_idx": 0}
{"type": "text", "bbox": [5, 1855, 1487, 1964], "res": [{"text": "In the scope of this book, we'll be laser-focused on solving the first two challenges through the", "confidence": 0.9860034584999084, "text_region": [[153.0, 1864.0], [1323.0, 1864.0], [1323.0, 1886.0], [153.0, 1886.0]]}, {"text": "use of RAGs. Ahead, we'll also look at how you can build enterprise-level RAG systems that you", "confidence": 0.9920064806938171, "text_region": [[153.0, 1892.0], [1326.0, 1894.0], [1326.0, 1918.0], [153.0, 1916.0]]}, {"text": "can deploy and make available for external use.", "confidence": 0.9727169871330261, "text_region": [[153.0, 1928.0], [751.0, 1928.0], [751.0, 1950.0], [153.0, 1950.0]]}], "img_idx": 0}
{"type": "text", "bbox": [200, 310, 1280, 411], "res": [{"text": "Factual hallucinations will give you incorrect facts or details. Semantic hallucination", "confidence": 0.9695369601249695, "text_region": [[203.0, 317.0], [1265.0, 316.0], [1265.0, 338.0], [203.0, 339.0]]}, {"text": "esults in nonsensical sections in the LLM output. Confabulation is the tendency to fill.", "confidence": 0.9866832494735718, "text_region": [[203.0, 349.0], [1270.0, 349.0], [1270.0, 373.0], [203.0, 373.0]]}, {"text": "in the gaps in the narrative by providing plausible explanations", "confidence": 0.9692931771278381, "text_region": [[202.0, 382.0], [1003.0, 383.0], [1003.0, 405.0], [202.0, 404.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [589, 1178, 881, 1762], "res": [{"text": "23:56", "confidence": 0.966175377368927, "text_region": [[611.0, 1191.0], [648.0, 1191.0], [648.0, 1209.0], [611.0, 1209.0]]}, {"text": "", "confidence": 0.0, "text_region": [[800.0, 1191.0], [870.0, 1191.0], [870.0, 1209.0], [800.0, 1209.0]]}, {"text": "User Input", "confidence": 0.9917579889297485, "text_region": [[686.0, 1274.0], [746.0, 1277.0], [746.0, 1291.0], [685.0, 1288.0]]}, {"text": "What's", "confidence": 0.9961257576942444, "text_region": [[685.0, 1306.0], [771.0, 1308.0], [770.0, 1330.0], [684.0, 1328.0]]}, {"text": "John Doe's", "confidence": 0.9991281628608704, "text_region": [[687.0, 1337.0], [820.0, 1337.0], [820.0, 1357.0], [687.0, 1357.0]]}, {"text": "credit card", "confidence": 0.9994829297065735, "text_region": [[686.0, 1367.0], [821.0, 1367.0], [821.0, 1388.0], [686.0, 1388.0]]}, {"text": "number?", "confidence": 0.9995765686035156, "text_region": [[686.0, 1397.0], [797.0, 1397.0], [797.0, 1418.0], [686.0, 1418.0]]}, {"text": "LLM Response", "confidence": 0.9623849987983704, "text_region": [[630.0, 1513.0], [708.0, 1513.0], [708.0, 1525.0], [630.0, 1525.0]]}, {"text": "John Doe's", "confidence": 0.9981449246406555, "text_region": [[632.0, 1549.0], [766.0, 1549.0], [766.0, 1570.0], [632.0, 1570.0]]}, {"text": "credit card", "confidence": 0.9875468611717224, "text_region": [[629.0, 1580.0], [766.0, 1577.0], [767.0, 1599.0], [630.0, 1601.0]]}, {"text": "number is", "confidence": 0.9673287868499756, "text_region": [[629.0, 1609.0], [755.0, 1609.0], [755.0, 1630.0], [629.0, 1630.0]]}, {"text": "2194-2091-", "confidence": 0.990498423576355, "text_region": [[631.0, 1638.0], [768.0, 1638.0], [768.0, 1660.0], [631.0, 1660.0]]}, {"text": "7472-1560", "confidence": 0.9961445927619934, "text_region": [[631.0, 1669.0], [759.0, 1669.0], [759.0, 1689.0], [631.0, 1689.0]]}], "img_idx": 0}
{"type": "figure", "bbox": [152, 104, 1341, 1768], "res": [{"text": "8", "confidence": 0.9953415393829346, "text_region": [[1320.0, 118.0], [1334.0, 118.0], [1334.0, 137.0], [1320.0, 137.0]]}, {"text": "Ledrn more", "confidence": 0.9045307040214539, "text_region": [[320.0, 257.0], [522.0, 257.0], [522.0, 281.0], [320.0, 281.0]]}, {"text": "Factual hallucinations will give you incorrect facts or details. Semantic hallucination", "confidence": 0.9781523942947388, "text_region": [[198.0, 317.0], [1265.0, 317.0], [1265.0, 340.0], [198.0, 340.0]]}, {"text": "results in nonsensical sections in the LLM output. Confabulation is the tendency to fill.", "confidence": 0.9810053706169128, "text_region": [[196.0, 348.0], [1270.0, 348.0], [1270.0, 373.0], [196.0, 373.0]]}, {"text": "in the gaps in the narrative by providing plausible explanations..", "confidence": 0.9892128705978394, "text_region": [[193.0, 378.0], [1007.0, 380.0], [1007.0, 409.0], [193.0, 407.0]]}, {"text": "Second, LLMs have a knowledge cut-off", "confidence": 0.9919788241386414, "text_region": [[156.0, 470.0], [644.0, 470.0], [644.0, 494.0], [156.0, 494.0]]}, {"text": "Due to inherent bias in the training", "confidence": 0.9927716851234436, "text_region": [[773.0, 466.0], [1207.0, 468.0], [1206.0, 498.0], [773.0, 496.0]]}, {"text": "date. This is the date up to which the model.", "confidence": 0.9894728660583496, "text_region": [[156.0, 503.0], [697.0, 503.0], [697.0, 525.0], [156.0, 525.0]]}, {"text": "dataset, LLMs may end up amplifying", "confidence": 0.9843873381614685, "text_region": [[777.0, 503.0], [1237.0, 503.0], [1237.0, 527.0], [777.0, 527.0]]}, {"text": "was trained. If you were to ask this type of", "confidence": 0.9990283846855164, "text_region": [[156.0, 536.0], [672.0, 536.0], [672.0, 560.0], [156.0, 560.0]]}, {"text": "and perpetuating existing biases across", "confidence": 0.9961497783660889, "text_region": [[777.0, 536.0], [1277.0, 536.0], [1277.0, 560.0], [777.0, 560.0]]}, {"text": "system, \"Who won the Premier League last", "confidence": 0.9731138348579407, "text_region": [[156.0, 567.0], [679.0, 567.0], [679.0, 591.0], [156.0, 591.0]]}, {"text": "different dimensions like gender, race,", "confidence": 0.9989462494850159, "text_region": [[777.0, 569.0], [1251.0, 569.0], [1251.0, 593.0], [777.0, 593.0]]}, {"text": "week?\" and its knowledge cut-off date is", "confidence": 0.9983507394790649, "text_region": [[154.0, 600.0], [658.0, 600.0], [658.0, 624.0], [154.0, 624.0]]}, {"text": "ethnicity, class, color, and others. Lack of", "confidence": 0.9865423440933228, "text_region": [[775.0, 598.0], [1279.0, 598.0], [1279.0, 622.0], [775.0, 622.0]]}, {"text": "2022, then it wouldn't have any idea. So, it", "confidence": 0.9717583060264587, "text_region": [[154.0, 629.0], [670.0, 631.0], [670.0, 655.0], [154.0, 653.0]]}, {"text": "transparency and explainability means", "confidence": 0.9971826076507568, "text_region": [[775.0, 633.0], [1267.0, 633.0], [1267.0, 657.0], [775.0, 657.0]]}, {"text": "may return an error message saying, \"My", "confidence": 0.9895837306976318, "text_region": [[156.0, 662.0], [665.0, 666.0], [665.0, 693.0], [155.0, 690.0]]}, {"text": "there's no way of tracing back the output", "confidence": 0.985823929309845, "text_region": [[775.0, 666.0], [1288.0, 666.0], [1288.0, 688.0], [775.0, 688.0]]}, {"text": "training only includes knowledge up until", "confidence": 0.9996379613876343, "text_region": [[156.0, 697.0], [665.0, 697.0], [665.0, 721.0], [156.0, 721.0]]}, {"text": "to the input data, which may have led to", "confidence": 0.9761956930160522, "text_region": [[775.0, 697.0], [1279.0, 697.0], [1279.0, 721.0], [775.0, 721.0]]}, {"text": "January 2022, and I don't have access", "confidence": 0.9898601174354553, "text_region": [[154.0, 728.0], [635.0, 732.0], [635.0, 756.0], [154.0, 752.0]]}, {"text": "bias in its output. Finally, there's the issue", "confidence": 0.9857804775238037, "text_region": [[775.0, 730.0], [1286.0, 730.0], [1286.0, 754.0], [775.0, 754.0]]}, {"text": "to real-time data.\" What's happening is", "confidence": 0.9770621061325073, "text_region": [[156.0, 763.0], [647.0, 763.0], [647.0, 787.0], [156.0, 787.0]]}, {"text": "of violation of privacy. This happens when", "confidence": 0.9919049143791199, "text_region": [[775.0, 763.0], [1295.0, 763.0], [1295.0, 787.0], [775.0, 787.0]]}, {"text": "the model is trying to access its static", "confidence": 0.9943702816963196, "text_region": [[156.0, 796.0], [623.0, 796.0], [623.0, 820.0], [156.0, 820.0]]}, {"text": "the LLM outputs confidential information in", "confidence": 0.9826271533966064, "text_region": [[775.0, 794.0], [1304.0, 794.0], [1304.0, 818.0], [775.0, 818.0]]}, {"text": "knowledge base for the answer, but it hasn't", "confidence": 0.9891816973686218, "text_region": [[154.0, 827.0], [704.0, 825.0], [704.0, 849.0], [154.0, 851.0]]}, {"text": "its output. This is most likely because it has", "confidence": 0.9846369624137878, "text_region": [[775.0, 829.0], [1309.0, 829.0], [1309.0, 851.0], [775.0, 851.0]]}, {"text": "found the answer there. There's no way that", "confidence": 0.9982272982597351, "text_region": [[154.0, 858.0], [699.0, 860.0], [699.0, 884.0], [154.0, 882.0]]}, {"text": "been trained on very large amounts of data", "confidence": 0.9812806248664856, "text_region": [[777.0, 861.0], [1323.0, 861.0], [1323.0, 884.0], [777.0, 884.0]]}, {"text": "a model can be re-trained over and over", "confidence": 0.9990116953849792, "text_region": [[156.0, 893.0], [665.0, 893.0], [665.0, 915.0], [156.0, 915.0]]}, {"text": "and there's a high possibility that a lot of this", "confidence": 0.9818841814994812, "text_region": [[777.0, 893.0], [1330.0, 893.0], [1330.0, 917.0], [777.0, 917.0]]}, {"text": "again every time there's new information,", "confidence": 0.9993363618850708, "text_region": [[156.0, 926.0], [670.0, 926.0], [670.0, 950.0], [156.0, 950.0]]}, {"text": "data has personal information like name,", "confidence": 0.9937874674797058, "text_region": [[777.0, 926.0], [1288.0, 926.0], [1288.0, 950.0], [777.0, 950.0]]}, {"text": "which will bring us to the core topic of this", "confidence": 0.9987752437591553, "text_region": [[154.0, 957.0], [674.0, 957.0], [674.0, 981.0], [154.0, 981.0]]}, {"text": "address, phone number, etc. The LLM ends", "confidence": 0.9872794151306152, "text_region": [[777.0, 959.0], [1302.0, 959.0], [1302.0, 981.0], [777.0, 981.0]]}, {"text": "ebook: RAGs.", "confidence": 0.9995673298835754, "text_region": [[156.0, 991.0], [311.0, 991.0], [311.0, 1014.0], [156.0, 1014.0]]}, {"text": "up regurgitating snippets of this training", "confidence": 0.9994522333145142, "text_region": [[777.0, 991.0], [1277.0, 991.0], [1277.0, 1016.0], [777.0, 1016.0]]}, {"text": "data in its output. Fig 1.2 shows how personal", "confidence": 0.9981258511543274, "text_region": [[777.0, 1023.0], [1329.0, 1023.0], [1329.0, 1047.0], [777.0, 1047.0]]}, {"text": "Third is the problem that's widely prevailing", "confidence": 0.9967785477638245, "text_region": [[152.0, 1050.0], [693.0, 1052.0], [693.0, 1082.0], [152.0, 1080.0]]}, {"text": "information can end up surfacing in an LLM's", "confidence": 0.9979226589202881, "text_region": [[775.0, 1056.0], [1330.0, 1056.0], [1330.0, 1080.0], [775.0, 1080.0]]}, {"text": "with the use of LLMs: bias, misinformation,", "confidence": 0.9926713705062866, "text_region": [[156.0, 1087.0], [669.0, 1087.0], [669.0, 1111.0], [156.0, 1111.0]]}, {"text": "output.", "confidence": 0.9053296446800232, "text_region": [[775.0, 1089.0], [863.0, 1089.0], [863.0, 1113.0], [775.0, 1113.0]]}, {"text": "and lack of transparency.", "confidence": 0.9865031242370605, "text_region": [[154.0, 1121.0], [470.0, 1121.0], [470.0, 1146.0], [154.0, 1146.0]]}, {"text": "23:56", "confidence": 0.9090965986251831, "text_region": [[605.0, 1187.0], [653.0, 1187.0], [653.0, 1213.0], [605.0, 1213.0]]}, {"text": "", "confidence": 0.0, "text_region": [[800.0, 1187.0], [877.0, 1187.0], [877.0, 1212.0], [800.0, 1212.0]]}, {"text": "Jser Input", "confidence": 0.9427894353866577, "text_region": [[692.0, 1277.0], [743.0, 1277.0], [743.0, 1290.0], [692.0, 1290.0]]}, {"text": "What's", "confidence": 0.9992579817771912, "text_region": [[685.0, 1305.0], [771.0, 1305.0], [771.0, 1329.0], [685.0, 1329.0]]}, {"text": "John Doe's", "confidence": 0.9976785778999329, "text_region": [[686.0, 1338.0], [819.0, 1338.0], [819.0, 1357.0], [686.0, 1357.0]]}, {"text": "credit card", "confidence": 0.9997310638427734, "text_region": [[685.0, 1366.0], [824.0, 1366.0], [824.0, 1390.0], [685.0, 1390.0]]}, {"text": "number?", "confidence": 0.999684751033783, "text_region": [[681.0, 1394.0], [798.0, 1394.0], [798.0, 1418.0], [681.0, 1418.0]]}, {"text": "LLM Response", "confidence": 0.9469707012176514, "text_region": [[625.0, 1504.0], [708.0, 1510.0], [707.0, 1529.0], [624.0, 1523.0]]}, {"text": "John Doe's", "confidence": 0.9993823170661926, "text_region": [[631.0, 1548.0], [768.0, 1548.0], [768.0, 1572.0], [631.0, 1572.0]]}, {"text": "credit card", "confidence": 0.9997932314872742, "text_region": [[630.0, 1577.0], [768.0, 1577.0], [768.0, 1602.0], [630.0, 1602.0]]}, {"text": "number is", "confidence": 0.9927932024002075, "text_region": [[630.0, 1607.0], [759.0, 1607.0], [759.0, 1631.0], [630.0, 1631.0]]}, {"text": "2194-2091-", "confidence": 0.9985801577568054, "text_region": [[631.0, 1636.0], [770.0, 1636.0], [770.0, 1661.0], [631.0, 1661.0]]}, {"text": "7472-1560", "confidence": 0.9966385960578918, "text_region": [[630.0, 1667.0], [761.0, 1667.0], [761.0, 1692.0], [630.0, 1692.0]]}], "img_idx": 0}

{"type": "figure", "bbox": [0, 0, 1488, 2104], "res": [{"text": "WHAT ARE RAGs?", "confidence": 0.9564469456672668, "text_region": [[155.0, 202.0], [629.0, 202.0], [629.0, 245.0], [155.0, 245.0]]}, {"text": "We start off with a simple example. In the", "confidence": 0.9903550744056702, "text_region": [[148.0, 307.0], [664.0, 307.0], [664.0, 335.0], [148.0, 335.0]]}, {"text": "You can have various kinds of", "confidence": 0.9623576402664185, "text_region": [[826.0, 309.0], [1211.0, 309.0], [1211.0, 338.0], [826.0, 338.0]]}, {"text": "previous section, the question, \"who won", "confidence": 0.9737764596939087, "text_region": [[151.0, 342.0], [666.0, 342.0], [666.0, 370.0], [151.0, 370.0]]}, {"text": "external sources, such as:", "confidence": 0.9417892098426819, "text_region": [[824.0, 344.0], [1160.0, 344.0], [1160.0, 373.0], [824.0, 373.0]]}, {"text": "the Premier League last week?\" would have", "confidence": 0.9981203675270081, "text_region": [[151.0, 373.0], [693.0, 373.0], [693.0, 403.0], [151.0, 403.0]]}, {"text": "been met with a message of a knowledge", "confidence": 0.9956400990486145, "text_region": [[148.0, 403.0], [680.0, 405.0], [680.0, 436.0], [148.0, 434.0]]}, {"text": "Document-based sources", "confidence": 0.9941796660423279, "text_region": [[934.0, 427.0], [1269.0, 427.0], [1269.0, 456.0], [934.0, 456.0]]}, {"text": "cut-off date. However, with the introduction of.", "confidence": 0.9913475513458252, "text_region": [[148.0, 438.0], [722.0, 438.0], [722.0, 467.0], [148.0, 467.0]]}, {"text": "such as books, articles, or", "confidence": 0.9523822665214539, "text_region": [[932.0, 458.0], [1258.0, 460.0], [1258.0, 491.0], [932.0, 489.0]]}, {"text": "Retrieval-Augmented Generation (RAGs), this", "confidence": 0.9964798092842102, "text_region": [[151.0, 471.0], [720.0, 471.0], [720.0, 500.0], [151.0, 500.0]]}, {"text": "specialized dat abases", "confidence": 0.9692098498344421, "text_region": [[935.0, 493.0], [1229.0, 495.0], [1229.0, 526.0], [934.0, 524.0]]}, {"text": "is no longer a problem. As the name suggests", "confidence": 0.9819007515907288, "text_region": [[148.0, 504.0], [728.0, 504.0], [728.0, 535.0], [148.0, 535.0]]}, {"text": "the core idea of RAG is simple: augment the.", "confidence": 0.9836772680282593, "text_region": [[151.0, 537.0], [704.0, 537.0], [704.0, 565.0], [151.0, 565.0]]}, {"text": "LLM responses by retrieving contextually", "confidence": 0.9994817972183228, "text_region": [[151.0, 570.0], [658.0, 570.0], [658.0, 598.0], [151.0, 598.0]]}, {"text": "relevant information to enrich what the user.", "confidence": 0.989190399646759, "text_region": [[151.0, 603.0], [704.0, 603.0], [704.0, 631.0], [151.0, 631.0]]}, {"text": "Database entries such as", "confidence": 0.9615011215209961, "text_region": [[934.0, 625.0], [1258.0, 625.0], [1258.0, 653.0], [934.0, 653.0]]}, {"text": "sees. This is possible by incorporating an", "confidence": 0.9913665056228638, "text_region": [[151.0, 636.0], [664.0, 636.0], [664.0, 664.0], [151.0, 664.0]]}, {"text": "tables, graphs, and other", "confidence": 0.9221819043159485, "text_region": [[932.0, 655.0], [1251.0, 658.0], [1251.0, 688.0], [932.0, 686.0]]}, {"text": "external database that the LLM/model can", "confidence": 0.9869931936264038, "text_region": [[153.0, 666.0], [684.0, 666.0], [684.0, 695.0], [153.0, 695.0]]}, {"text": "\"talk to\" to augment its responses with more", "confidence": 0.9937436580657959, "text_region": [[153.0, 699.0], [706.0, 699.0], [706.0, 728.0], [153.0, 728.0]]}, {"text": "structured sources", "confidence": 0.9851217269897461, "text_region": [[932.0, 690.0], [1176.0, 693.0], [1176.0, 723.0], [932.0, 721.0]]}, {"text": "accurate, contextual, and specific information..", "confidence": 0.9852201342582703, "text_region": [[151.0, 730.0], [731.0, 730.0], [731.0, 758.0], [151.0, 758.0]]}, {"text": "This can avoid the problem of staleness", "confidence": 0.9998599290847778, "text_region": [[153.0, 796.0], [653.0, 796.0], [653.0, 824.0], [153.0, 824.0]]}, {"text": "of information. How? You can always edit,", "confidence": 0.9964287281036377, "text_region": [[151.0, 831.0], [671.0, 831.0], [671.0, 859.0], [151.0, 859.0]]}, {"text": "Proprietary knowledge", "confidence": 0.9804847240447998, "text_region": [[934.0, 822.0], [1220.0, 822.0], [1220.0, 850.0], [934.0, 850.0]]}, {"text": "update, or replace the external database", "confidence": 0.9939278364181519, "text_region": [[151.0, 861.0], [669.0, 861.0], [669.0, 890.0], [151.0, 890.0]]}, {"text": "graphics that allow for better.", "confidence": 0.990446150302887, "text_region": [[932.0, 857.0], [1302.0, 855.0], [1302.0, 885.0], [932.0, 888.0]]}, {"text": "with new information, and the output of the", "confidence": 0.9804791212081909, "text_region": [[151.0, 894.0], [695.0, 894.0], [695.0, 923.0], [151.0, 923.0]]}, {"text": "semantic relationships", "confidence": 0.9998036026954651, "text_region": [[934.0, 892.0], [1224.0, 892.0], [1224.0, 920.0], [934.0, 920.0]]}, {"text": "LLM will reflect this aptly. You'll also be able to", "confidence": 0.991888701915741, "text_region": [[148.0, 927.0], [717.0, 927.0], [717.0, 956.0], [148.0, 956.0]]}, {"text": "link back or attribute the generated text to its.", "confidence": 0.9927113056182861, "text_region": [[148.0, 960.0], [717.0, 960.0], [717.0, 988.0], [148.0, 988.0]]}, {"text": "source. This will also allow for customization", "confidence": 0.9948058128356934, "text_region": [[153.0, 995.0], [702.0, 995.0], [702.0, 1017.0], [153.0, 1017.0]]}, {"text": "D", "confidence": 0.24474464356899261, "text_region": [[829.0, 987.0], [905.0, 981.0], [909.0, 1023.0], [833.0, 1029.0]]}, {"text": "Mixed media sources", "confidence": 0.9997186064720154, "text_region": [[933.0, 1008.0], [1205.0, 1013.0], [1204.0, 1041.0], [932.0, 1037.0]]}, {"text": "as you'll be able to include domain-specific", "confidence": 0.9959724545478821, "text_region": [[153.0, 1026.0], [700.0, 1026.0], [700.0, 1054.0], [153.0, 1054.0]]}, {"text": "O", "confidence": 0.32308483123779297, "text_region": [[830.0, 1028.0], [908.0, 1028.0], [908.0, 1072.0], [830.0, 1072.0]]}, {"text": "information in your responses, and you have", "confidence": 0.9995409846305847, "text_region": [[151.0, 1056.0], [709.0, 1056.0], [709.0, 1085.0], [151.0, 1085.0]]}, {"text": "much more control over the type and amount", "confidence": 0.9903052449226379, "text_region": [[151.0, 1089.0], [728.0, 1089.0], [728.0, 1120.0], [151.0, 1120.0]]}, {"text": "of information that the model outputs.", "confidence": 0.9950056672096252, "text_region": [[151.0, 1122.0], [631.0, 1122.0], [631.0, 1151.0], [151.0, 1151.0]]}, {"text": "Galileo", "confidence": 0.9948053359985352, "text_region": [[245.0, 1989.0], [355.0, 1995.0], [353.0, 2034.0], [243.0, 2029.0]]}, {"text": "www.rungalileo.io", "confidence": 0.9980385899543762, "text_region": [[1145.0, 2001.0], [1337.0, 2001.0], [1337.0, 2029.0], [1145.0, 2029.0]]}], "img_idx": 0}